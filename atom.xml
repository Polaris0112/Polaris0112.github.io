<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-03-07T08:36:25.056Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Jayden</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>比特币如何达成共识 - 最长链的选择</title>
    <link href="http://yoursite.com/2018/03/03/blockchain-selection/"/>
    <id>http://yoursite.com/2018/03/03/blockchain-selection/</id>
    <published>2018-03-02T16:00:00.000Z</published>
    <updated>2018-03-07T08:36:25.056Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是比特币如何达成共识 - 最长链的选择</p><p>比特币没有中心机构，几乎所有的完整节点都有一份公共总帐本，那么大家如何达成共识：确认哪一份才是公认权威的总账本呢？</p><h2 id="为什么要遵守协议"><a href="#为什么要遵守协议" class="headerlink" title="为什么要遵守协议"></a>为什么要遵守协议</h2><p>这其实是一个经济问题，在经济活动中的每个人都是自私自利的，追求的是利益的最大化，一个节点工作量只有在其他的节点认同其是有效的（打包的新区块，其他的节点只有验证通过才会加入到区块链中，并在网络上传播），才能够过得收益，<br>而只有遵守规则才会得到其他的节点认同。<br>因此，基于逐利，节点就会自发的遵守协议。共识就是数以万计的独立节点遵守了简单的规则（通过异步交互）自发形成的。</p><blockquote><p>共识：共同遵守的协议规范</p></blockquote><h2 id="去中心化共识"><a href="#去中心化共识" class="headerlink" title="去中心化共识"></a>去中心化共识</h2><p>在<a href="https://polaris0112.github.io/2018/03/03/blockchain-pow/" target="_blank" rel="noopener">工作量证明</a>一篇，我们了解通过工作量证明来竞争记账，权威的总帐本是怎么达到共识的，没有完全说清楚，今天补上，<br>实际上，比特币的共识由所有节点的4个独立过程相互作用而产生：</p><ul><li>每个节点（挖矿节点）依据标准对每个交易进行独立验证</li><li>挖矿节点通过完成工作量证明，将交易记录独立打包进新区块</li><li>每个节点独立的对新区块进行校验并组装进区块链</li><li>每个节点对区块链进行独立选择，在工作量证明机制下选择累计工作量最大的区块链</li></ul><p>共识最终目的是保证比特币不停的在工作量最大的区块链上运转，工作量最大的区块链就是权威的公共总帐本。</p><h2 id="最长链的选择"><a href="#最长链的选择" class="headerlink" title="最长链的选择"></a>最长链的选择</h2><p>先来一个定义，把累计了最多难度的区块链。在一般情况下，也是包含最多区块的那个链称为<strong>主链</strong><br>每一个（挖矿）节点总是选择并尝试延长主链。</p><h2 id="分叉"><a href="#分叉" class="headerlink" title="分叉"></a>分叉</h2><p>当有两名矿工在几乎在相同的时间内，各自都算得了工作量证明解，便立即传播自己的“获胜”区块到网络中，先是传播给邻近的节点而后传播到整个网络。每个收到有效区块的节点都会将其并入并延长区块链。<br>当这个两个区块传播时，一些节点首先收到#3458A, 一些节点首先收到#3458B，这两个候选区块（通常这两个候选区块会包含几乎相同的交易）都是主链的延伸，分叉就会产生，这时分叉出有竞争关系的两条链，如图：</p><p><img src="/images/blockchain-7.jpg" alt="blockchain-7"></p><p>两个块都收到的节点，会把其中有更多工作量的一条会继续作为主链，另一条作为备用链保存（保存是因为备用链将来可能会超过主链难度称为新主链）。</p><h2 id="分叉解决"><a href="#分叉解决" class="headerlink" title="分叉解决"></a>分叉解决</h2><p>收到#3458A的（挖矿）节点，会立刻以这个区块为父区块来产生新的候选区块，并尝试寻找这个候选区块的工作量证明解。同样地，接受#3458B区块的节点会以这个区块为链的顶点开始生成新块，延长这个链（下面称为B链）。<br>这时总会有一方抢先发现工作量证明解并将其传播出去，假设以#3458B为父区块的工作量证明首先解出，如图：</p><p><img src="/images/blockchain-8.jpg" alt="blockchain-8"></p><p>当原本以#3458A为父区块求解的节点在收到#3458B, #3459B之后，会立刻将B链作为主链（因为#3458A为顶点的链已经不是最长链了）继续挖矿。</p><blockquote><p>节点也有可能先收到#3459B，再收到#3458B，收到#3459B时，会被认为是“孤块“（因为还找不到#3459B的父块#3458B）保存在孤块池中，一旦收到父块#3458B时，节点就会将孤块从孤块池中取出，并且连接到它的父区块，让它作为区块链的一部分。</p></blockquote><p>比特币将区块间隔设计为10分钟，是在更快速的交易确认和更低的分叉概率间作出的妥协。更短的区块产生间隔会让交易确认更快地完成，也会导致更加频繁地区块链分叉。与之相对地，长的间隔会减少分叉数量，却会导致更长的确认时间。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是比特币如何达成共识 - 最长链的选择&lt;/p&gt;
&lt;p&gt;比特币没有中心机构，几乎所有的完整节点都有一份公共总帐本，那么大家如何达成共识：确认哪一份才是公认权威的总账本呢？&lt;/p&gt;
&lt;h2 id=&quot;为什么要遵守协议&quot;&gt;&lt;a href=&quot;#为什么要遵守协议&quot; clas
      
    
    </summary>
    
      <category term="比特币如何达成共识 - 最长链的选择" scheme="http://yoursite.com/categories/%E6%AF%94%E7%89%B9%E5%B8%81%E5%A6%82%E4%BD%95%E8%BE%BE%E6%88%90%E5%85%B1%E8%AF%86-%E6%9C%80%E9%95%BF%E9%93%BE%E7%9A%84%E9%80%89%E6%8B%A9/"/>
    
    
      <category term="Blockchain" scheme="http://yoursite.com/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>比特币区块结构 Merkle 树及简单支付验证分析</title>
    <link href="http://yoursite.com/2018/03/03/blockchain-merkle/"/>
    <id>http://yoursite.com/2018/03/03/blockchain-merkle/</id>
    <published>2018-03-02T16:00:00.000Z</published>
    <updated>2018-03-07T08:35:51.512Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是比特币区块结构 Merkle 树及简单支付验证分析</p><p>在比特币网络中，不是每个节点都有能力储存完整的区块链数据，受限于存储空间的的限制，很多节点是以SPV（Simplified Payment Verification简单支付验证）钱包接入比特币网络，通过简单支付验证可以在不必存储完整区块链下对交易进行验证，本文将分析区块结构Merkle树及如何进行交易验证。</p><h2 id="区块结构"><a href="#区块结构" class="headerlink" title="区块结构"></a>区块结构</h2><p>在<a href="https://polaris0112.github.io/2018/03/03/blockchain-pow/" target="_blank" rel="noopener">工作量证明</a>中出现过一个区块信息截图：</p><p><img src="/images/blockchain-6.jpg" alt="blockchain-6"></p><p>细心的同学一定已经在里面发现了很多未讲的其他信息，如：时间戳，版本号，交易次数，二进制哈希树根(Merkle根)等。</p><p>我们来看看一个区块结构到底是怎样的：</p><p><img src="/images/blockchain-9.jpg" alt="blockchain-9"></p><p>如上图（下文称：区块结构图）所示：每个数据区块包含区块头和区块体。<br>区块头封装了当前版本号、前一区块哈希值、当前区块PoW要求的随机数(Nonce)、时间戳、以及Merkle根信息。<br>区块体则包括当前区块经过验证的、 区块创建过程中生成的所有交易记录。这些记录通过 Merkle树的哈希过程生成唯一的Merkle根并记入区块头.</p><blockquote><p>区块哈希值实际上并不包含在区块的数据结构里，其实区块打包时只有区块头被用于计算哈希（从网络被接收时由每个节点计算出来），常说的区块哈希值实际是区块头哈希值，它可以用来唯一、明确地标识一个区块。</p></blockquote><p>区块头是80字节，而平均每个交易至少是250字节，而且平均每个区块包含2000个交易。因此，包含完整交易的区块比区块头的4千倍还要大。<br>SPV节点只下载区块头，不下载包含在每个区块中的交易信息。这样的不含交易信息的区块链，大小只有完整区块链的几千分之1，那SPV节点是如何验证交易的呢？</p><h2 id="哈希验证"><a href="#哈希验证" class="headerlink" title="哈希验证"></a>哈希验证</h2><p>上面先留一个引子，先来回顾下哈希函数，<a href="https://polaris0112.github.io/2018/03/02/blockchain-accounting/" target="_blank" rel="noopener">记账原理</a>我们知道原始信息任何微小的变化都会哈希完全不同的哈希值。</p><h2 id="简单文件验证"><a href="#简单文件验证" class="headerlink" title="简单文件验证"></a>简单文件验证</h2><p>我们通常用哈希来检验下载的文件是否完整，我经常看到这样的下载页面：</p><p><img src="/images/blockchain-10.jpg" alt="blockchain-10"></p><p>可以看到下载链接后面提供了一个MD5（MD5也是一种Hash算法），这样我们可以在下载之后对文件计算MD5，如果MD5与提供的MD5相等，说明文件有没有被损坏，这个验证过程相信大家都能理解。</p><h3 id="多点文件验证-哈希列表"><a href="#多点文件验证-哈希列表" class="headerlink" title="多点文件验证(哈希列表)"></a>多点文件验证(哈希列表)</h3><p>现在复杂度提高一点，在P2P网络中下载时，会把大文件切成小文件，同时从多个机器上下载数据，这个时候怎么验证数据呢？</p><p>以BT下载为例，在下载真正的数据之前，我们会先下载一个哈希列表的（每个下小块计算出一个哈希），如果有一个小块数据在传输过程中损坏了，那我只要重新下载这一个数据块就行了，这时有一个问题就出现了，那么多的哈希，怎么保证它们本身(哈希列表中的哈希值)都是正确地呢？</p><p>答案是把每个小块数据的哈希值拼到一起，然后对这个长字符串在作一次哈希运算，得到哈希列表的根哈希。只要根哈希校对比一样就说明验哈希列表是正确的，再通过哈希列表校验小数据块，如果所有的小数据块验证通过则说明大文件没有被损坏。</p><h3 id="Merkle树"><a href="#Merkle树" class="headerlink" title="Merkle树"></a>Merkle树</h3><p>验证交易的过程和文件验证很相似，可以人为每个交易是一个小数据块，但比特币使用Merkle树的方式进行验证，相对于哈希列表，Merkle树是一种哈希二叉树，它的明显的一个好处是可以单独拿出一个分支来（作为一个小树）对部分数据进行校验，更加高效。</p><p>我们回看下上面的区块结构图，区块体就包含这样一个Merkle树,Merkle树被用来归纳一个区块中的所有交易。</p><p>每个叶子节点是每个交易信息的哈希，往上对相邻的两个哈希合并成字符串再哈希，继续类似的操作直到只剩下顶部的一个节点，即Merkle根，存入区块头。</p><p>因为Merkle树是二叉树，所以它需要偶数个叶子节点。如果仅有奇数个交易需要归纳，那最后的交易就会被复制一份以构成偶数个叶子节点，这种偶数个叶子节点的树也被称为平衡树。</p><h3 id="简化支付验证"><a href="#简化支付验证" class="headerlink" title="简化支付验证"></a>简化支付验证</h3><p>SPV节点不保存所有交易也不会下载整个区块，仅仅保存区块头，我们来看看它是如何对交易数据进行验证的。</p><p>假如要验证区块结构图中交易6，SPV节点会通过向相邻节点索要（通过Merkleblock消息）包括从交易6哈希值沿Merkle树上溯至区块头根哈希处的哈希序列 (即哈希节点6, 5, 56, 78, 5678, 1234 1~8 - 称为认证路径) 来确认交易的存在性和正确性。（在N个交易组成的区块中确认任一交易只需要计算log2(N)个字节的哈希值，非常快速高效）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是比特币区块结构 Merkle 树及简单支付验证分析&lt;/p&gt;
&lt;p&gt;在比特币网络中，不是每个节点都有能力储存完整的区块链数据，受限于存储空间的的限制，很多节点是以SPV（Simplified Payment Verification简单支付验证）钱包接入比特币网
      
    
    </summary>
    
      <category term="比特币区块结构 Merkle 树及简单支付验证分析" scheme="http://yoursite.com/categories/%E6%AF%94%E7%89%B9%E5%B8%81%E5%8C%BA%E5%9D%97%E7%BB%93%E6%9E%84-Merkle-%E6%A0%91%E5%8F%8A%E7%AE%80%E5%8D%95%E6%94%AF%E4%BB%98%E9%AA%8C%E8%AF%81%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Blockchain" scheme="http://yoursite.com/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>比特币如何挖矿（挖矿原理）-工作量证明</title>
    <link href="http://yoursite.com/2018/03/03/blockchain-pow/"/>
    <id>http://yoursite.com/2018/03/03/blockchain-pow/</id>
    <published>2018-03-02T16:00:00.000Z</published>
    <updated>2018-03-07T08:34:30.193Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是比特币如何挖矿（挖矿原理）-工作量证明</p><p>在<a href="https://polaris0112.github.io/2018/03/02/blockchain-accounting/" target="_blank" rel="noopener">区块链记账原理</a>一篇，我们了解到记账是把交易记录、交易时间、账本序号、上一个Hash值等信息计算Hash打包的过程。<br>我们知道所有的计算和存贮是需要消耗计算机资源的，既然要付出成本，那节点为什么还要参与记账呢？在中本聪（比特币之父）的设计里，完成记账的节点可以获得系统给与的一定数量的比特币奖励，这个奖励的过程也就是比特币的发行过程，因此大家形象的把记账称为“挖矿”，本文将详细讨论这个过程。</p><h2 id="记账工作"><a href="#记账工作" class="headerlink" title="记账工作"></a>记账工作</h2><p>由于记账是有奖励的，每次记账都可以给自己凭空增加一定数量的个比特币（当前是12.5比特币，博文写作时每个比特币是4万人民币以上，大家可以算算多少钱），因此就出现大家争相记账，大家一起记账就会引起问题：出现记账不一致的问题，比特币系统引入工作量证明来解决这个问题，规则如下：</p><ul><li>一段时间内（10分钟左右，具体时间会与密码学难题难度相互影响）只有一人可以记账成功</li><li>通过解决密码学难题（即工作量证明）竞争获得唯一记账权</li><li>其他节点复制记账结果</li></ul><p>不过在进行工作量证明之前，记账节点会做进行如下准备工作：</p><ul><li>收集广播中还没有被记录账本的原始交易信息</li><li>检查每个交易信息中付款地址有没有足够的余额</li><li>验证交易是否有正确的签名</li><li>把验证通过的交易信息进行打包记录</li><li>添加一个奖励交易：给自己的地址增加12.5比特币</li></ul><p>如果节点争夺记账权成功的话，就可以得到12.5比特币的奖励。</p><h2 id="工作量证明"><a href="#工作量证明" class="headerlink" title="工作量证明"></a>工作量证明</h2><p><a href="https://polaris0112.github.io/2018/03/02/blockchain-accounting/" target="_blank" rel="noopener">区块链记账原理</a>我们了解到，每次记账的时候会把上一个块的Hash值和当前的账页信息一起作为原始信息进行Hash。<br>如果仅仅是这样，显然每个人都可以很轻松的完成记账。<br>为了保证10分钟左右只有一个人可以记账，就必须要提高记账的难度，使得Hash的结果必须以若干个0开头。同是为了满足这个条件，在进行Hash时引入一个随机数变量。</p><p>用伪代码表示一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 没有难度时为：Hash(上一个Hash值，交易记录集) = 456635BCD</span></span><br><span class="line">Hash(上一个Hash值，交易记录集，随机数) = 0000aFD635BCD</span><br></pre></td></tr></table></figure><p>我们知道改变Hash的原始信息的任何一部分，Hash值也会随之不断的变化，因此在运算Hash时，不断的改变随机数的值，总可以找的一个随机数使的Hash的结果以若干个0开头（下文把这个过程称为猜谜），率先找到随机数的节点就获得此次记账的唯一记账权。</p><h3 id="计算量分析"><a href="#计算量分析" class="headerlink" title="计算量分析"></a>计算量分析</h3><p>（这部分可选阅读）我们简单分析下记账难度有多大，<br>Hash值是由数字和大小写字母构成的字符串，每一位有62种可能性（可能为26个大写字母、26个小写字母，10个数字中任一个），假设任何一个字符出现的概率是均等的，那么第一位为0的概率是1/62（其他位出现什么字符先不管），理论上需要尝试62次Hash运算才会出现一次第一位为0的情况，如果前两2位为0，就得尝试62的平方次Hash运算，以n个0开头就需要尝试62的n次方次运算。我们结合当前实际区块#493050信息来看看：</p><p><img src="/images/blockchain-6.jpg" alt="blockchain-6"></p><p>注：<a href="https://blockchain.info" target="_blank" rel="noopener">数据来源</a><br>我们可以看到Hash值以18个0开头，理论上需要尝试62的18次方次，这个数是非常非常巨大的，我已经算不清楚了，应该是亿亿级别以上了。如此大的计算量需要投入大量的计算设备、电力等，<br>目前应该没有单矿工独立参与挖矿了，基本都是由矿工联合起来组成矿池进行挖矿（矿池里的矿工按算力百分比来分收益）。</p><p>从经济的角度讲，只有挖矿还有收益（比特币价格不断上涨也让收益变大），就会有新的矿工加入，从而加剧竞争，提高算力难度，挖矿就需要耗费更多的运算和电力，相互作用引起最终成本会接近收益。</p><p>题外话：国内由于电力成本较低，相对收益更高，中国的算力占整个网络的一半以上</p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>在节点成功找到满足的Hash值之后，会马上对全网进行广播打包区块，网络的节点收到广播打包区块，会立刻对其进行验证。</p><p>如果验证通过，则表明已经有节点成功解迷，自己就不再竞争当前区块打包，而是选择接受这个区块，记录到自己的账本中，然后进行下一个区块的竞争猜谜。<br>网络中只有最快解谜的区块，才会添加的账本中，其他的节点进行复制，这样就保证了整个账本的唯一性。</p><p>假如节点有任何的作弊行为，都会导致网络的节点验证不通过，直接丢弃其打包的区块，这个区块就无法记录到总账本中，作弊的节点耗费的成本就白费了，因此在巨大的挖矿成本下，也使得矿工自觉自愿的遵守比特币系统的共识协议，也就确保了整个系统的安全。</p><p>进阶阅读<a href="https://polaris0112.github.io/2018/03/03/blockchain-merkle/" target="_blank" rel="noopener">比特币区块结构Merkle树及简单支付验证分析</a>，可以详细了解区块结构如何验证交易。</p><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>矿工的收益其实不仅仅包含新发行的12.5比特币奖励，同时还有交易费收益（本文忽略一些细节是为了让主干更清晰）。</p><p>有兴趣的同学可以看看图中区块都包含了那些信息，红箭头标示出的是本文涉及的信息。</p><p>本文中有提到共识协议，比特币共识协议主要是由工作量证明和最长链机制 两部分组成，请阅读<a href="https://polaris0112.github.io/2018/03/03/blockchain-selection/" target="_blank" rel="noopener">比特币如何达成共识 - 最长链的选择</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是比特币如何挖矿（挖矿原理）-工作量证明&lt;/p&gt;
&lt;p&gt;在&lt;a href=&quot;https://polaris0112.github.io/2018/03/02/blockchain-accounting/&quot; target=&quot;_blank&quot; rel=&quot;noopene
      
    
    </summary>
    
      <category term="比特币如何挖矿（挖矿原理）-工作量证明" scheme="http://yoursite.com/categories/%E6%AF%94%E7%89%B9%E5%B8%81%E5%A6%82%E4%BD%95%E6%8C%96%E7%9F%BF%EF%BC%88%E6%8C%96%E7%9F%BF%E5%8E%9F%E7%90%86%EF%BC%89-%E5%B7%A5%E4%BD%9C%E9%87%8F%E8%AF%81%E6%98%8E/"/>
    
    
      <category term="Blockchain" scheme="http://yoursite.com/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>区块链记账原理</title>
    <link href="http://yoursite.com/2018/03/02/blockchain-accounting/"/>
    <id>http://yoursite.com/2018/03/02/blockchain-accounting/</id>
    <published>2018-03-01T16:00:00.000Z</published>
    <updated>2018-03-07T08:36:14.592Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是区块链记账原理</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>区块链(1.0)是一个基于密码学安全的分布式账本，是一个方便验证，不可篡改的账本。<br>通常认为与智能合约相结合的区块链为区块链2.0, 如以太坊是典型的区块链2.0<br>很多人只了解过比特币，不知道区块链，比特币实际是一个使用了区块链技术的应用，只是比特币当前太热，把区块链技术的光芒给掩盖了。区块链才是未来，期望各位开发人员少关心币价，多关心技术。<br>本文将讲解区块链1.0技术是如何实现的。</p><h2 id="哈希函数"><a href="#哈希函数" class="headerlink" title="哈希函数"></a>哈希函数</h2><p>在讲区块链记账之前，先说明一下哈希函数。<br>哈希函数：Hash(原始信息) = 摘要信息<br>原始信息可以是任意的信息, hash之后会得到一个简短的摘要信息</p><p>哈希函数有几个特点:</p><ul><li>同样的原始信息用同一个哈希函数总能得到相同的摘要信息</li><li>原始信息任何微小的变化都会哈希出面目全非的摘要信息</li><li>从摘要信息无法逆向推算出原始信息</li></ul><p>举例说明：<br>Hash(张三借给李四100万，利息1%，1年后还本息 …..) = AC4635D34DEF<br>账本上记录了AC4635D34DEF这样一条记录。</p><p>可以看出哈希函数有4个作用：</p><ul><li>简化信息<br>很好理解，哈希后的信息变短了。</li><li>标识信息<br>可以使用AC4635D34DEF来标识原始信息，摘要信息也称为原始信息的id。</li><li>隐匿信息<br>账本是AC4635D34DEF这样一条记录，原始信息被隐匿。</li><li>验证信息<br>假如李四在还款时欺骗说，张三只借给李四10万，双方可以用AC4635D34DEF来验证原始信息</li></ul><p>哈希函数的这4个作用在区块链技术里有广泛的运用。<br>（哈希函数是一组函数或算法，以后会发文章专门介绍哈希）</p><h2 id="区块链记账方法"><a href="#区块链记账方法" class="headerlink" title="区块链记账方法"></a>区块链记账方法</h2><p>假设有一个账页序号为0的账页交易记录如下:</p><p><img src="/images/blockchain-5.png" alt="blockchain-5"></p><p>记账时间为：2017-10-22 10:22:02</p><p>区块链在记账是会把账页信息（包含序号、记账时间、交易记录）作为原始信息进行Hash, 得到一个Hash值，如：787635ACD, 用函数表示为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hash(序号0、记账时间、交易记录) = 787635ACD</span><br></pre></td></tr></table></figure><p>账页信息和Hash值组合在一起就构成了第一个区块。</p><blockquote><p>比特币系统里约10分钟记一次账，即每个区块生成时间大概间隔10分钟</p></blockquote><p>在记第2个账页的时候，会把上一个块的Hash值和当前的账页信息一起作为原始信息进行Hash,即：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hash(上一个Hash值、序号1、记账时间、交易记录) = 456635BCD</span><br></pre></td></tr></table></figure><p>这样第2个区块不仅包含了本账页信息，还间接的包含了第一个区块的信息。依次按照此方法继续记账，则最新的区块总是间接包含了所有之前的账页信息。</p><p>所有这些区块组合起来就形成了区块链，这样的区块链就构成了一个便于验证（只要验证最后一个区块的Hash值就相当于验证了整个账本），不可更改（任何一个交易信息的更改，会让所有之后的区块的Hash值发生变化，这样在验证时就无法通过）的总账本。</p><p>记账有成本，想了解节点为什么要记账，请看这篇：<a href="https://polaris0112.github.io/2018/03/03/blockchain-pow/" target="_blank" rel="noopener">在比特币如何挖矿-工作量证明</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是区块链记账原理&lt;/p&gt;
&lt;h2 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h2&gt;&lt;p&gt;区块链(1.0)是一个基于密码学安全的分布式账本，是一个方便验证，不可篡改的账本。&lt;br&gt;通常认
      
    
    </summary>
    
      <category term="区块链记账原理" scheme="http://yoursite.com/categories/%E5%8C%BA%E5%9D%97%E9%93%BE%E8%AE%B0%E8%B4%A6%E5%8E%9F%E7%90%86/"/>
    
    
      <category term="Blockchain" scheme="http://yoursite.com/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>用Python从0开始创建一个区块链</title>
    <link href="http://yoursite.com/2018/03/02/blockchain-python/"/>
    <id>http://yoursite.com/2018/03/02/blockchain-python/</id>
    <published>2018-03-01T16:00:00.000Z</published>
    <updated>2018-03-07T08:29:11.421Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是用Python建立一个区块链，初步了解区块链使用到的技术。</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>本文要求读者对 Python 有基本的理解，能读写基本的 Python，并且需要对 HTTP 请求有基本的了解。</p><p>我们知道区块链是由区块的记录构成的不可变、有序的链结构，记录可以是交易、文件或任何你想要的数据，重要的是它们是通过哈希值（hashes）链接起来的。</p><p>如果你还不是很了解哈希，可以查看<a href="https://learncryptography.com/hash-functions/what-are-hash-functions" target="_blank" rel="noopener">这篇文章</a>。</p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p>确保已经安装 Python3.6+、pip、Flask、requests。</p><h3 id="安装方法"><a href="#安装方法" class="headerlink" title="安装方法"></a>安装方法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install Flask==0.12.2 requests==2.18.4</span><br></pre></td></tr></table></figure><p>同时还需要一个 HTTP 客户端，比如 Postman、cURL 或其他客户端。</p><p>参考<a href="https://github.com/dvf/blockchain" target="_blank" rel="noopener">源代码</a>。</p><h2 id="开始创建-Blockchain"><a href="#开始创建-Blockchain" class="headerlink" title="开始创建 Blockchain"></a>开始创建 Blockchain</h2><p>新建一个文件 blockchain.py，本文所有的代码都写在这一个文件中，可以随时参考<a href="https://github.com/dvf/blockchain" target="_blank" rel="noopener">源代码</a>。</p><h3 id="Blockchain-类"><a href="#Blockchain-类" class="headerlink" title="Blockchain 类"></a>Blockchain 类</h3><p>首先创建一个 Blockchain 类，在构造函数中创建了两个列表，一个用于储存区块链，一个用于储存交易。</p><p><strong>以下是 Blockchain 类的框架：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.chain = []</span><br><span class="line">        self.current_transactions = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_block</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Creates a new Block and adds it to the chain</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_transaction</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Adds a new transaction to the list of transactions</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hash</span><span class="params">(block)</span>:</span></span><br><span class="line">        <span class="comment"># Hashes a Block</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">last_block</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># Returns the last Block in the chain</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>Blockchain 类用来管理链条，它能存储交易、加入新块等，下面我们来进一步完善这些方法。</p><h3 id="块结构"><a href="#块结构" class="headerlink" title="块结构"></a>块结构</h3><p>每个区块包含属性：索引（index）、Unix 时间戳（timestamp）、交易列表（transactions）、工作量证明（稍后解释）以及前一个区块的 Hash 值。</p><p><strong>以下是一个区块的结构：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">block = &#123;</span><br><span class="line">    <span class="string">'index'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">'timestamp'</span>: <span class="number">1506057125.900785</span>,</span><br><span class="line">    <span class="string">'transactions'</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">'sender'</span>: <span class="string">"8527147fe1f5426f9dd545de4b27ee00"</span>,</span><br><span class="line">            <span class="string">'recipient'</span>: <span class="string">"a77f5cdfa2934df3954a5c7c7da5df1f"</span>,</span><br><span class="line">            <span class="string">'amount'</span>: <span class="number">5</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'proof'</span>: <span class="number">324984774000</span>,</span><br><span class="line">    <span class="string">'previous_hash'</span>: <span class="string">"2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里区块链的概念就清楚了，每个新的区块都包含上一个区块的 Hash，这是关键的一点，它保障了区块链的不可变性。</p><p>如果攻击者破坏了前面的某个区块，那么后面所有区块的Hash都会变得不正确。不理解的话，慢慢消化，可参考<a href="https://polaris0112.github.io/2018/03/02/blockchain-accounting/" target="_blank" rel="noopener">区块链记账原理</a>。</p><h3 id="加入交易"><a href="#加入交易" class="headerlink" title="加入交易"></a>加入交易</h3><p><strong>接下来我们需要添加一个交易，来完善下 new_transaction 方法：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span><span class="params">(object)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_transaction</span><span class="params">(self, sender, recipient, amount)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成新交易信息，信息将加入到下一个待挖的区块中</span></span><br><span class="line"><span class="string">        :param sender: &lt;str&gt; Address of the Sender</span></span><br><span class="line"><span class="string">        :param recipient: &lt;str&gt; Address of the Recipient</span></span><br><span class="line"><span class="string">        :param amount: &lt;int&gt; Amount</span></span><br><span class="line"><span class="string">        :return: &lt;int&gt; The index of the Block that will hold this transaction</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.current_transactions.append(&#123;</span><br><span class="line">            <span class="string">'sender'</span>: sender,</span><br><span class="line">            <span class="string">'recipient'</span>: recipient,</span><br><span class="line">            <span class="string">'amount'</span>: amount,</span><br><span class="line">        &#125;)</span><br><span class="line">        <span class="keyword">return</span> self.last_block[<span class="string">'index'</span>] + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>方法向列表中添加一个交易记录，并返回该记录将被添加到的区块(下一个待挖掘的区块)的索引，等下在用户提交交易时会有用。</p><h3 id="创建新块"><a href="#创建新块" class="headerlink" title="创建新块"></a>创建新块</h3><p>当 Blockchain 实例化后，我们需要构造一个创世块（没有前区块的第一个区块），并且给它加上一个工作量证明。每个区块都需要经过工作量证明，俗称挖矿，稍后会继续讲解。</p><p><strong>为了构造创世块，我们还需要完善 new_block()，new_transaction() 和hash() 方法：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.current_transactions = []</span><br><span class="line">        self.chain = []</span><br><span class="line">        <span class="comment"># Create the genesis block</span></span><br><span class="line">        self.new_block(previous_hash=<span class="number">1</span>, proof=<span class="number">100</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_block</span><span class="params">(self, proof, previous_hash=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成新块</span></span><br><span class="line"><span class="string">        :param proof: &lt;int&gt; The proof given by the Proof of Work algorithm</span></span><br><span class="line"><span class="string">        :param previous_hash: (Optional) &lt;str&gt; Hash of previous Block</span></span><br><span class="line"><span class="string">        :return: &lt;dict&gt; New Block</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        block = &#123;</span><br><span class="line">            <span class="string">'index'</span>: len(self.chain) + <span class="number">1</span>,</span><br><span class="line">            <span class="string">'timestamp'</span>: time(),</span><br><span class="line">            <span class="string">'transactions'</span>: self.current_transactions,</span><br><span class="line">            <span class="string">'proof'</span>: proof,</span><br><span class="line">            <span class="string">'previous_hash'</span>: previous_hash <span class="keyword">or</span> self.hash(self.chain[<span class="number">-1</span>]),</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># Reset the current list of transactions</span></span><br><span class="line">        self.current_transactions = []</span><br><span class="line">        self.chain.append(block)</span><br><span class="line">        <span class="keyword">return</span> block</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_transaction</span><span class="params">(self, sender, recipient, amount)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成新交易信息，信息将加入到下一个待挖的区块中</span></span><br><span class="line"><span class="string">        :param sender: &lt;str&gt; Address of the Sender</span></span><br><span class="line"><span class="string">        :param recipient: &lt;str&gt; Address of the Recipient</span></span><br><span class="line"><span class="string">        :param amount: &lt;int&gt; Amount</span></span><br><span class="line"><span class="string">        :return: &lt;int&gt; The index of the Block that will hold this transaction</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.current_transactions.append(&#123;</span><br><span class="line">            <span class="string">'sender'</span>: sender,</span><br><span class="line">            <span class="string">'recipient'</span>: recipient,</span><br><span class="line">            <span class="string">'amount'</span>: amount,</span><br><span class="line">        &#125;)</span><br><span class="line">        <span class="keyword">return</span> self.last_block[<span class="string">'index'</span>] + <span class="number">1</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">last_block</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.chain[<span class="number">-1</span>]</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hash</span><span class="params">(block)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        生成块的 SHA-256 hash值</span></span><br><span class="line"><span class="string">        :param block: &lt;dict&gt; Block</span></span><br><span class="line"><span class="string">        :return: &lt;str&gt;</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># We must make sure that the Dictionary is Ordered, or we will have inconsistent hashes</span></span><br><span class="line">        block_string = json.dumps(block, sort_keys=<span class="keyword">True</span>).encode()</span><br><span class="line">        <span class="keyword">return</span> hashlib.sha256(block_string).hexdigest()</span><br></pre></td></tr></table></figure><p>通过上面的代码和注释可以对区块链有直观的了解，接下来我们看看区块是怎么挖出来的。</p><h3 id="理解工作量证明"><a href="#理解工作量证明" class="headerlink" title="理解工作量证明"></a>理解工作量证明</h3><p>新的区块依赖工作量证明算法（PoW）来构造。PoW 的目标是找出一个符合特定条件的数字，这个数字很难计算出来，但容易验证。这就是工作量证明的核心思想。</p><p><strong>为了方便理解，举个例子：</strong></p><p>假设一个整数 x 乘以另一个整数 y 的积的 Hash 值必须以 0 结尾，即 hash(x * y) = ac23dc…0。设变量 x = 5，求 y 的值？</p><p><strong>用 Python 实现如下：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> sha256</span><br><span class="line">x = <span class="number">5</span></span><br><span class="line">y = <span class="number">0</span>  <span class="comment"># y未知</span></span><br><span class="line"><span class="keyword">while</span> sha256(<span class="string">f'<span class="subst">&#123;x*y&#125;</span>'</span>.encode()).hexdigest()[<span class="number">-1</span>] != <span class="string">"0"</span>:</span><br><span class="line">    y += <span class="number">1</span></span><br><span class="line">print(<span class="string">f'The solution is y = <span class="subst">&#123;y&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><p>结果是：y = 21，因为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hash(<span class="number">5</span> * <span class="number">21</span>) = <span class="number">1253e9373</span>e..<span class="number">.5e3600155</span>e860</span><br></pre></td></tr></table></figure><p>在比特币中，使用称为 Hashcash 的工作量证明算法，它和上面的问题很类似，矿工们为了争夺创建区块的权利而争相计算结果。</p><p>通常，计算难度与目标字符串需要满足的特定字符的数量成正比，矿工算出结果后，会获得比特币奖励。当然，在网络上非常容易验证这个结果。</p><h3 id="实现工作量证明"><a href="#实现工作量证明" class="headerlink" title="实现工作量证明"></a>实现工作量证明</h3><p>让我们来实现一个相似 PoW 算法，规则是：寻找一个数 p，使得它与前一个区块的 proof 拼接成的字符串的 Hash 值以 4 个零开头。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> uuid <span class="keyword">import</span> uuid4</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span><span class="params">(object)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">proof_of_work</span><span class="params">(self, last_proof)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        简单的工作量证明:</span></span><br><span class="line"><span class="string">         - 查找一个 p' 使得 hash(pp') 以4个0开头</span></span><br><span class="line"><span class="string">         - p 是上一个块的证明,  p' 是当前的证明</span></span><br><span class="line"><span class="string">        :param last_proof: &lt;int&gt;</span></span><br><span class="line"><span class="string">        :return: &lt;int&gt;</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        proof = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.valid_proof(last_proof, proof) <span class="keyword">is</span> <span class="keyword">False</span>:</span><br><span class="line">            proof += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> proof</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">valid_proof</span><span class="params">(last_proof, proof)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        验证证明: 是否hash(last_proof, proof)以4个0开头?</span></span><br><span class="line"><span class="string">        :param last_proof: &lt;int&gt; Previous Proof</span></span><br><span class="line"><span class="string">        :param proof: &lt;int&gt; Current Proof</span></span><br><span class="line"><span class="string">        :return: &lt;bool&gt; True if correct, False if not.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        guess = <span class="string">f'<span class="subst">&#123;last_proof&#125;</span><span class="subst">&#123;proof&#125;</span>'</span>.encode()</span><br><span class="line">        guess_hash = hashlib.sha256(guess).hexdigest()</span><br><span class="line">        <span class="keyword">return</span> guess_hash[:<span class="number">4</span>] == <span class="string">"0000"</span></span><br></pre></td></tr></table></figure><p>衡量算法复杂度的办法是修改零开头的个数。使用 4 个零来用于演示，你会发现多一个零都会大大增加计算出结果所需的时间。</p><p>现在 Blockchain 类基本已经完成了，接下来使用 HTTP requests 来进行交互。</p><h2 id="Blockchain-作为-API-接口"><a href="#Blockchain-作为-API-接口" class="headerlink" title="Blockchain 作为 API 接口"></a>Blockchain 作为 API 接口</h2><p>我们将使用 Python Flask 框架，这是一个轻量 Web 应用框架，它方便将网络请求映射到 Python 函数，现在我们来让 Blockchain 运行在 Flask Web 上。</p><p><strong>我们将创建三个接口：</strong></p><ul><li><p>/transactions/new 创建一个交易并添加到区块</p></li><li><p>/mine 告诉服务器去挖掘新的区块</p></li><li><p>/chain 返回整个区块链</p></li></ul><h3 id="创建节点"><a href="#创建节点" class="headerlink" title="创建节点"></a>创建节点</h3><p>我们的“Flask 服务器”将扮演区块链网络中的一个节点，<strong>我们先添加一些框架代码：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> textwrap <span class="keyword">import</span> dedent</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> uuid <span class="keyword">import</span> uuid4</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span><span class="params">(object)</span>:</span></span><br><span class="line">    ...</span><br><span class="line"><span class="comment"># Instantiate our Node</span></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"><span class="comment"># Generate a globally unique address for this node</span></span><br><span class="line">node_identifier = str(uuid4()).replace(<span class="string">'-'</span>, <span class="string">''</span>)</span><br><span class="line"><span class="comment"># Instantiate the Blockchain</span></span><br><span class="line">blockchain = Blockchain()</span><br><span class="line"><span class="meta">@app.route('/mine', methods=['GET'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mine</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"We'll mine a new Block"</span></span><br><span class="line"><span class="meta">@app.route('/transactions/new', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_transaction</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"We'll add a new transaction"</span></span><br><span class="line"><span class="meta">@app.route('/chain', methods=['GET'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">full_chain</span><span class="params">()</span>:</span></span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">'chain'</span>: blockchain.chain,</span><br><span class="line">        <span class="string">'length'</span>: len(blockchain.chain),</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> jsonify(response), <span class="number">200</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app.run(host=<span class="string">'0.0.0.0'</span>, port=<span class="number">5000</span>)</span><br></pre></td></tr></table></figure><p><strong>简单的说明一下以上代码：</strong></p><ul><li>第 15 行：创建一个节点。</li><li>第 18 行：为节点创建一个随机的名字。</li><li>第 21 行：实例 Blockchain 类。</li><li>第 24–26 行：创建 /mine GET 接口。</li><li>第 28–30 行：创建 /transactions/new POST 接口,可以给接口发送交易数据。</li><li>第 32–38 行：创建 /chain 接口, 返回整个区块链。</li><li>第 40–41 行：服务运行在端口 5000 上。</li></ul><h3 id="发送交易"><a href="#发送交易" class="headerlink" title="发送交易"></a>发送交易</h3><p><strong>发送到节点的交易数据结构如下：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">"sender"</span>: <span class="string">"my address"</span>,</span><br><span class="line"> <span class="string">"recipient"</span>: <span class="string">"someone else's address"</span>,</span><br><span class="line"> <span class="string">"amount"</span>: 5</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>之前已经有添加交易的方法，基于接口来添加交易就很简单了：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> textwrap <span class="keyword">import</span> dedent</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> uuid <span class="keyword">import</span> uuid4</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, jsonify, request</span><br><span class="line">...</span><br><span class="line"><span class="meta">@app.route('/transactions/new', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">new_transaction</span><span class="params">()</span>:</span></span><br><span class="line">    values = request.get_json()</span><br><span class="line">    <span class="comment"># Check that the required fields are in the POST'ed data</span></span><br><span class="line">    required = [<span class="string">'sender'</span>, <span class="string">'recipient'</span>, <span class="string">'amount'</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> all(k <span class="keyword">in</span> values <span class="keyword">for</span> k <span class="keyword">in</span> required):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'Missing values'</span>, <span class="number">400</span></span><br><span class="line">    <span class="comment"># Create a new Transaction</span></span><br><span class="line">    index = blockchain.new_transaction(values[<span class="string">'sender'</span>], values[<span class="string">'recipient'</span>], values[<span class="string">'amount'</span>])</span><br><span class="line">    response = &#123;<span class="string">'message'</span>: <span class="string">f'Transaction will be added to Block <span class="subst">&#123;index&#125;</span>'</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> jsonify(response), <span class="number">201</span></span><br></pre></td></tr></table></figure><h3 id="挖矿"><a href="#挖矿" class="headerlink" title="挖矿"></a>挖矿</h3><p><strong>挖矿正是神奇所在，它很简单，做了以下三件事：</strong></p><ul><li>计算工作量证明 PoW。</li><li>通过新增一个交易授予矿工（自己）一个币。</li><li>构造新区块并将其添加到链中。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> textwrap <span class="keyword">import</span> dedent</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> uuid <span class="keyword">import</span> uuid4</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, jsonify, request</span><br><span class="line">...</span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> uuid <span class="keyword">import</span> uuid4</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, jsonify, request</span><br><span class="line">...</span><br><span class="line"><span class="meta">@app.route('/mine', methods=['GET'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mine</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># We run the proof of work algorithm to get the next proof...</span></span><br><span class="line">    last_block = blockchain.last_block</span><br><span class="line">    last_proof = last_block[<span class="string">'proof'</span>]</span><br><span class="line">    proof = blockchain.proof_of_work(last_proof)</span><br><span class="line">    <span class="comment"># 给工作量证明的节点提供奖励.</span></span><br><span class="line">    <span class="comment"># 发送者为 "0" 表明是新挖出的币</span></span><br><span class="line">    blockchain.new_transaction(</span><br><span class="line">        sender=<span class="string">"0"</span>,</span><br><span class="line">        recipient=node_identifier,</span><br><span class="line">        amount=<span class="number">1</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># Forge the new Block by adding it to the chain</span></span><br><span class="line">    block = blockchain.new_block(proof)</span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">'message'</span>: <span class="string">"New Block Forged"</span>,</span><br><span class="line">        <span class="string">'index'</span>: block[<span class="string">'index'</span>],</span><br><span class="line">        <span class="string">'transactions'</span>: block[<span class="string">'transactions'</span>],</span><br><span class="line">        <span class="string">'proof'</span>: block[<span class="string">'proof'</span>],</span><br><span class="line">        <span class="string">'previous_hash'</span>: block[<span class="string">'previous_hash'</span>],</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> jsonify(response), <span class="number">200</span></span><br></pre></td></tr></table></figure><p>注意交易的接收者是我们自己的服务器节点，我们做的大部分工作都只是围绕 Blockchain 类方法进行交互。到此，我们的区块链就算完成了，我们来实际运行下。</p><h3 id="运行区块链"><a href="#运行区块链" class="headerlink" title="运行区块链"></a>运行区块链</h3><p>你可以使用 cURL 或 Postman 去和 API 进行交互。</p><p><strong>启动 server：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ python blockchain.py</span><br><span class="line">* Runing on http://127.0.0.1:5000/ (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure><p><strong>让我们通过请求 <a href="http://localhost:5000/mine" target="_blank" rel="noopener">http://localhost:5000/mine</a> 来进行挖矿：</strong><br><img src="/images/blockchain-1.jpg" alt="blockchain-1"></p><p><strong>通过 post 请求，添加一个新交易：</strong><br><img src="/images/blockchain-2.jpg" alt="blockchain-2"></p><p><strong>如果不是使用 Postman，则用以下的 cURL 语句也是一样的：</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ curl -X POST -H <span class="string">"Content-Type: application/json"</span> -d <span class="string">'&#123;</span></span><br><span class="line"><span class="string"> "sender": "d4ee26eee15148ee92c6cd394edd974e",</span></span><br><span class="line"><span class="string"> "recipient": "someone-other-address",</span></span><br><span class="line"><span class="string"> "amount": 5</span></span><br><span class="line"><span class="string">&#125;'</span> <span class="string">"http://localhost:5000/transactions/new"</span></span><br></pre></td></tr></table></figure></p><p>在挖了两次矿之后，就有 3 个块了，通过请求 <a href="http://localhost:5000/chain" target="_blank" rel="noopener">http://localhost:5000/chain</a> 可以得到所有的块信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"chain"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"index"</span>: 1,</span><br><span class="line">      <span class="string">"previous_hash"</span>: 1,</span><br><span class="line">      <span class="string">"proof"</span>: 100,</span><br><span class="line">      <span class="string">"timestamp"</span>: 1506280650.770839,</span><br><span class="line">      <span class="string">"transactions"</span>: []</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"index"</span>: 2,</span><br><span class="line">      <span class="string">"previous_hash"</span>: <span class="string">"c099bc...bfb7"</span>,</span><br><span class="line">      <span class="string">"proof"</span>: 35293,</span><br><span class="line">      <span class="string">"timestamp"</span>: 1506280664.717925,</span><br><span class="line">      <span class="string">"transactions"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"amount"</span>: 1,</span><br><span class="line">          <span class="string">"recipient"</span>: <span class="string">"8bbcb347e0634905b0cac7955bae152b"</span>,</span><br><span class="line">          <span class="string">"sender"</span>: <span class="string">"0"</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"index"</span>: 3,</span><br><span class="line">      <span class="string">"previous_hash"</span>: <span class="string">"eff91a...10f2"</span>,</span><br><span class="line">      <span class="string">"proof"</span>: 35089,</span><br><span class="line">      <span class="string">"timestamp"</span>: 1506280666.1086972,</span><br><span class="line">      <span class="string">"transactions"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"amount"</span>: 1,</span><br><span class="line">          <span class="string">"recipient"</span>: <span class="string">"8bbcb347e0634905b0cac7955bae152b"</span>,</span><br><span class="line">          <span class="string">"sender"</span>: <span class="string">"0"</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"length"</span>: 3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="一致性（共识）"><a href="#一致性（共识）" class="headerlink" title="一致性（共识）"></a>一致性（共识）</h2><p>我们已经有了一个基本的区块链可以接受交易和挖矿，但是区块链系统应该是分布式的。</p><p>既然是分布式的，那么我们究竟拿什么保证所有节点有同样的链呢？这就是一致性问题，我们要想在网络上有多个节点，就必须实现一个一致性的算法。</p><h3 id="注册节点"><a href="#注册节点" class="headerlink" title="注册节点"></a>注册节点</h3><p>在实现一致性算法之前，我们需要找到一种方式让一个节点知道它相邻的节点。</p><p><strong>每个节点都需要保存一份包含网络中其他节点的记录，因此让我们新增几个接口：</strong></p><ul><li>/nodes/register 接收 URL 形式的新节点列表。</li><li>/nodes/resolve 执行一致性算法，解决任何冲突，确保节点拥有正确的链。</li></ul><p><strong>我们修改下 Blockchain 的 init 函数并提供一个注册节点方法：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line">...</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">        self.nodes = set()</span><br><span class="line">        ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">register_node</span><span class="params">(self, address)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Add a new node to the list of nodes</span></span><br><span class="line"><span class="string">        :param address: &lt;str&gt; Address of node. Eg. 'http://192.168.0.5:5000'</span></span><br><span class="line"><span class="string">        :return: None</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        parsed_url = urlparse(address)</span><br><span class="line">        self.nodes.add(parsed_url.netloc)</span><br></pre></td></tr></table></figure><p>我们用 set 来储存节点，这是一种避免重复添加节点的简单方法。</p><h3 id="实现共识算法"><a href="#实现共识算法" class="headerlink" title="实现共识算法"></a>实现共识算法</h3><p>前面提到，冲突是指不同的节点拥有不同的链，为了解决这个问题，规定最长的、有效的链才是最终的链，换句话说，网络中有效最长链才是实际的链。</p><p><strong>我们使用以下的算法，来达到网络中的共识：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blockchain</span><span class="params">(object)</span></span></span><br><span class="line"><span class="class">    ...</span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">valid_chain</span><span class="params">(self, chain)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Determine if a given blockchain is valid</span></span><br><span class="line"><span class="string">        :param chain: &lt;list&gt; A blockchain</span></span><br><span class="line"><span class="string">        :return: &lt;bool&gt; True if valid, False if not</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        last_block = chain[<span class="number">0</span>]</span><br><span class="line">        current_index = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> current_index &lt; len(chain):</span><br><span class="line">            block = chain[current_index]</span><br><span class="line">            print(<span class="string">f'<span class="subst">&#123;last_block&#125;</span>'</span>)</span><br><span class="line">            print(<span class="string">f'<span class="subst">&#123;block&#125;</span>'</span>)</span><br><span class="line">            print(<span class="string">"\n-----------\n"</span>)</span><br><span class="line">            <span class="comment"># Check that the hash of the block is correct</span></span><br><span class="line">            <span class="keyword">if</span> block[<span class="string">'previous_hash'</span>] != self.hash(last_block):</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            <span class="comment"># Check that the Proof of Work is correct</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.valid_proof(last_block[<span class="string">'proof'</span>], block[<span class="string">'proof'</span>]):</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            last_block = block</span><br><span class="line">            current_index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">resolve_conflicts</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        共识算法解决冲突</span></span><br><span class="line"><span class="string">        使用网络中最长的链.</span></span><br><span class="line"><span class="string">        :return: &lt;bool&gt; True 如果链被取代, 否则为False</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        neighbours = self.nodes</span><br><span class="line">        new_chain = <span class="keyword">None</span></span><br><span class="line">        <span class="comment"># We're only looking for chains longer than ours</span></span><br><span class="line">        max_length = len(self.chain)</span><br><span class="line">        <span class="comment"># Grab and verify the chains from all the nodes in our network</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> neighbours:</span><br><span class="line">            response = requests.get(<span class="string">f'http://<span class="subst">&#123;node&#125;</span>/chain'</span>)</span><br><span class="line">            <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">                length = response.json()[<span class="string">'length'</span>]</span><br><span class="line">                chain = response.json()[<span class="string">'chain'</span>]</span><br><span class="line">                <span class="comment"># Check if the length is longer and the chain is valid</span></span><br><span class="line">                <span class="keyword">if</span> length &gt; max_length <span class="keyword">and</span> self.valid_chain(chain):</span><br><span class="line">                    max_length = length</span><br><span class="line">                    new_chain = chain</span><br><span class="line">        <span class="comment"># Replace our chain if we discovered a new, valid chain longer than ours</span></span><br><span class="line">        <span class="keyword">if</span> new_chain:</span><br><span class="line">            self.chain = new_chain</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br></pre></td></tr></table></figure><p>第一个方法 valid_chain() 用来检查是否是有效链，遍历每个块验证 hash 和 proof。</p><p>第二个方法 resolve_conflicts() 用来解决冲突，遍历所有的邻居节点，并用上一个方法检查链的有效性， 如果发现有效更长链，就替换掉自己的链。</p><p>让我们添加两个路由，一个用来注册节点，一个用来解决冲突。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route('/nodes/register', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">register_nodes</span><span class="params">()</span>:</span></span><br><span class="line">    values = request.get_json()</span><br><span class="line">    nodes = values.get(<span class="string">'nodes'</span>)</span><br><span class="line">    <span class="keyword">if</span> nodes <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"Error: Please supply a valid list of nodes"</span>, <span class="number">400</span></span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">        blockchain.register_node(node)</span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">'message'</span>: <span class="string">'New nodes have been added'</span>,</span><br><span class="line">        <span class="string">'total_nodes'</span>: list(blockchain.nodes),</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> jsonify(response), <span class="number">201</span></span><br><span class="line"><span class="meta">@app.route('/nodes/resolve', methods=['GET'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consensus</span><span class="params">()</span>:</span></span><br><span class="line">    replaced = blockchain.resolve_conflicts()</span><br><span class="line">    <span class="keyword">if</span> replaced:</span><br><span class="line">        response = &#123;</span><br><span class="line">            <span class="string">'message'</span>: <span class="string">'Our chain was replaced'</span>,</span><br><span class="line">            <span class="string">'new_chain'</span>: blockchain.chain</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        response = &#123;</span><br><span class="line">            <span class="string">'message'</span>: <span class="string">'Our chain is authoritative'</span>,</span><br><span class="line">            <span class="string">'chain'</span>: blockchain.chain</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">return</span> jsonify(response), <span class="number">200</span></span><br></pre></td></tr></table></figure><p>你可以在不同的机器运行节点，或在一台机机开启不同的网络端口来模拟多节点的网络。</p><p><strong>这里在同一台机器开启不同的端口演示，在不同的终端运行以下命令，就启动了两个节点：</strong></p><ul><li><a href="http://localhost:5000" target="_blank" rel="noopener">http://localhost:5000</a> </li><li><a href="http://localhost:5001" target="_blank" rel="noopener">http://localhost:5001</a></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pipenv run python blockchain.py</span><br><span class="line">$ pipenv run python blockchain.py -p 5001</span><br></pre></td></tr></table></figure><p><img src="/images/blockchain-3.jpg" alt="blockchain-3"></p><p>然后在节点 2 上挖两个块，确保是更长的链，然后在节点 1 上访问接口 /nodes/resolve，这时节点 1 的链会通过共识算法被节点 2 的链取代。</p><p><img src="/images/blockchain-4.jpg" alt="blockchain-4"></p><p>好啦，你可以邀请朋友们一起来测试你的区块链。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是用Python建立一个区块链，初步了解区块链使用到的技术。&lt;/p&gt;
&lt;h2 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h2&gt;&lt;p&gt;本文要求读者对 Python 有基本
      
    
    </summary>
    
      <category term="用Python从0开始创建一个区块链" scheme="http://yoursite.com/categories/%E7%94%A8Python%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    
      <category term="Blockchain" scheme="http://yoursite.com/tags/Blockchain/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Flask" scheme="http://yoursite.com/tags/Flask/"/>
    
  </entry>
  
  <entry>
    <title>Gitlab踩坑升级过程</title>
    <link href="http://yoursite.com/2018/03/01/gitlab-update/"/>
    <id>http://yoursite.com/2018/03/01/gitlab-update/</id>
    <published>2018-02-28T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.822Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是Gitlab跨大版本更新，数据迁移备份过程记录</p><h2 id="背景简述"><a href="#背景简述" class="headerlink" title="背景简述"></a>背景简述</h2><p>由于各个项目迭代次数较多，Gitlab的服务器硬件相对较低，而且也出现过遇到当前Gitlab版本Bug的情况，所以最近就打算一次性把Gitlab迁移到配置较好的企业服务器并升级到最新版本。</p><p>目前原来版本是gitlab-ce-8.8.0.ce.0，现在最新的版本是gitlab-ce-10.5.2.ce.0，这次过程就是从8.8.0升级到10.5.2。</p><h2 id="Gitlab部署"><a href="#Gitlab部署" class="headerlink" title="Gitlab部署"></a>Gitlab部署</h2><ul><li>系统以CentOS7为例</li></ul><p>下载RPM包地址：<a href="https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/" target="_blank" rel="noopener">Gitlab-CE清华大学镜像站</a></p><h2 id="先安装依赖"><a href="#先安装依赖" class="headerlink" title="先安装依赖"></a>先安装依赖</h2><p>参考<a href="https://about.gitlab.com/downloads/#centos7" target="_blank" rel="noopener">官方说明</a>中的Install and configure the necessary dependencies一节。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ yum install curl policycoreutils openssh-server openssh-clients</span><br><span class="line">$ systemctl <span class="built_in">enable</span> sshd</span><br><span class="line">$ systemctl start sshd</span><br><span class="line">$ yum install postfix</span><br><span class="line">$ systemctl <span class="built_in">enable</span> postfix</span><br><span class="line">$ systemctl start postfix</span><br><span class="line">$ firewall-cmd --permanent --add-service=http</span><br><span class="line">$ systemctl reload firewalld</span><br></pre></td></tr></table></figure><h2 id="下载与原来版本一致的RPM包"><a href="#下载与原来版本一致的RPM包" class="headerlink" title="下载与原来版本一致的RPM包"></a>下载与原来版本一致的RPM包</h2><p>这里我先记录如何进行数据迁移，<strong>数据迁移必须使用版本一致的gitlab</strong>，跨版本的数据恢复可能会报错。</p><h3 id="先下载gitlab-ce-8-8-0-ce-0"><a href="#先下载gitlab-ce-8-8-0-ce-0" class="headerlink" title="先下载gitlab-ce-8.8.0.ce.0"></a>先下载gitlab-ce-8.8.0.ce.0</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 下载</span></span><br><span class="line">$ wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-8.8.0-ce.0.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装</span></span><br><span class="line">$ rpm -i gitlab-ce-8.8.0-ce.0.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="修改配置文件-etc-gitlab-gitlab-rb"><a href="#修改配置文件-etc-gitlab-gitlab-rb" class="headerlink" title="修改配置文件(/etc/gitlab/gitlab.rb)"></a>修改配置文件(/etc/gitlab/gitlab.rb)</h2><p>修改配置项：</p><ul><li><p>域名：external_url ‘<a href="http://gitlab.rd.exmaple.com" target="_blank" rel="noopener">http://gitlab.rd.exmaple.com</a>‘</p></li><li><p>时区：gitlab_rails[‘time_zone’] = ‘Asia/Shanghai’</p></li><li><p>通知发送的邮箱: gitlab_rails[‘gitlab_email_from’] = ‘gitlab-notifications@example.com’</p></li><li><p>修改SMTP服务器配置：gitlab_rails[‘smtp*’]</p></li><li><p>仓库路径：git_data_dir “/home/gitlab/git-data”</p><ul><li>注意，不支持符号链接</li></ul></li></ul><p>参见：<a href="https://github.com/Polaris0112/Ops-Tools/blob/master/gitlab/gitlab.rb" target="_blank" rel="noopener">配置文件</a></p><p><strong>另外留意配置文件的权限问题</strong></p><p>正确的是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正确的是</span></span><br><span class="line"><span class="comment"># -rw-------. 1 root root 20227 Feb 28 16:59 gitlab.rb</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改权限命令</span></span><br><span class="line">$ chmod 600 /etc/gitlab/gitlab.rb</span><br></pre></td></tr></table></figure><h2 id="编译部署"><a href="#编译部署" class="headerlink" title="编译部署"></a>编译部署</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译</span></span><br><span class="line">$ gitlab-ctl reconfigure</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启服务</span></span><br><span class="line">$ gitlab-ctl restart</span><br></pre></td></tr></table></figure><h2 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h2><h3 id="配置文件中相关的选项"><a href="#配置文件中相关的选项" class="headerlink" title="配置文件中相关的选项"></a>配置文件中相关的选项</h3><ul><li><p>备份目录：<code>gitlab_rails[&#39;backup_path&#39;] = &quot;/home/gitlab/backups&quot;</code></p></li><li><p>备份文件保存时长: <code>gitlab_rails[&#39;backup_keep_time&#39;] = 604800</code></p></li></ul><h3 id="手动命令操作备份"><a href="#手动命令操作备份" class="headerlink" title="手动命令操作备份"></a>手动命令操作备份</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab-rake gitlab:backup:create</span><br></pre></td></tr></table></figure><h2 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h2><p><strong>大致来说：</strong></p><ul><li><p>需保证gitlab版本和备份时一致</p></li><li><p>需要启动服务，但停掉前台和队列，以防止用户操作干扰</p></li><li><p>从备份机或者原本服务器上提取备份压缩包，传输至新服务器</p></li><li><p>把备份文件放到/var/opt/gitlab/backups/路径下</p></li><li><p>跑恢复脚本gitlab-rake gitlab:backup:restore，指定时间戳参数BACKUP</p></li><li><p>把服务都启动</p></li><li><p>检查确认</p></li></ul><h3 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h3><p>详细说明可参考官方文档中的<a href="https://gitlab.com/gitlab-org/gitlab-ce/blob/master/doc/raketasks/backup_restore.md#restore-a-previously-created-backup" target="_blank" rel="noopener">Backup restore - Restore a previously created backup</a>一节。下面是原文，源代码部署部分省略掉了：</p><p>停前台服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab-ctl stop unicorn</span><br><span class="line">$ gitlab-ctl stop sidekiq</span><br><span class="line">$ gitlab-ctl stop nginx</span><br></pre></td></tr></table></figure><p>恢复对应时间戳备份的数据(<strong>注意：以下命令的压缩文件、服务器IP、时间戳均需要替换指定的环境中具体的值</strong>)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从旧服务器找到备份文件并scp到新服务器</span></span><br><span class="line">$ scp 1519857115_gitlab_backup.tar 192.168.0.85:./</span><br><span class="line"></span><br><span class="line"><span class="comment"># 到新服务器把压缩文件移动到指定路径下并修改所属用户</span></span><br><span class="line">$ mv 1519857115_gitlab_backup.tar /var/opt/gitlab/backups/</span><br><span class="line">$ chown -R git:git /var/opt/gitlab/backups</span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复备份</span></span><br><span class="line">$ gitlab-rake gitlab:backup:restore BACKUP=1519857115</span><br><span class="line"></span><br><span class="line"><span class="comment">## 恢复过程中需要交互两次，均输入yes继续即可。</span></span><br></pre></td></tr></table></figure><p>启动服务、检查：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab-ctl restart</span><br><span class="line">$ gitlab-rake gitlab:check SANITIZE=<span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="远程备份"><a href="#远程备份" class="headerlink" title="远程备份"></a>远程备份</h2><p>远程备份</p><ul><li><p>开源的auto-gitlab-backup项目可以完成一般备份和/etc/gitlab/*备份，以及同步到远端的工作。</p></li><li><p>用crontab触发每日定时执行备份</p></li><li><p>参见: <a href="https://github.com/Polaris0112/Ops-Tools/blob/master/gitlab/auto-gitlab-backup.conf" target="_blank" rel="noopener">配置文件</a></p></li></ul><h2 id="更新Gitlab"><a href="#更新Gitlab" class="headerlink" title="更新Gitlab"></a>更新Gitlab</h2><h3 id="先关闭前端服务，防止用户人为操作"><a href="#先关闭前端服务，防止用户人为操作" class="headerlink" title="先关闭前端服务，防止用户人为操作"></a>先关闭前端服务，防止用户人为操作</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab-ctl stop unicorn</span><br><span class="line">$ gitlab-ctl stop sidekiq</span><br><span class="line">$ gitlab-ctl stop nginx</span><br></pre></td></tr></table></figure><p>执行完毕后，原本gitlab网页应该就不能访问，用户也不能拉取或者提交代码。</p><h3 id="下载新版Gitlab并更新"><a href="#下载新版Gitlab并更新" class="headerlink" title="下载新版Gitlab并更新"></a>下载新版Gitlab并更新</h3><p>这里要注意的是，跨版本更新不能跨两个大版本，即8.8.0不能直接升级到10.5.2，升级后会因为PostgreSQL数据库会启动失败导致页面出现502，部分服务不能启动。</p><p>所以我们要一级一级升，目前确认的是可以先从8.8.0升级到9.5.9然后再升级到10.5.2<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果怕担心升级失败的话，可以先升级一个小版本进行测试</span></span><br><span class="line"><span class="comment"># $ wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-8.8.1-ce.0.el7.x86_64.rpm</span></span><br><span class="line"><span class="comment"># $ rpm -Uvh gitlab-ce-8.8.1-ce.0.el7.x86_64.rpm</span></span><br><span class="line"><span class="comment"># 等待一段时间</span></span><br><span class="line"><span class="comment"># 执行完成后，重新配置gitlab</span></span><br><span class="line"><span class="comment"># $ gitlab-ctl reconfigure</span></span><br><span class="line"><span class="comment"># 完成后重启gitlab</span></span><br><span class="line"><span class="comment"># $ gitlab-ctl restart</span></span><br><span class="line"><span class="comment"># 启动完需要等服务启动一分钟左右后，才登陆网页查看</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 直接升级到9.5.9</span></span><br><span class="line">$ wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-9.5.9-ce.0.el7.x86_64.rpm</span><br><span class="line">$ rpm- Uvh gitlab-ce-9.5.9-ce.0.el7.x86_64.rpm</span><br><span class="line"><span class="comment"># 等待一段时间</span></span><br><span class="line"><span class="comment"># 执行完成后，重新配置gitlab</span></span><br><span class="line">$ gitlab-ctl reconfigure</span><br><span class="line"><span class="comment"># 完成后重启gitlab</span></span><br><span class="line">$ gitlab-ctl restart</span><br><span class="line"><span class="comment">## 然后查看页面有没有更新成功</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 若成功，则重复第一步</span></span><br><span class="line">$ gitlab-ctl stop unicorn</span><br><span class="line">$ gitlab-ctl stop sidekiq</span><br><span class="line">$ gitlab-ctl stop nginx</span><br><span class="line"></span><br><span class="line">$ wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-10.5.2-ce.0.el7.x86_64.rpm</span><br><span class="line">$ rpm -Uvh gitlab-ce-10.5.2-ce.0.el7.x86_64.rpm</span><br><span class="line">$ gitlab-ctl reconfigure</span><br><span class="line">$ gitlab-ctl restart</span><br></pre></td></tr></table></figure></p><p>所有执行完成后，等待服务启动一分钟以后就可以开启网页查看gitlab是否更新成功。</p><h2 id="踩过的坑"><a href="#踩过的坑" class="headerlink" title="踩过的坑"></a>踩过的坑</h2><h3 id="编译GitLab出现ruby-block-supervise-redis-sleep-action-run并卡住"><a href="#编译GitLab出现ruby-block-supervise-redis-sleep-action-run并卡住" class="headerlink" title="编译GitLab出现ruby_block[supervise_redis_sleep] action run并卡住"></a>编译GitLab出现ruby_block[supervise_redis_sleep] action run并卡住</h3><p>解决方案：</p><ul><li><p>按住CTRL+C强制结束</p></li><li><p>运行<code>systemctl restart gitlab-runsvdir</code></p></li><li><p>再次执行<code>gitlab-ctl reconfigure</code></p></li></ul><p><a href="https://gitlab.com/gitlab-org/omnibus-gitlab/issues/160" target="_blank" rel="noopener">解决方案来源</a></p><h2 id="完整卸载gitlab"><a href="#完整卸载gitlab" class="headerlink" title="完整卸载gitlab"></a>完整卸载gitlab</h2><ul><li>停止gitlab</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitlab-ctl stop</span><br></pre></td></tr></table></figure><ul><li>卸载gitlab</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ rpm -e gitlab-ce</span><br></pre></td></tr></table></figure><ul><li>查看gitlab进程</li></ul><p>kill掉所有的gitlab进程</p><p>确认所有gitlab进程已经被删除</p><ul><li>删除gitlab文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ find / -name gitlab|xargs rm -rf    <span class="comment"># 删除所有包含gitlab的文件及目录</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是Gitlab跨大版本更新，数据迁移备份过程记录&lt;/p&gt;
&lt;h2 id=&quot;背景简述&quot;&gt;&lt;a href=&quot;#背景简述&quot; class=&quot;headerlink&quot; title=&quot;背景简述&quot;&gt;&lt;/a&gt;背景简述&lt;/h2&gt;&lt;p&gt;由于各个项目迭代次数较多，Gitlab的服务器硬
      
    
    </summary>
    
      <category term="Gitlab升级" scheme="http://yoursite.com/categories/Gitlab%E5%8D%87%E7%BA%A7/"/>
    
    
      <category term="Gitlab" scheme="http://yoursite.com/tags/Gitlab/"/>
    
      <category term="Update" scheme="http://yoursite.com/tags/Update/"/>
    
      <category term="Migration" scheme="http://yoursite.com/tags/Migration/"/>
    
  </entry>
  
  <entry>
    <title>Zabbix汉化字体修改</title>
    <link href="http://yoursite.com/2018/02/28/zabbix-fonts/"/>
    <id>http://yoursite.com/2018/02/28/zabbix-fonts/</id>
    <published>2018-02-27T16:00:00.000Z</published>
    <updated>2018-03-07T04:00:43.907Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是Zabbix3.4安装后，设置为中文环境，但是查看”图形”监控的时候图形下方的图例中文也会出现乱码（方块），所以需要修改字体文件来显示正常中文。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>Zabbix的图形显示用的字体是dejavu，不支持中文。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="Zabbix3-2-x以及之前的解决方法"><a href="#Zabbix3-2-x以及之前的解决方法" class="headerlink" title="Zabbix3.2.x以及之前的解决方法"></a>Zabbix3.2.x以及之前的解决方法</h3><p>这个版本之前的都是放在Web服务的文件夹中，比如</p><ul><li><p>nginx：使用这个Web服务的路径在(yum安装)<code>/usr/share/nginx/html/</code>目录下，(编译安装)自定义目录路径下。</p></li><li><p>apache：使用这个Web服务的路径在(默认路径)<code>/var/www/html/</code>目录下。</p></li></ul><p>这两个Web服务的文件下一般都会有一个zabbix的文件(或者叫其他名字)，然后里面的<code>/path/zabbix/fonts/</code>目录下会有一个叫<code>DejaVuSans.ttf</code>的文件。</p><p>因为前端的php已经默认了使用<code>DejaVuSans.ttf</code>这个文件作为字体文件，所以我们可以不修改php，把我们想要的字体改成对应的名字就行。</p><p><a href="https://github.com/Polaris0112/Ops-Tools/raw/master/zabbix_installation/MSYH.TTF" target="_blank" rel="noopener">微软雅黑</a>  &lt;–这个是我从Windows7中导出来的微软雅黑字体，亲测可用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 然后把这个字体先复制`/path/zabbix/fonts`下，下面以nginx为例</span></span><br><span class="line">$ cp MSYH.TTF /usr/share/nginx/html/zabbix/fonts/</span><br><span class="line"></span><br><span class="line"><span class="comment">## 更改原本字体文件名作为备份</span></span><br><span class="line">$ mv /usr/share/nginx/html/zabbix/fonts/DejaVuSans.ttf /usr/share/nginx/html/zabbix/fonts/DejaVuSans.ttf.bak</span><br><span class="line"></span><br><span class="line"><span class="comment">## 把新的字体改到对应的字体文件名</span></span><br><span class="line">$ mv /usr/share/nginx/html/zabbix/fonts/MSYH.TTF /usr/share/nginx/html/zabbix/fonts/DejaVuSans.ttf</span><br></pre></td></tr></table></figure><p>无需重启服务，直接刷新网页端即可。</p><h3 id="Zabbix3-4-x的解决方法"><a href="#Zabbix3-4-x的解决方法" class="headerlink" title="Zabbix3.4.x的解决方法"></a>Zabbix3.4.x的解决方法</h3><p>以下方法使用的是用yum方法安装Zabbix3.4.7之后修改字体，测试通过。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 先下载字体，如上</span></span><br><span class="line">$ wget https://github.com/Polaris0112/Ops-Tools/raw/master/zabbix_installation/MSYH.TTF</span><br><span class="line">$ mv MSYH.TTF /usr/share/fonts/MSYH.TTF</span><br><span class="line"></span><br><span class="line"><span class="comment">## zabbix配置文件(/usr/share/zabbix/include/defines.inc.php)里，定义的字体叫做graphfont.ttf</span></span><br><span class="line"><span class="comment">## 然后一路软链接到DejaVuSans.ttf，如下：</span></span><br><span class="line"><span class="comment">## /usr/share/zabbix/graphfont.ttf -&gt; /etc/alternatives/zabbix-web-font -&gt; /usr/share/fonts/dejavu/DejaVuSans.ttf</span></span><br><span class="line"><span class="comment">## 那么，修改掉最后一层软连接的目标字体就可以了。执行类似下面的命令就可以了。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 先备份原有字体</span></span><br><span class="line">$ mv /etc/alternatives/zabbix-web-font /etc/alternatives/zabbix-web-font_bak </span><br><span class="line"></span><br><span class="line"><span class="comment">## 创建新增软连接</span></span><br><span class="line">$ ln -s /usr/share/fonts/MSYH.TTF /etc/alternatives/zabbix-web-font</span><br></pre></td></tr></table></figure><p>无需重启服务，直接刷新网页端即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是Zabbix3.4安装后，设置为中文环境，但是查看”图形”监控的时候图形下方的图例中文也会出现乱码（方块），所以需要修改字体文件来显示正常中文。&lt;/p&gt;
&lt;h2 id=&quot;原因&quot;&gt;&lt;a href=&quot;#原因&quot; class=&quot;headerlink&quot; title=&quot;原
      
    
    </summary>
    
      <category term="Zabbix汉化字体修改" scheme="http://yoursite.com/categories/Zabbix%E6%B1%89%E5%8C%96%E5%AD%97%E4%BD%93%E4%BF%AE%E6%94%B9/"/>
    
    
      <category term="Zabbix" scheme="http://yoursite.com/tags/Zabbix/"/>
    
      <category term="Font" scheme="http://yoursite.com/tags/Font/"/>
    
  </entry>
  
  <entry>
    <title>浅析僵尸进程与孤儿进程</title>
    <link href="http://yoursite.com/2018/02/28/zombie-process-and-orphaned-process/"/>
    <id>http://yoursite.com/2018/02/28/zombie-process-and-orphaned-process/</id>
    <published>2018-02-27T16:00:00.000Z</published>
    <updated>2018-03-07T06:21:58.550Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是理解僵尸进程和孤儿进程的产生原因</p><h2 id="知识背景"><a href="#知识背景" class="headerlink" title="知识背景"></a>知识背景</h2><p>在被誉为UNIX编程“圣经”的一书《unix环境高级编程》中有提到僵尸进程和孤儿进程。不少同学对这两个概念会混淆，这篇文章总结一下。</p><p>在unix/linux系统中，大多情况下，子进程是通过父进程fork创建的，注：系统调用fork，是一个比较有意思系统调用，它调用一次，返回两个值，失败返回-1,成功时在子进程返回0，父进程返回所创建子进程的pid。本文暂时只需了解这些就够了，有兴趣的同学可以查阅man文档，描述的非常清楚。</p><p>子进程创建后，子进程的结束和父进程的运行是一个异步过程,也就是说父进程没办法预测子进程什么时候结束。 当一个子进程完成它的工作终止之后，其父进程需要调用wait()或waitpid()去获取子进程的终止状态。</p><h2 id="孤儿进程"><a href="#孤儿进程" class="headerlink" title="孤儿进程"></a>孤儿进程</h2><p>首先来认识下什么叫孤儿进程，所谓孤儿进程，顾名思义，和现实生活中的孤儿有点类似，当一个进程的<code>父进程结束</code>时，但是它自己还没有结束，那么这个进程将会成为孤儿进程。最后孤儿进程将会被<code>init进程</code>（进程号为1）的进程收养，当然在子进程结束时也会由init进程完成对它的状态收集工作，因此一般来说，孤儿进程并不会有什么危害。</p><p>下面看一个关于<strong>孤儿进程</strong>的例子：在main函数中，创建子进程，然后让父进程睡眠1s，让子进程先运行打印出其进程id(pid)以及父进程id(ppid)；随后子进程睡眠3s（此时会调度到父进程运行直至结束），目的是<code>让父进程先于子进程结束</code>，让子进程有个孤儿的状态；最后子进程再打印出其进程id(pid)以及父进程id(ppid)；观察两次打印 其父进程id(ppid)的区别。</p><p><img src="/images/orphaned-process-1.jpg" alt="orphaned-process-1"></p><p><img src="/images/orphaned-process-2.jpg" alt="orphaned-process-2"></p><p>从运行结果来看：当其父进程结束后，子进程成为了孤儿进程，其父进程id(ppid)为1，也就是说，init进程成为该子进程的父进程了。</p><h2 id="僵尸进程"><a href="#僵尸进程" class="headerlink" title="僵尸进程"></a>僵尸进程</h2><p>好了，说完了孤儿进程，再来谈谈僵尸进程，其实对于这2两个概念（指孤儿进程与僵尸进程）不少人容易混淆，其实如果仔细理解的话，还是很容易区分的。</p><p>僵尸进程是指：一个进程使用fork创建子进程，如果<strong>子进程退出</strong>，而父进程并<code>没有调用</code>wait或waitpid获取子进程的状态信息，那么子进程的某些信息如进程描述符仍然保存在系统中。这种进程称之为僵死进程。</p><p>下面是1个关于<strong>僵尸进程</strong>的例子：在main函数中，创建子进程，然后让父进程睡眠10s，让子进程先终止（注意和孤儿进程例子的区别）；这里子进程结束后父进程没有调用wait/waitpid函数获取其状态，用ps查看进程状态可以看出子进程为僵尸状态。</p><p><img src="/images/zombie-process-1.jpg" alt="zombie-process-1"></p><p><img src="/images/zombie-process-2.jpg" alt="zombie-process-2"></p><p><img src="/images/zombie-process-3.jpg" alt="zombie-process-3"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注：任何一个子进程(init除外)在<span class="built_in">exit</span>()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个子进程在结束时都要经过的阶段。如果子进程在<span class="built_in">exit</span>()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。  如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。</span><br></pre></td></tr></table></figure><p>讲了僵尸进程产生的原因，再来讲讲僵尸进程的危害：僵尸进程会在系统中保留其某些信息如进程描述符、进程id等等。以进程id为例，系统中可用的进程id是有限的，如果由于系统中大量的僵尸进程占用进程id，就会导致因为没有可用的进程id系统不能产生新的进程，这种问题可就大了，这就是僵尸进程带来的危害。</p><h2 id="如何杀死僵尸进程"><a href="#如何杀死僵尸进程" class="headerlink" title="如何杀死僵尸进程"></a>如何杀死僵尸进程</h2><p>如上可知，僵尸进程一旦出现之后，很难自己消亡，会一直存在下去，直至系统重启。虽然僵尸进程几乎不占系统资源，但是，这样下去，数量太多了之后，终究会给系统带来其他的影响。</p><p>请注意：defunct状态下的僵尸进程是不能直接使用kill -9命令杀掉的，否则就不叫僵尸进程了。</p><p><strong>解决方法</strong>：</p><ul><li><p>重启服务器，这个是最简单，最易用的方法，但是如果你服务器电脑上运行有其他的程序，那么这个方法，代价很大。所以，尽量使用下面一种方法。</p></li><li><p>找到该defunct僵尸进程的父进程，将该进程的父进程杀掉，则此defunct进程将自动消失。</p></li></ul><p>参考命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ps -ef | grep defunct_process_pid</span><br></pre></td></tr></table></figure><h2 id="如何预防僵尸进程"><a href="#如何预防僵尸进程" class="headerlink" title="如何预防僵尸进程"></a>如何预防僵尸进程</h2><p>以上介绍的只是在发现了僵尸进程之后，如何去杀死它。那么，有同学可能会说了，这个是治标不治本的。真正的办法是，不让它产生，问题才能彻底解决。</p><ul><li><p>在父进程创建子进程之前，就向系统申明自己并不会对这个子进程的exit动作进行任何关注行为，这样的话，子进程一旦退出后，系统就不会去等待父进程的操作，而是直接将该子进程的资源回收掉，也就不会出现僵尸进程了。具体的办法就是，在父进程的初始化函数中，调用这个函数：signal(SIGCHLD,SIG_IGN)；</p></li><li><p>如果上述语句没来得及调用，也有另外一个办法。那就是在创建完子进程后，用waitpid等待子进程返回，也能达到上述效果；</p></li><li><p>如果上述两个办法都不愿意采用，那还有一招：在父进程创建子进程的时候，连续调用两次fork()，而且使紧跟的子进程直接退出，使其孙子进程成为孤儿进程，从而init进程将代替父进程来接手，负责清除这个孤儿进程。于是，父进程就无需进行任何的清理行为，系统会自动处理；</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是理解僵尸进程和孤儿进程的产生原因&lt;/p&gt;
&lt;h2 id=&quot;知识背景&quot;&gt;&lt;a href=&quot;#知识背景&quot; class=&quot;headerlink&quot; title=&quot;知识背景&quot;&gt;&lt;/a&gt;知识背景&lt;/h2&gt;&lt;p&gt;在被誉为UNIX编程“圣经”的一书《unix环境高级编程》中有
      
    
    </summary>
    
      <category term="浅析僵尸进程与孤儿进程" scheme="http://yoursite.com/categories/%E6%B5%85%E6%9E%90%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B/"/>
    
    
      <category term="Zombie Process" scheme="http://yoursite.com/tags/Zombie-Process/"/>
    
      <category term="Orphaned Process" scheme="http://yoursite.com/tags/Orphaned-Process/"/>
    
  </entry>
  
  <entry>
    <title>NFS安装部署</title>
    <link href="http://yoursite.com/2018/02/27/nfs-installation/"/>
    <id>http://yoursite.com/2018/02/27/nfs-installation/</id>
    <published>2018-02-26T16:00:00.000Z</published>
    <updated>2018-03-06T09:48:07.668Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是在CentOS7系统中安装NFS网络文件存储系统</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>CentOS7</li></ul><h3 id="1-关闭系统防火墙和selinux"><a href="#1-关闭系统防火墙和selinux" class="headerlink" title="1.关闭系统防火墙和selinux"></a>1.关闭系统防火墙和selinux</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl status firewalld</span><br><span class="line">firewalld.service - firewalld - dynamic firewall daemon</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled)</span><br><span class="line">   Active: active (running) since Sat 2017-06-03 09:38:00 CST; 8s ago</span><br><span class="line">     Docs: man:firewalld(1)</span><br><span class="line"> Main PID: 24067 (firewalld)</span><br><span class="line">   CGroup: /system.slice/firewalld.service</span><br><span class="line">           └─24067 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid</span><br><span class="line"></span><br><span class="line">Jun 03 09:37:58 linuxidc systemd[1]: Starting firewalld - dynamic firewall daemon...</span><br><span class="line">Jun 03 09:38:00 linuxidc systemd[1]: Started firewalld - dynamic firewall daemon.</span><br><span class="line"></span><br><span class="line"><span class="comment">## 关闭防火墙</span></span><br><span class="line">$ systemctl stop firewalld</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 把selinux设为许可模式</span></span><br><span class="line">$ setenforce 0</span><br><span class="line"></span><br><span class="line"><span class="comment">## 要想禁用selinux,则需要编辑selinux的配置文件,把SELINUX设置成disabled,然后重启生效</span></span><br><span class="line">$ vi /etc/sysconfig/selinux</span><br><span class="line"><span class="comment"># This file controls the state of SELinux on the system.</span></span><br><span class="line"><span class="comment"># SELINUX= can take one of these three values:</span></span><br><span class="line"><span class="comment">#     enforcing - SELinux security policy is enforced.</span></span><br><span class="line"><span class="comment">#     permissive - SELinux prints warnings instead of enforcing.</span></span><br><span class="line"><span class="comment">#     disabled - No SELinux policy is loaded.</span></span><br><span class="line">SELINUX=disabled</span><br><span class="line"><span class="comment"># SELINUXTYPE= can take one of three two values:</span></span><br><span class="line"><span class="comment">#     targeted - Targeted processes are protected,</span></span><br><span class="line"><span class="comment">#     minimum - Modification of targeted policy. Only selected processes are protected. </span></span><br><span class="line"><span class="comment">#     mls - Multi Level Security protection.</span></span><br><span class="line">SELINUXTYPE=targeted</span><br></pre></td></tr></table></figure><h3 id="2-安装所需的软件包"><a href="#2-安装所需的软件包" class="headerlink" title="2.安装所需的软件包"></a>2.安装所需的软件包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y rpc-bind nfs-utils</span><br></pre></td></tr></table></figure><h3 id="3-服务端配置"><a href="#3-服务端配置" class="headerlink" title="3.服务端配置"></a>3.服务端配置</h3><p>NFS服务的主要配置文件为 /etc/exports.<br>/etc/exports文件内容格式：</p><ul><li>&lt;输出目录&gt; 客户端（选项:访问权限,用户映射,其他]<ul><li>输出目录是指NFS系统中所定义的共享给客户端使用的文件系统</li><li>客户端是定义网络中可以访问这个NFS共享目录的IP地址或网段或域名等</li><li>客户端常用的指定方式<ul><li>指定ip地址的主机：192.168.100.1</li><li>指定一个子网：192.168.100.0/24 也可以写成:192.168.100.0/255.255.255.0</li><li>指定域名的主机：david.bsmart.cn</li><li>指定域中的所有主机：*.bsmart.cn</li><li>所有主机：*</li></ul></li></ul></li><li>选项用来设置输出目录的访问权限、用户映射等。</li><li>NFS主要有3类选项：<ul><li>设置输出目录只读：ro</li><li>设置输出目录读写：rw</li></ul></li><li>用户映射选项<ul><li>all_squash：将远程访问的所有普通用户及所属组都映射为匿名用户或用户组（nfsnobody）；</li><li>no_all_squash：与all_squash取反（默认设置）；</li><li>root_squash：将root用户及所属组都映射为匿名用户或用户组（默认设置）；</li><li>no_root_squash：与rootsquash取反；</li><li>anonuid=xxx：将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用户（UID=xxx）；</li><li>anongid=xxx：将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户（GID=xxx）；</li></ul></li><li>其它选项<ul><li>secure：限制客户端只能从小于1024的tcp/ip端口连接nfs服务器（默认设置）；</li><li>insecure：允许客户端从大于1024的tcp/ip端口连接服务器；</li><li>sync：将数据同步写入内存缓冲区与磁盘中，效率低，但可以保证数据的一致性；</li><li>async：将数据先保存在内存缓冲区中，必要时才写入磁盘；</li><li>wdelay：检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率（默认设置）；</li><li>no_wdelay：若有写操作则立即执行，应与sync配合使用；</li><li>subtree：若输出目录是一个子目录，则nfs服务器将检查其父目录的权限(默认设置)；</li><li>no_subtree：即使输出目录是一个子目录，nfs服务器也不检查其父目录的权限，这样可以提高效率；<br>-修改/etc/exports文件,定义NFS共享</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 先创建本地目录并把共享目录的权限设定为所有用户都可读可写权限</span></span><br><span class="line">$ mkdir -p /data</span><br><span class="line">$ chmod 766 /data</span><br><span class="line"></span><br><span class="line"><span class="comment">## 修改NFS配置文件,定义共享</span></span><br><span class="line">$ vi /etc/exports</span><br><span class="line">/data *(rw,sync)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 把RPCbind加入开机处启动选项中</span></span><br><span class="line">$ systemctl <span class="built_in">enable</span> rpcbind </span><br><span class="line"></span><br><span class="line"><span class="comment">## 启动RPCbind</span></span><br><span class="line">$ systemctl start rpcbind</span><br><span class="line"></span><br><span class="line"><span class="comment">## 把NFS加入到开机自启动选项中</span></span><br><span class="line">$ systemctl <span class="built_in">enable</span> nfs</span><br><span class="line"></span><br><span class="line"><span class="comment">## 开启NFS服务</span></span><br><span class="line">$ systemctl start nfs</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看本机共享的文件系统</span></span><br><span class="line">$ exportfs</span><br></pre></td></tr></table></figure><h2 id="客户端配置（以下操作均在客户端上）"><a href="#客户端配置（以下操作均在客户端上）" class="headerlink" title="客户端配置（以下操作均在客户端上）"></a>客户端配置（以下操作均在客户端上）</h2><h3 id="1-客户端关闭防火墙和selinux-方法同上"><a href="#1-客户端关闭防火墙和selinux-方法同上" class="headerlink" title="1.客户端关闭防火墙和selinux,方法同上."></a>1.客户端关闭防火墙和selinux,方法同上.</h3><h3 id="2-客户端安装NFS软件包-并把NFS服务设为开机自启动-方法同上"><a href="#2-客户端安装NFS软件包-并把NFS服务设为开机自启动-方法同上" class="headerlink" title="2.客户端安装NFS软件包,并把NFS服务设为开机自启动,方法同上."></a>2.客户端安装NFS软件包,并把NFS服务设为开机自启动,方法同上.</h3><h3 id="3-挂载共享的NFS文件系统"><a href="#3-挂载共享的NFS文件系统" class="headerlink" title="3.挂载共享的NFS文件系统"></a>3.挂载共享的NFS文件系统</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 把服务端(192.168.0.100)的共享目录挂载到本机的/share上</span></span><br><span class="line">$ mkdir -p /upload</span><br><span class="line">$ mount 192.168.0.100:/data /share</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看是否已经挂载成功</span></span><br><span class="line">$ mount | grep media</span><br><span class="line">192.168.0.100:/data on /share <span class="built_in">type</span> nfs4 (rw,relatime,vers=4.0,rsize=131072,wsize=131072,namlen=255,hard,prot</span><br><span class="line"></span><br><span class="line"><span class="comment">## 把共享目录写入系统挂载文件系统</span></span><br><span class="line">$ vi /etc/fstab</span><br><span class="line">192.168.16.29:/data        /share      nfs4    defaults    0 0</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="1-在服务端共享目录中新建一个10M大小的文件"><a href="#1-在服务端共享目录中新建一个10M大小的文件" class="headerlink" title="1.在服务端共享目录中新建一个10M大小的文件"></a>1.在服务端共享目录中新建一个10M大小的文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 在NFS共享目录上新建一个10M大小的文件,提示成功</span></span><br><span class="line">$ <span class="built_in">cd</span> /data</span><br><span class="line">$ dd <span class="keyword">if</span>=/dev/zero of=/data/f1 bs=1M count=10</span><br><span class="line">$ ll -h</span><br><span class="line">total 10M</span><br><span class="line">-rw-r--r--. 1 root root 10M Mar  6 10:14 f1</span><br></pre></td></tr></table></figure><h3 id="2-在客户端新建另一个文件f2-同时尝试删除另一个文件f1"><a href="#2-在客户端新建另一个文件f2-同时尝试删除另一个文件f1" class="headerlink" title="2.在客户端新建另一个文件f2,同时尝试删除另一个文件f1"></a>2.在客户端新建另一个文件f2,同时尝试删除另一个文件f1</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /share</span><br><span class="line">$ ls</span><br><span class="line">f1</span><br><span class="line"></span><br><span class="line"><span class="comment">## 在共享目录上新建一个文件f2,未报错</span></span><br><span class="line">$ touch f2</span><br><span class="line"><span class="comment">## 删除存在的文件f1,未报错</span></span><br><span class="line">$ rm -f f1</span><br></pre></td></tr></table></figure><h3 id="3-在服务端查看共享目录中的文件"><a href="#3-在服务端查看共享目录中的文件" class="headerlink" title="3.在服务端查看共享目录中的文件"></a>3.在服务端查看共享目录中的文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls</span><br><span class="line">f2</span><br></pre></td></tr></table></figure><p>部署完毕。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是在CentOS7系统中安装NFS网络文件存储系统&lt;/p&gt;
&lt;h2 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;CentOS7&lt;/li&gt;
&lt;/ul
      
    
    </summary>
    
      <category term="NFS安装部署" scheme="http://yoursite.com/categories/NFS%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="NFS" scheme="http://yoursite.com/tags/NFS/"/>
    
      <category term="CentOS" scheme="http://yoursite.com/tags/CentOS/"/>
    
  </entry>
  
  <entry>
    <title>Zabbix性能优化</title>
    <link href="http://yoursite.com/2018/02/26/zabbix-optimization/"/>
    <id>http://yoursite.com/2018/02/26/zabbix-optimization/</id>
    <published>2018-02-25T16:00:00.000Z</published>
    <updated>2018-03-06T08:29:46.634Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是从多个方面优化Zabbix性能，使其能监控大量服务器。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>由于计划日益增加的服务器数量，所以需要监控系统的性能可以跟上处理数量庞大的服务器数据。因此需要对Zabbix服务端进行性能优化。</p><p>主要优化有几方面：</p><p>一、从软件设置层面来看，Zabbix的C-S模式收集数据主要分为被动模式和主动模式，当选择被动模式的时候，是服务端根据主机列表来逐个请求数据，这样的话当客户端数量越来越大，那么服务端接受对应数据的间隔也会越来越长从而导致数据延迟。另一个模式是主动模式，在这个模式下，服务端设置好监控项之后，客户端（配置文件中设置好开启主动模式）就会请求服务端的监控列表，然后客户端会对应这个监控列表上的监控项进行数据收集并主动发送给服务端。这样，服务端只需要提供一个监控列表，就可能让客户端自行提取，服务端不需要等待返回数据，而是客户端直接把数据发回服务端，这样可以大大减少服务端的网络请求的压力。</p><p>二、从软件架构层面来看，对于大量的服务器，我们可以使用Zabbix-Proxy这个服务，这个服务本意是监控客户端与服务端在不同内网的情况使用的，不过用上Zabbix-Proxy之后，它也算是一个服务端，只不过它不会有前端界面，它只是负责统一接收客户端数据并发送给服务端，这样的话可以大大减少服务端处理数据的压力。</p><p>三、从数据版本和引擎层面来看，本人会建议使用Percona+TokuDB的组合。MySQL 4和5使用默认的MyISAM存储引擎安装每个表。从5.5开始，MySQL已将默认存储引擎从MyISAM更改为InnoDB。MyISAM没有提供事务支持，而InnoDB提供了事务支持。与MyISAM相比，InnoDB提供了许多细微的性能改进，并且在处理潜在的数据丢失时提供了更高的可靠性和安全性。Percona XtraDB 是 InnoDB 存储引擎的增强版，被设计用来更好的使用更新计算机硬件系统的性能，同时还包含有一些在高性能环境下的新特性。XtraDB 存储引擎是完全的向下兼容，在 MariaDB 中，XtraDB 存储引擎被标识为”ENGINE=InnoDB”，这个与 InnoDB 是一样的，所以你可以直接用XtraDB 替换掉 InnoDB 而不会产生任何问题。Percona XtraDB 包含有所有 InnoDB 健壮性，可依赖的 ACID 兼容设计和高级 MVCC 架构。XtraDB 在 InnoDB 的坚实基础上构建，使 XtraDB 具有更多的特性，更好调用，更多的参数指标和更多的扩展。从实践的角度来看，XtraDB 被设计用来在多核心的条件下更有效的使用内存和更加方便，更加可用。新的特性被用来降低 InnoDB 的局限性。性能层面，XtraDB与内置的MySQL 5.1 InnoDB 引擎相比，它每分钟可处理2.7倍的事务。同时，按照官方的介绍，TokuDB 引擎是可扩展的，支持事务 ACID 特性，支持多版本控制(MVCC)，这几点等同 InnoDB 的特性，不过对基于索引的查询做了很好的改进，还提供了支持在线表更改的支持(不是所有字段都支持， 后面再说明)，在磁盘和缓存方面也做了很好的改进。TokuDB 结合 松散树索引(Fractal Tree indexing)，可以应用于高负载的大量写(write-intensive)的场景里。对于这个组合，本人觉得很适合运用在Zabbix这种若有大量数据刷新写入的场景里面使用。</p><p>四、从数据库表层面来看，可以把Zabbix中的几个大表进行表分区。Zabbix的大表有：</p><ul><li>history</li><li>history_log</li><li>history_str</li><li>history_text</li><li>history_uint</li><li>trends</li><li>trends_uint</li></ul><p>第一个方案在客户端的配置文件找到<code>ServerActive</code>并填入服务器IP作为值，重启客户端则开启了主动模式，然后在Web端对应的监控项修改属性，改成主动模式即可</p><p>第二个方案可以参考<a href="https://polaris0112.github.io/2018/02/25/zabbix-yum-installation/" target="_blank" rel="noopener">《Zabbix YUM方式部署》</a>最后有提及到Zabbix-Proxy的部署方式</p><h2 id="安装部署Percona-TokuDB引擎"><a href="#安装部署Percona-TokuDB引擎" class="headerlink" title="安装部署Percona+TokuDB引擎"></a>安装部署Percona+TokuDB引擎</h2><p>关于Percona的安装教程可以参考<a href="https://polaris0112.github.io/2018/02/25/zabbix-source-installation/" target="_blank" rel="noopener">《Zabbix 编译安装部署》</a>中的<code>安装Percona Mysql数据库(比原生Mysql性能更优)</code>部分，对应安装即可。</p><p>不过除了安装主要的Percona数据库以外，还要下载TokuDB插件以及其依赖jemalloc 3.3.0以上版本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y jemalloc-devel.x86_64</span><br><span class="line">$ yum install -y Percona-Server-tokudb-57</span><br></pre></td></tr></table></figure></p><p>（弃用）关闭Transparent Huge Pages(THP)<br>Percona安装TokuDB已经默认配置，不需要单独配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">test</span> -f /sys/kernel/mm/transparent_hugepage/enabled; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">test</span> -f /sys/kernel/mm/transparent_hugepage/defrag; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p><p>假设你的Percona已经正常运行（并且设置好root密码），那么可以执行以下命令安装TokuDB插件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ ps_tokudb_admin --<span class="built_in">enable</span> -uroot -p</span><br><span class="line"><span class="comment">#password</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#然后会出现一些日志信息，有可能会出现以下信息</span></span><br><span class="line"><span class="comment">#PLEASE RESTART MYSQL SERVICE AND RUN THIS SCRIPT AGAIN TO FINISH INSTALLATION!</span></span><br><span class="line"><span class="comment">#按照提示，重启mysql，然后再跑多一次这个命令</span></span><br><span class="line"></span><br><span class="line">$ systemctl restart mysql</span><br><span class="line">$ ps_tokudb_admin --<span class="built_in">enable</span> -uroot -p</span><br><span class="line"><span class="comment">#password</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#出现信息</span></span><br><span class="line"><span class="comment">#Installing TokuDB engine...</span></span><br><span class="line"><span class="comment">#INFO: Successfully installed TokuDB engine plugin.</span></span><br><span class="line"><span class="comment">#即为安装成功</span></span><br></pre></td></tr></table></figure></p><p>查看是否已经安装成功<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -u root -p</span><br><span class="line"><span class="comment">#password</span></span><br><span class="line"></span><br><span class="line">mysql &gt; show engines;</span><br><span class="line">+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+</span><br><span class="line">| Engine             | Support | Comment                                                                    | Transactions | XA   | Savepoints |</span><br><span class="line">+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+</span><br><span class="line">| MEMORY             | YES     | Hash based, stored <span class="keyword">in</span> memory, useful <span class="keyword">for</span> temporary tables                  | NO           | NO   | NO         |</span><br><span class="line">| CSV                | YES     | CSV storage engine                                                         | NO           | NO   | NO         |</span><br><span class="line">| MyISAM             | YES     | MyISAM storage engine                                                      | NO           | NO   | NO         |</span><br><span class="line">| BLACKHOLE          | YES     | /dev/null storage engine (anything you write to it disappears)             | NO           | NO   | NO         |</span><br><span class="line">| PERFORMANCE_SCHEMA | YES     | Performance Schema                                                         | NO           | NO   | NO         |</span><br><span class="line">| TokuDB             | YES     | Percona TokuDB Storage Engine with Fractal Tree(tm) Technology             | YES          | YES  | YES        |</span><br><span class="line">| MRG_MYISAM         | YES     | Collection of identical MyISAM tables                                      | NO           | NO   | NO         |</span><br><span class="line">| ARCHIVE            | YES     | Archive storage engine                                                     | NO           | NO   | NO         |</span><br><span class="line">| InnoDB             | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES          | YES  | YES        |</span><br><span class="line">| FEDERATED          | NO      | Federated MySQL storage engine                                             | NULL         | NULL | NULL       |</span><br><span class="line">+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+</span><br><span class="line"></span><br><span class="line"><span class="comment">#见到Engine一列中有TokuDB则是安装成功</span></span><br></pre></td></tr></table></figure></p><h2 id="卸载TokuDB方法"><a href="#卸载TokuDB方法" class="headerlink" title="卸载TokuDB方法"></a>卸载TokuDB方法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ ps_tokudb_admin --<span class="built_in">disable</span> -uroot -p</span><br><span class="line"><span class="comment">#password</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动卸载插件</span></span><br><span class="line">$ mysql -u root -p</span><br><span class="line"><span class="comment">#password</span></span><br><span class="line"></span><br><span class="line">mysql &gt; UNINSTALL PLUGIN tokudb;</span><br><span class="line">mysql &gt; UNINSTALL PLUGIN tokudb_file_map;</span><br><span class="line">mysql &gt; UNINSTALL PLUGIN tokudb_fractal_tree_info;</span><br><span class="line">mysql &gt; UNINSTALL PLUGIN tokudb_fractal_tree_block_map;</span><br><span class="line">mysql &gt; UNINSTALL PLUGIN tokudb_trx;</span><br><span class="line">mysql &gt; UNINSTALL PLUGIN tokudb_locks;</span><br><span class="line">mysql &gt; UNINSTALL PLUGIN tokudb_lock_waits;</span><br><span class="line">mysql &gt; UNINSTALL PLUGIN tokudb_background_job_status;</span><br></pre></td></tr></table></figure><p>以上命令跑完即可卸载tokudb插件。</p><h2 id="修改Zabbix部分表的引擎"><a href="#修改Zabbix部分表的引擎" class="headerlink" title="修改Zabbix部分表的引擎"></a>修改Zabbix部分表的引擎</h2><p>这步操作的前提是已经做好Zabbix数据库初始化的步骤，详细可以参考<a href="https://polaris0112.github.io/2018/02/25/zabbix-yum-installation/" target="_blank" rel="noopener">《Zabbix YUM方式部署》</a>或者<a href="https://polaris0112.github.io/2018/02/25/zabbix-source-installation/" target="_blank" rel="noopener">《Zabbix 编译安装部署》</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -u zabbix -p zabbix</span><br><span class="line"><span class="comment">#zabbix mysql password</span></span><br><span class="line"></span><br><span class="line">mysql &gt; alter table <span class="built_in">history</span> engine = <span class="string">'TOKUDB'</span>;</span><br><span class="line">mysql &gt; alter table history_log engine = <span class="string">'TOKUDB'</span>;</span><br><span class="line">mysql &gt; alter table history_str engine = <span class="string">'TOKUDB'</span>;</span><br><span class="line">mysql &gt; alter table history_text engine = <span class="string">'TOKUDB'</span>;</span><br><span class="line">mysql &gt; alter table history_uint engine = <span class="string">'TOKUDB'</span>;</span><br><span class="line">mysql &gt; alter table trends engine = <span class="string">'TOKUDB'</span>;</span><br><span class="line">mysql &gt; alter table trends_uint engine = <span class="string">'TOKUDB'</span>;</span><br></pre></td></tr></table></figure><p>操作完成后，zabbix的数据库大表的引擎将会改用tokudb，性能更佳。</p><h2 id="把Zabbix数据库中需要经常操作的大表进行表分区"><a href="#把Zabbix数据库中需要经常操作的大表进行表分区" class="headerlink" title="把Zabbix数据库中需要经常操作的大表进行表分区"></a>把Zabbix数据库中需要经常操作的大表进行表分区</h2><p><strong>分表前提</strong></p><ul><li><p>按时间范围分表（字段clock，字段无索引）</p></li><li><p>MySQL分区表要求范围字段是唯一索引或主键索引，或者是其中一部分，需要修改前核实clock是否在索引中</p></li></ul><h3 id="创建4个存储过程"><a href="#创建4个存储过程" class="headerlink" title="创建4个存储过程"></a>创建4个存储过程</h3><p>存储过程1</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">DELIMITER $$</span><br><span class="line">CREATE PROCEDURE `partition_create`(SCHEMANAME varchar(64), TABLENAME varchar(64), PARTITIONNAME varchar(64), CLOCK int)</span><br><span class="line">BEGIN</span><br><span class="line">        /*</span><br><span class="line">           SCHEMANAME = The DB schema <span class="keyword">in</span> <span class="built_in">which</span> to make changes</span><br><span class="line">           TABLENAME = The table with partitions to potentially delete</span><br><span class="line">           PARTITIONNAME = The name of the partition to create</span><br><span class="line">        */</span><br><span class="line">        /*</span><br><span class="line">           Verify that the partition does not already exist</span><br><span class="line">        */</span><br><span class="line"></span><br><span class="line">        DECLARE RETROWS INT;</span><br><span class="line">        SELECT COUNT(1) INTO RETROWS</span><br><span class="line">        FROM information_schema.partitions</span><br><span class="line">        WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_description &gt;= CLOCK;</span><br><span class="line"></span><br><span class="line">        IF RETROWS = 0 THEN</span><br><span class="line">        /*</span><br><span class="line">           1. Print a message indicating that a partition was created.</span><br><span class="line">           2. Create the SQL to create the partition.</span><br><span class="line">           3. Execute the SQL from <span class="comment">#2.</span></span><br><span class="line">        */</span><br><span class="line">        SELECT CONCAT( <span class="string">"partition_create("</span>, SCHEMANAME, <span class="string">","</span>, TABLENAME, <span class="string">","</span>, PARTITIONNAME, <span class="string">","</span>, CLOCK, <span class="string">")"</span> ) AS msg;</span><br><span class="line">        SET @sql = CONCAT( <span class="string">'ALTER TABLE '</span>, SCHEMANAME, <span class="string">'.'</span>, TABLENAME, <span class="string">' ADD PARTITION (PARTITION '</span>, PARTITIONNAME, <span class="string">' VALUES LESS THAN ('</span>, CLOCK, <span class="string">'));'</span> );</span><br><span class="line">        PREPARE STMT FROM @sql;</span><br><span class="line">        EXECUTE STMT;</span><br><span class="line">        DEALLOCATE PREPARE STMT;</span><br><span class="line">        END IF;</span><br><span class="line">END$$</span><br><span class="line">DELIMITER ;</span><br></pre></td></tr></table></figure><p>存储过程2</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">DELIMITER $$</span><br><span class="line">CREATE PROCEDURE `partition_drop`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), DELETE_BELOW_PARTITION_DATE BIGINT)</span><br><span class="line">BEGIN</span><br><span class="line">        /*</span><br><span class="line">           SCHEMANAME = The DB schema <span class="keyword">in</span> <span class="built_in">which</span> to make changes</span><br><span class="line">           TABLENAME = The table with partitions to potentially delete</span><br><span class="line">           DELETE_BELOW_PARTITION_DATE = Delete any partitions with names that are dates older than this one (yyyy-mm-dd)</span><br><span class="line">        */</span><br><span class="line">        DECLARE <span class="keyword">done</span> INT DEFAULT FALSE;</span><br><span class="line">        DECLARE drop_part_name VARCHAR(16);</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">           Get a list of all the partitions that are older than the date</span><br><span class="line">           <span class="keyword">in</span> DELETE_BELOW_PARTITION_DATE.  All partitions are prefixed with</span><br><span class="line">           a <span class="string">"p"</span>, so use SUBSTRING TO get rid of that character.</span><br><span class="line">        */</span><br><span class="line">        DECLARE myCursor CURSOR FOR</span><br><span class="line">        SELECT partition_name</span><br><span class="line">        FROM information_schema.partitions</span><br><span class="line">        WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND CAST(SUBSTRING(partition_name FROM 2) AS UNSIGNED) &lt; DELETE_BELOW_PARTITION_DATE;</span><br><span class="line">        DECLARE CONTINUE HANDLER FOR NOT FOUND SET <span class="keyword">done</span> = TRUE;</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">           Create the basics <span class="keyword">for</span> when we need to drop the partition.  Also, create</span><br><span class="line">           @drop_partitions to hold a comma-delimited list of all partitions that</span><br><span class="line">           should be deleted.</span><br><span class="line">        */</span><br><span class="line">        SET @alter_header = CONCAT(<span class="string">"ALTER TABLE "</span>, SCHEMANAME, <span class="string">"."</span>, TABLENAME, <span class="string">" DROP PARTITION "</span>);</span><br><span class="line">        SET @drop_partitions = <span class="string">""</span>;</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">           Start looping through all the partitions that are too old.</span><br><span class="line">        */</span><br><span class="line">        OPEN myCursor;</span><br><span class="line">        read_loop: LOOP</span><br><span class="line">        FETCH myCursor INTO drop_part_name;</span><br><span class="line">        IF <span class="keyword">done</span> THEN</span><br><span class="line">    LEAVE read_loop;</span><br><span class="line">        END IF;</span><br><span class="line">        SET @drop_partitions = IF(@drop_partitions = <span class="string">""</span>, drop_part_name, CONCAT(@drop_partitions, <span class="string">","</span>, drop_part_name));</span><br><span class="line">        END LOOP;</span><br><span class="line">        IF @drop_partitions != <span class="string">""</span> THEN</span><br><span class="line">        /*</span><br><span class="line">           1. Build the SQL to drop all the necessary partitions.</span><br><span class="line">           2. Run the SQL to drop the partitions.</span><br><span class="line">           3. Print out the table partitions that were deleted.</span><br><span class="line">        */</span><br><span class="line">        SET @full_sql = CONCAT(@alter_header, @drop_partitions, <span class="string">";"</span>);</span><br><span class="line">        PREPARE STMT FROM @full_sql;</span><br><span class="line">        EXECUTE STMT;</span><br><span class="line">        DEALLOCATE PREPARE STMT;</span><br><span class="line"></span><br><span class="line">        SELECT CONCAT(SCHEMANAME, <span class="string">"."</span>, TABLENAME) AS `table`, @drop_partitions AS `partitions_deleted`;</span><br><span class="line">        ELSE</span><br><span class="line">        /*</span><br><span class="line">           No partitions are being deleted, so <span class="built_in">print</span> out <span class="string">"N/A"</span> (Not applicable) to indicate</span><br><span class="line">           that no changes were made.</span><br><span class="line">        */</span><br><span class="line">        SELECT CONCAT(SCHEMANAME, <span class="string">"."</span>, TABLENAME) AS `table`, <span class="string">"N/A"</span> AS `partitions_deleted`;</span><br><span class="line">        END IF;</span><br><span class="line">END$$</span><br><span class="line">DELIMITER ;</span><br></pre></td></tr></table></figure><p>存储过程3</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">DELIMITER $$</span><br><span class="line">CREATE PROCEDURE `partition_maintenance`(SCHEMA_NAME VARCHAR(32), TABLE_NAME VARCHAR(32), KEEP_DATA_DAYS INT, HOURLY_INTERVAL INT, CREATE_NEXT_INTERVALS INT)</span><br><span class="line">BEGIN</span><br><span class="line">        DECLARE OLDER_THAN_PARTITION_DATE VARCHAR(16);</span><br><span class="line">        DECLARE PARTITION_NAME VARCHAR(16);</span><br><span class="line">        DECLARE OLD_PARTITION_NAME VARCHAR(16);</span><br><span class="line">        DECLARE LESS_THAN_TIMESTAMP INT;</span><br><span class="line">        DECLARE CUR_TIME INT;</span><br><span class="line"></span><br><span class="line">        CALL partition_verify(SCHEMA_NAME, TABLE_NAME, HOURLY_INTERVAL);</span><br><span class="line">        SET CUR_TIME = UNIX_TIMESTAMP(DATE_FORMAT(NOW(), <span class="string">'%Y-%m-%d 00:00:00'</span>));</span><br><span class="line"></span><br><span class="line">        SET @__interval = 1;</span><br><span class="line">        create_loop: LOOP</span><br><span class="line">        IF @__interval &gt; CREATE_NEXT_INTERVALS THEN</span><br><span class="line">    LEAVE create_loop;</span><br><span class="line">        END IF;</span><br><span class="line"></span><br><span class="line">        SET LESS_THAN_TIMESTAMP = CUR_TIME + (HOURLY_INTERVAL * @__interval * 3600);</span><br><span class="line">        SET PARTITION_NAME = FROM_UNIXTIME(CUR_TIME + HOURLY_INTERVAL * (@__interval - 1) * 3600, <span class="string">'p%Y%m%d%H00'</span>);</span><br><span class="line">        IF(PARTITION_NAME != OLD_PARTITION_NAME) THEN</span><br><span class="line">    CALL partition_create(SCHEMA_NAME, TABLE_NAME, PARTITION_NAME, LESS_THAN_TIMESTAMP);</span><br><span class="line">        END IF;</span><br><span class="line">        SET @__interval=@__interval+1;</span><br><span class="line">        SET OLD_PARTITION_NAME = PARTITION_NAME;</span><br><span class="line">        END LOOP;</span><br><span class="line"></span><br><span class="line">        SET OLDER_THAN_PARTITION_DATE=DATE_FORMAT(DATE_SUB(NOW(), INTERVAL KEEP_DATA_DAYS DAY), <span class="string">'%Y%m%d0000'</span>);</span><br><span class="line">        CALL partition_drop(SCHEMA_NAME, TABLE_NAME, OLDER_THAN_PARTITION_DATE);</span><br><span class="line"></span><br><span class="line">END$$</span><br><span class="line">DELIMITER ;</span><br></pre></td></tr></table></figure><p>存储过程4</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">DELIMITER $$</span><br><span class="line">CREATE PROCEDURE `partition_verify`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), HOURLYINTERVAL INT(11))</span><br><span class="line">BEGIN</span><br><span class="line">        DECLARE PARTITION_NAME VARCHAR(16);</span><br><span class="line">        DECLARE RETROWS INT(11);</span><br><span class="line">        DECLARE FUTURE_TIMESTAMP TIMESTAMP;</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">         * Check <span class="keyword">if</span> any partitions exist <span class="keyword">for</span> the given SCHEMANAME.TABLENAME.</span><br><span class="line">         */</span><br><span class="line">        SELECT COUNT(1) INTO RETROWS</span><br><span class="line">        FROM information_schema.partitions</span><br><span class="line">        WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_name IS NULL;</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">         * If partitions <span class="keyword">do</span> not exist, go ahead and partition the table</span><br><span class="line">         */</span><br><span class="line">        IF RETROWS = 1 THEN</span><br><span class="line">        /*</span><br><span class="line">         * Take the current date at 00:00:00 and add HOURLYINTERVAL to it.  This is the timestamp below <span class="built_in">which</span> we will store values.</span><br><span class="line">         * We begin partitioning based on the beginning of a day.  This is because we don<span class="string">'t want to generate a random partition</span></span><br><span class="line"><span class="string">         * that won'</span>t necessarily fall <span class="keyword">in</span> line with the desired partition naming (ie: <span class="keyword">if</span> the hour interval is 24 hours, we could</span><br><span class="line">         * end up creating a partition now named <span class="string">"p201403270600"</span> when all other partitions will be like <span class="string">"p201403280000"</span>).</span><br><span class="line">         */</span><br><span class="line">        SET FUTURE_TIMESTAMP = TIMESTAMPADD(HOUR, HOURLYINTERVAL, CONCAT(CURDATE(), <span class="string">" "</span>, <span class="string">'00:00:00'</span>));</span><br><span class="line">        SET PARTITION_NAME = DATE_FORMAT(CURDATE(), <span class="string">'p%Y%m%d%H00'</span>);</span><br><span class="line"></span><br><span class="line">        -- Create the partitioning query</span><br><span class="line">        SET @__PARTITION_SQL = CONCAT(<span class="string">"ALTER TABLE "</span>, SCHEMANAME, <span class="string">"."</span>, TABLENAME, <span class="string">" PARTITION BY RANGE(`clock`)"</span>);</span><br><span class="line">        SET @__PARTITION_SQL = CONCAT(@__PARTITION_SQL, <span class="string">"(PARTITION "</span>, PARTITION_NAME, <span class="string">" VALUES LESS THAN ("</span>, UNIX_TIMESTAMP(FUTURE_TIMESTAMP), <span class="string">"));"</span>);</span><br><span class="line"></span><br><span class="line">        -- Run the partitioning query</span><br><span class="line">        PREPARE STMT FROM @__PARTITION_SQL;</span><br><span class="line">        EXECUTE STMT;</span><br><span class="line">        DEALLOCATE PREPARE STMT;</span><br><span class="line">        END IF;</span><br><span class="line">END$$</span><br><span class="line">DELIMITER ;</span><br></pre></td></tr></table></figure><h3 id="存储过程中有四个功能："><a href="#存储过程中有四个功能：" class="headerlink" title="存储过程中有四个功能："></a>存储过程中有四个功能：</h3><ul><li><p>partition_create - 这将在给定模式中的给定表上创建一个分区。</p></li><li><p>partition_drop - 这将删除给定模式中给定表上给定时间戳的分区。</p></li><li><p>partition_maintenance - 此功能是用户调用的。它负责解析给定的参数，然后根据需要创建/删除分区。</p></li><li><p>partition_verify - 检查给定模式中给定表上是否启用了分区。如果没有启用，它将创建一个单独的分区。</p></li></ul><p><strong>partition_create</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">程序定义：partition_create（SCHEMANAME varchar（64），TABLENAME varchar（64），PARTITIONNAME varchar（64），CLOCK int）</span><br><span class="line">示例：CALL partition_create（“zabbix”，“<span class="built_in">history</span>”，“p20131216”，1387267200）;</span><br><span class="line">SCHEMANAME =要在其中进行更改的DB模式</span><br><span class="line">TABLENAME =要在其上创建PARTITIONNAME的表</span><br><span class="line">PARTITIONNAME =要创建的分区的名称</span><br><span class="line">将创建CLOCK = PARTITIONNAME以保存“clock”列值小于此值的值</span><br></pre></td></tr></table></figure></p><p><strong>partition_drop</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">过程定义：partition_drop（SCHEMANAME VARCHAR（64），TABLENAME VARCHAR（64），DELETE_BELOW_PARTITION_DATE VARCHAR（64））</span><br><span class="line">示例：CALL partition_drop（“zabbix”，“<span class="built_in">history</span>”，“20131216”）;</span><br><span class="line">SCHEMANAME =要在其中进行更改的DB模式</span><br><span class="line">TABLENAME =要删除PARTITIONNAME的表</span><br><span class="line">DELETE_BELOW_PARTITION_DATE =允许的最旧分区日期。所有旧版本的分区将被删除。格式为yyyymmdd。</span><br></pre></td></tr></table></figure></p><p><strong>partition_maintenance</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">过程定义：partition_maintenance（SCHEMA_NAME VARCHAR（32），TABLE_NAME VARCHAR（32），KEEP_DATA_DAYS INT，HOURLY_INTERVAL INT，CREATE_NEXT_INTERVALS INT）</span><br><span class="line">示例：CALL partition_maintenance（<span class="string">'zabbix'</span>，<span class="string">'history'</span>，28，24，14 ）;</span><br><span class="line">SCHEMA_NAME =要在其中进行更改的DB模式</span><br><span class="line">TABLE_NAME =要进行更改的表</span><br><span class="line">KEEP_DATA_DAYS =要保留的分区的最大天数。所有超过此天数的分区将被删除。</span><br><span class="line">HOURLY_INTERVAL =分区之间的小时间隔。例如，每日分区的值为24，小时分区的值为1。</span><br><span class="line">CREATE_NEXT_INTERVALS =提前创建的值的分区数。</span><br></pre></td></tr></table></figure></p><p><strong>partition_verify</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">过程定义：partition_verify（SCHEMANAME VARCHAR（64），TABLENAME VARCHAR（64），HOURLYINTERVAL INT（11））</span><br><span class="line">示例：CALL partition_verify（“zabbix”，“<span class="built_in">history</span>”）;</span><br><span class="line">SCHEMANAME =要在其中进行更改的DB模式</span><br><span class="line">TABLENAME =要检查分区的表</span><br><span class="line">HOURLY_INTERVAL =分区之间的小时间隔。例如，每日分区的值为24，小时分区的值为1。</span><br></pre></td></tr></table></figure></p><h3 id="分区表需求"><a href="#分区表需求" class="headerlink" title="分区表需求"></a>分区表需求</h3><ul><li><p>每月一个分区（24小时*31约等于720小时）</p></li><li><p>历史保存1年数据（12个月）</p></li><li><p>趋势保存2年数据（24个月）</p></li><li><p>未来周期12个（未来12个月）</p></li></ul><p>单独语句：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql &gt; CALL partition_maintenance(<span class="string">'zabbix'</span>, <span class="string">'history'</span>, 24, 720, 12);</span><br><span class="line">mysql &gt; CALL partition_maintenance(zabbix, <span class="string">'trends'</span>, 48, 720, 12);</span><br></pre></td></tr></table></figure></p><p>解释：创建24个分区，其中未来月份12个，每个周期存储720小时数据</p><h3 id="添加以下存储过程，用来增加新的分区和删除旧的分区"><a href="#添加以下存储过程，用来增加新的分区和删除旧的分区" class="headerlink" title="添加以下存储过程，用来增加新的分区和删除旧的分区"></a>添加以下存储过程，用来增加新的分区和删除旧的分区</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DELIMITER $$</span><br><span class="line">CREATE PROCEDURE `partition_maintenance_all`(SCHEMA_NAME VARCHAR(32))</span><br><span class="line">BEGIN</span><br><span class="line">    CALL partition_maintenance(SCHEMA_NAME, <span class="string">'history'</span>, 24, 720, 12);</span><br><span class="line">    CALL partition_maintenance(SCHEMA_NAME, <span class="string">'history_log'</span>, 24, 720, 12);</span><br><span class="line">    CALL partition_maintenance(SCHEMA_NAME, <span class="string">'history_str'</span>, 24, 720, 12);</span><br><span class="line">    CALL partition_maintenance(SCHEMA_NAME, <span class="string">'history_text'</span>, 24, 720, 12);</span><br><span class="line">    CALL partition_maintenance(SCHEMA_NAME, <span class="string">'history_uint'</span>, 24, 720, 12);</span><br><span class="line">    CALL partition_maintenance(SCHEMA_NAME, <span class="string">'trends'</span>, 48, 720, 12);</span><br><span class="line">    CALL partition_maintenance(SCHEMA_NAME, <span class="string">'trends_uint'</span>, 48, 720, 12);</span><br><span class="line">END$$</span><br><span class="line">DELIMITER ;</span><br></pre></td></tr></table></figure><p>存储过程文件下载：<br><a href="https://raw.githubusercontent.com/Polaris0112/Ops-Tools/master/zabbix_installation/partition_call.sql" target="_blank" rel="noopener">partition_call.sql</a></p><p><a href="https://raw.githubusercontent.com/Polaris0112/Ops-Tools/master/zabbix_installation/partition_all.sql" target="_blank" rel="noopener">partition_all.sql</a></p><p>导入mysql数据库中<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -u zabbix -p zabbix &lt; partition_call.sql</span><br><span class="line"><span class="comment">#zabbix mysql password</span></span><br><span class="line"></span><br><span class="line">$ mysql -u zabbix -p zabbix &lt; partition_all.sql</span><br><span class="line"><span class="comment">#zabbix mysql password</span></span><br></pre></td></tr></table></figure></p><p>直接执行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -u zabbix -p zabbix -e <span class="string">"call partition_maintenance_all('zabbix');"</span></span><br><span class="line"><span class="comment">#zabbix mysql password</span></span><br></pre></td></tr></table></figure></p><p>执行后，观察分区表状态是否建立</p><h3 id="定时调用此存储过程"><a href="#定时调用此存储过程" class="headerlink" title="定时调用此存储过程"></a>定时调用此存储过程</h3><p>用来增加新的分区和删除旧的分区，注意定时调用的间隔不能小于每次创建的未来的分区周期，如上情况，<strong>最少12个月调用一次</strong></p><p>创建调用脚本：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vim /root/shell/create_partition.sh</span><br><span class="line">/opt/tokudb/mysql/bin/mysql -uzabbix -pzabbix zabbix -e <span class="string">"call partition_maintenance_all('zabbix');"</span></span><br></pre></td></tr></table></figure></p><p>crontab -e 加入以下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 3 * */10 * sh /root/shell/create_partition.sh</span><br></pre></td></tr></table></figure></p><h3 id="关闭housekeeper功能"><a href="#关闭housekeeper功能" class="headerlink" title="关闭housekeeper功能"></a>关闭housekeeper功能</h3><p>在网页端的<strong>管理</strong> –&gt; <strong>一般</strong> ，页面右上下拉菜单选择<strong>管家</strong>，然后把开启内部管家的勾选去掉，再点击<strong>更新</strong>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是从多个方面优化Zabbix性能，使其能监控大量服务器。&lt;/p&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;由于计划日益增加的服务器数量，所以需要监控系统的性能可以
      
    
    </summary>
    
      <category term="Zabbix性能优化" scheme="http://yoursite.com/categories/Zabbix%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="Zabbix" scheme="http://yoursite.com/tags/Zabbix/"/>
    
      <category term="Optimization" scheme="http://yoursite.com/tags/Optimization/"/>
    
  </entry>
  
  <entry>
    <title>MyISAM和InnoDB区别详解</title>
    <link href="http://yoursite.com/2018/02/26/myisam-innodb/"/>
    <id>http://yoursite.com/2018/02/26/myisam-innodb/</id>
    <published>2018-02-25T16:00:00.000Z</published>
    <updated>2018-03-06T08:37:49.364Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是MySQL存储引擎中的MyISAM和InnoDB区别详解</p><h2 id="知识背景"><a href="#知识背景" class="headerlink" title="知识背景"></a>知识背景</h2><p>在使用MySQL的过程中对MyISAM和InnoDB这两个概念存在了些疑问，到底两者引擎有何分别一直是存在我心中的疑问。</p><ul><li><p>MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。不过，在这几年的发展下，MySQL也导入了InnoDB（另一种数据库引擎），以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。</p></li><li><p>InnoDB，是MySQL的数据库引擎之一，为MySQL AB发布binary的标准之一。InnoDB由Innobase Oy公司所开发，2006年五月时由甲骨文公司并购。与传统的ISAM与MyISAM相比，InnoDB的最大特色就是支持了ACID兼容的事务（Transaction）功能，类似于PostgreSQL。目前InnoDB采用双轨制授权，一是GPL授权，另一是专有软件授权。</p></li></ul><h2 id="MyISAM与InnoDB的区别是什么？"><a href="#MyISAM与InnoDB的区别是什么？" class="headerlink" title="MyISAM与InnoDB的区别是什么？"></a>MyISAM与InnoDB的区别是什么？</h2><h3 id="1、-存储结构"><a href="#1、-存储结构" class="headerlink" title="1、 存储结构"></a>1、 存储结构</h3><p>MyISAM：每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。</p><p>InnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。</p><h3 id="2、-存储空间"><a href="#2、-存储空间" class="headerlink" title="2、 存储空间"></a>2、 存储空间</h3><p>MyISAM：可被压缩，存储空间较小。支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。</p><p>InnoDB：需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。</p><h3 id="3、-可移植性、备份及恢复"><a href="#3、-可移植性、备份及恢复" class="headerlink" title="3、 可移植性、备份及恢复"></a>3、 可移植性、备份及恢复</h3><p>MyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。</p><p>InnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。</p><h3 id="4、-事务支持"><a href="#4、-事务支持" class="headerlink" title="4、 事务支持"></a>4、 事务支持</h3><p>MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。</p><p>InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。</p><h3 id="5、-AUTO-INCREMENT"><a href="#5、-AUTO-INCREMENT" class="headerlink" title="5、 AUTO_INCREMENT"></a>5、 AUTO_INCREMENT</h3><p>MyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。</p><p>InnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。</p><h3 id="6、-表锁差异"><a href="#6、-表锁差异" class="headerlink" title="6、 表锁差异"></a>6、 表锁差异</h3><p>MyISAM：只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。</p><p>InnoDB：支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。</p><h3 id="7、-全文索引"><a href="#7、-全文索引" class="headerlink" title="7、 全文索引"></a>7、 全文索引</h3><p>MyISAM：支持 FULLTEXT类型的全文索引</p><p>InnoDB：不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。</p><h3 id="8、-表主键"><a href="#8、-表主键" class="headerlink" title="8、 表主键"></a>8、 表主键</h3><p>MyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。</p><p>InnoDB：如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。</p><h3 id="9、-表的具体行数"><a href="#9、-表的具体行数" class="headerlink" title="9、 表的具体行数"></a>9、 表的具体行数</h3><p>MyISAM：保存有表的总行数，如果select count(*) from table;会直接取出出该值。</p><p>InnoDB：没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。</p><h3 id="10、-CURD操作"><a href="#10、-CURD操作" class="headerlink" title="10、 CURD操作"></a>10、 CURD操作</h3><p>MyISAM：如果执行大量的SELECT，MyISAM是更好的选择。</p><p>InnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。</p><h3 id="11、-外键"><a href="#11、-外键" class="headerlink" title="11、 外键"></a>11、 外键</h3><p>MyISAM：不支持</p><p>InnoDB：支持</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过上述的分析，基本上可以考虑使用InnoDB来替代MyISAM引擎了，原因是InnoDB自身很多良好的特点，比如事务支持、存储 过程、视图、行级锁定等等，在并发很多的情况下，相信InnoDB的表现肯定要比MyISAM强很多。另外，任何一种表都不是万能的，只用恰当的针对业务类型来选择合适的表类型，才能最大的发挥MySQL的性能优势。如果不是很复杂的Web应用，非关键应用，还是可以继续考虑MyISAM的，这个具体情况可以自己斟酌。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是MySQL存储引擎中的MyISAM和InnoDB区别详解&lt;/p&gt;
&lt;h2 id=&quot;知识背景&quot;&gt;&lt;a href=&quot;#知识背景&quot; class=&quot;headerlink&quot; title=&quot;知识背景&quot;&gt;&lt;/a&gt;知识背景&lt;/h2&gt;&lt;p&gt;在使用MySQL的过程中对MyISAM
      
    
    </summary>
    
      <category term="MySQL存储引擎中的MyISAM和InnoDB区别详解" scheme="http://yoursite.com/categories/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B8%AD%E7%9A%84MyISAM%E5%92%8CInnoDB%E5%8C%BA%E5%88%AB%E8%AF%A6%E8%A7%A3/"/>
    
    
      <category term="MySQL" scheme="http://yoursite.com/tags/MySQL/"/>
    
      <category term="MyISAM" scheme="http://yoursite.com/tags/MyISAM/"/>
    
      <category term="InnoDB" scheme="http://yoursite.com/tags/InnoDB/"/>
    
  </entry>
  
  <entry>
    <title>Zabbix 编译安装部署</title>
    <link href="http://yoursite.com/2018/02/25/zabbix-source-installation/"/>
    <id>http://yoursite.com/2018/02/25/zabbix-source-installation/</id>
    <published>2018-02-24T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.785Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是使用源码编译方式安装Zabbix3.4.x</p><h2 id="Zabbix简介"><a href="#Zabbix简介" class="headerlink" title="Zabbix简介"></a>Zabbix简介</h2><p>Zabbix 是由Alexei Vladishev创建，目前由Zabbix SIA在持续开发和支持。</p><p>Zabbix 是一个企业级的分布式开源监控方案。</p><p>Zabbix是一款能够监控各种网络参数以及服务器健康性和完整性的软件。Zabbix使用灵活的通知机制，允许用户为几乎任何事件配置基于邮件的告警。这样可以快速反馈服务器的问题。基于已存储的数据，Zabbix提供了出色的报告和数据可视化功能。这些功能使得Zabbix成为容量规划的理想方案。</p><p>Zabbix支持主动轮询和被动捕获。Zabbix所有的报告、统计信息和配置参数都可以通过基于Web的前端页面进行访问。基于Web的前端页面可以确保您从任何方面评估您的网络状态和服务器的健康性。适当的配置后，Zabbix可以在IT基础架构监控方面扮演重要的角色。对于只有少量服务器的小型组织和拥有大量服务器的大型公司也同样如此。</p><p>Zabbix是免费的。Zabbix是根据GPL通用公共许可证第2版编写和发行的。这意味着它的源代码都是免费发行的，可供公众任意使用。</p><p>想了解更多Zabbix相关信息，可以参考<a href="https://www.zabbix.com/documentation/3.4/zh/start" target="_blank" rel="noopener">Zabbix官方文档</a></p><h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><ul><li>CentOS 7/RHEL 7</li></ul><p>整套安装流程是在CentOS7上的zabbix-server和zabbix-agent(版本为3.4.6)，使用前端网页服务器是nginx</p><h3 id="添加zabbix用户"><a href="#添加zabbix用户" class="headerlink" title="添加zabbix用户"></a>添加zabbix用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ useradd -r -s /sbin/nologin zabbix</span><br></pre></td></tr></table></figure><h3 id="安装Percona-Mysql数据库-比原生Mysql性能更优"><a href="#安装Percona-Mysql数据库-比原生Mysql性能更优" class="headerlink" title="安装Percona Mysql数据库(比原生Mysql性能更优)"></a>安装Percona Mysql数据库(比原生Mysql性能更优)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 添加到yum repo</span></span><br><span class="line">$ vi /etc/yum.repos.d/percona-release.repo</span><br><span class="line"><span class="comment">########################################</span></span><br><span class="line"><span class="comment"># Percona releases and sources, stable #</span></span><br><span class="line"><span class="comment">########################################</span></span><br><span class="line">[percona-release-<span class="variable">$basearch</span>]</span><br><span class="line">name = Percona-Release YUM repository - <span class="variable">$basearch</span></span><br><span class="line">baseurl = http://repo.percona.com/release/<span class="variable">$releasever</span>/RPMS/<span class="variable">$basearch</span></span><br><span class="line">enabled = 1</span><br><span class="line">gpgcheck = 1</span><br><span class="line">gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-percona</span><br><span class="line">[percona-release-noarch]</span><br><span class="line">name = Percona-Release YUM repository - noarch</span><br><span class="line">baseurl = http://repo.percona.com/release/<span class="variable">$releasever</span>/RPMS/noarch</span><br><span class="line">enabled = 1</span><br><span class="line">gpgcheck = 1</span><br><span class="line">gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-percona</span><br><span class="line">[percona-release-source]</span><br><span class="line">name = Percona-Release YUM repository - Source packages</span><br><span class="line">baseurl = http://repo.percona.com/release/<span class="variable">$releasever</span>/SRPMS</span><br><span class="line">enabled = 0</span><br><span class="line">gpgcheck = 1</span><br><span class="line">gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-percona</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 下载percona key并安装</span></span><br><span class="line">$ wget http://www.percona.com/downloads/RPM-GPG-KEY-percona -O /etc/pki/rpm-gpg/RPM-GPG-KEY-percona</span><br><span class="line">$ yum install -y Percona-Server-devel-57 Percona-Server-shared-57 Percona-Server-client-57 Percona-Server-server-57 percona-zabbix-templates Percona-Server-shared</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 开启mysql服务并设置开机启动</span></span><br><span class="line">$ systemctl start mysql      <span class="comment">## 注意启动服务的时候会进行一连串初始化日志输出，其中会包括一个随机生成的密码作为初次启动设置的root密码(留意有一行有"A temporary password"相关字眼)，下一步需要用到</span></span><br><span class="line">$ systemctl <span class="built_in">enable</span> mysql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用上述获得的密码对mysql的root密码进行修改</span></span><br><span class="line">$ mysql -u root -p<span class="string">"&lt;temporary password&gt;"</span> -e <span class="string">'SET PASSWORD = PASSWORD("'</span>&lt;your root password&gt;<span class="string">'");ALTER USER "root"@localhost PASSWORD EXPIRE NEVER;flush privileges;'</span> --connect-expired-password</span><br><span class="line"><span class="comment">## 以上需要修改的是`&lt;temporary password&gt;`，`&lt;your root password&gt;`</span></span><br><span class="line"><span class="comment">## 若命令报错，有可能是您设置的root密码安全性不足，需要8位其中包括至少一个大写字母、小写字母数字和特殊符号。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 以下是目前我正在使用的mysql配置文件，仅供参考，不一定符合每个场景使用</span></span><br><span class="line">$ vi /etc/my.cnf</span><br><span class="line"><span class="comment"># *** default location during install, and will be replaced if you</span></span><br><span class="line"><span class="comment"># *** upgrade to a newer version of MySQL.</span></span><br><span class="line">[mysqld]</span><br><span class="line"><span class="comment"># Remove leading # and set to the amount of RAM for the most important data</span></span><br><span class="line"><span class="comment"># cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.</span></span><br><span class="line"><span class="comment"># innodb_buffer_pool_size = 128M</span></span><br><span class="line"><span class="comment"># Remove leading # to turn on a very important data integrity option: logging</span></span><br><span class="line"><span class="comment"># changes to the binary log between backups.</span></span><br><span class="line"><span class="comment"># log_bin</span></span><br><span class="line"><span class="comment"># These are commonly set, remove the # and set as required.</span></span><br><span class="line"><span class="comment"># basedir = .....</span></span><br><span class="line"><span class="comment"># datadir = .....</span></span><br><span class="line"><span class="comment"># port = .....</span></span><br><span class="line"><span class="comment"># server_id = .....</span></span><br><span class="line"><span class="comment"># socket = .....</span></span><br><span class="line"><span class="comment"># Remove leading # to set options mainly useful for reporting servers.</span></span><br><span class="line"><span class="comment"># The server defaults are faster for transactions and fast SELECTs.</span></span><br><span class="line"><span class="comment"># Adjust sizes as needed, experiment to find the optimal values.</span></span><br><span class="line"><span class="comment"># join_buffer_size = 128M</span></span><br><span class="line"><span class="comment"># sort_buffer_size = 2M</span></span><br><span class="line"><span class="comment"># read_rnd_buffer_size = 2M </span></span><br><span class="line">sync_binlog=0</span><br><span class="line">show_compatibility_56=ON</span><br><span class="line">character-set-server = utf8</span><br><span class="line"><span class="comment"># network</span></span><br><span class="line">connect_timeout = 60</span><br><span class="line">wait_timeout = 2880</span><br><span class="line">max_connections = 2048</span><br><span class="line">max_allowed_packet = 32M</span><br><span class="line">max_connect_errors = 1000</span><br><span class="line"><span class="comment"># limits</span></span><br><span class="line">tmp_table_size = 512M</span><br><span class="line">max_heap_table_size = 256M</span><br><span class="line"><span class="comment"># logs</span></span><br><span class="line">log_error = /var/<span class="built_in">log</span>/mysql/mysql-error.log</span><br><span class="line">slow_query_log_file = /var/1og/mysql/mysql-slow.log</span><br><span class="line">slow_query_log = 1</span><br><span class="line">long_query_time = 20</span><br><span class="line">log_error_verbosity=2</span><br><span class="line"><span class="comment"># innodb</span></span><br><span class="line"><span class="comment">#innodb_data_home_dir = /var/lib/mysql/data</span></span><br><span class="line">innodb_file_per_table = 1</span><br><span class="line">innodb_status_file = 1</span><br><span class="line">innodb_buffer_pool_size = 2G</span><br><span class="line">innodb_flush_method = O_DIRECT</span><br><span class="line">innodb_io_capacity = 2000</span><br><span class="line">innodb_flush_log_at_trx_commit = 2</span><br><span class="line">innodb_support_xa = 0</span><br><span class="line">innodb_log_file_size = 512M</span><br><span class="line"><span class="comment"># other stuff</span></span><br><span class="line">event_scheduler = 1</span><br><span class="line">query_cache_type = 0</span><br><span class="line">sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</span><br><span class="line">[mysqld_safe]</span><br><span class="line"><span class="built_in">log</span>-error=/var/<span class="built_in">log</span>/mysqld.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 若修改过配置文件，记得要重启mysql服务</span></span><br><span class="line">$ systemctl restart mysql</span><br></pre></td></tr></table></figure><h2 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">$ yum install epel-release</span><br><span class="line">$ yum install nginx</span><br><span class="line">$ vi /etc/nginx/conf.d/zabbix.conf</span><br><span class="line">server &#123;</span><br><span class="line">    listen      80;</span><br><span class="line">    <span class="comment">#server_name zabbix.test;</span></span><br><span class="line">    charset     utf-8;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#root        /var/www/zabbix;</span></span><br><span class="line">    root        /usr/share/nginx/html/zabbix;</span><br><span class="line">    index       index.php;</span><br><span class="line"></span><br><span class="line">    location ~* /\.ht &#123;</span><br><span class="line">        deny  all;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~* /(api|conf|include)/ &#123;</span><br><span class="line">        rewrite ^/(.*)$ http://localhost/zabbix/index.php permanent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~ \.php$ &#123;</span><br><span class="line">        include fastcgi_params;</span><br><span class="line">        fastcgi_param   SCRIPT_FILENAME <span class="variable">$document_root</span><span class="variable">$fastcgi_script_name</span>;</span><br><span class="line">        fastcgi_param   QUERY_STRING    <span class="variable">$query_string</span>;</span><br><span class="line">        fastcgi_pass    127.0.0.1:9000;</span><br><span class="line">        fastcgi_intercept_errors on;</span><br><span class="line">        error_page      403 404 502 503 504 http://localhost/zabbix/index.php;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ~* \.(css|gif|jpeg|jpg|js|txt|png|tif|tiff|ico|jng|bmp|doc|pdf|rtf|xls|xpi|zip|tgz|gz|bz2|tar|mid|midi|mp3)$ &#123;</span><br><span class="line">        root /usr/share/nginx/html/zabbix/;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="安装PHP5-6提供前端支持"><a href="#安装PHP5-6提供前端支持" class="headerlink" title="安装PHP5.6提供前端支持"></a>安装PHP5.6提供前端支持</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 安装rpm</span></span><br><span class="line">$ rpm -ivh http://mirror.webtatic.com/yum/el7/webtatic-release.rpm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## yum安装php5.6</span></span><br><span class="line">$ yum install -y php56w-mcrypt php56w-mbstring php56w-common php56w-xmlrpc php56w-mysql php56w-pdo php56w-gd php56w-ldap php56w-xml php56w-cli php56w-bcmath php56w php56w-fpm</span><br><span class="line">$ service php-fpm start</span><br></pre></td></tr></table></figure><h3 id="下载Zabbix-3-4-6源码包并安装"><a href="#下载Zabbix-3-4-6源码包并安装" class="headerlink" title="下载Zabbix-3.4.6源码包并安装"></a>下载Zabbix-3.4.6源码包并安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 下载源码包</span></span><br><span class="line">$ wget -c https://nchc.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/3.4.6/zabbix-3.4.6.tar.gz</span><br><span class="line">$ tar zxf zabbix-3.4.6.tar.gz</span><br><span class="line">$ <span class="built_in">cd</span> zabbix-3.4.6</span><br><span class="line">$ ./configure --prefix=/usr/<span class="built_in">local</span>/zabbix --<span class="built_in">enable</span>-server --<span class="built_in">enable</span>-agent --with-mysql --with-net-snmp --with-libcurl</span><br><span class="line">$ make</span><br><span class="line">$ make install </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 初始化mysql的zabbix数据库(需要用到上述安装mysql的root密码)</span></span><br><span class="line">$ mysql -uroot -p<span class="string">"&lt;your root password&gt;"</span> -e <span class="string">'CREATE USER "zabbix"@"localhost" IDENTIFIED BY "'</span>&lt;zabbix db password&gt;<span class="string">'";'</span></span><br><span class="line">$ mysql -uroot -p<span class="string">"&lt;your root password&gt;"</span> -e <span class="string">'create database zabbix character set utf8;'</span></span><br><span class="line">$ mysql -uroot -p<span class="string">"&lt;your root password&gt;"</span> -e <span class="string">'grant all privileges on zabbix.* to zabbix@localhost identified by "'</span>&lt;zabbix db password&gt;<span class="string">'";flush privileges;'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 导入初始化的sql文件</span></span><br><span class="line">$ mysql -uzabbix -p<span class="string">"&lt;zabbix db password&gt;"</span> -e <span class="string">"use zabbix;source database/mysql/schema.sql;"</span></span><br><span class="line">$ mysql -uzabbix -p<span class="string">"&lt;zabbix db password&gt;"</span> -e <span class="string">"use zabbix;source database/mysql/images.sql;"</span></span><br><span class="line">$ mysql -uzabbix -p<span class="string">"&lt;zabbix db password&gt;"</span> -e <span class="string">"use zabbix;source database/mysql/data.sql;"</span></span><br></pre></td></tr></table></figure><h3 id="配置zabbix-server-conf"><a href="#配置zabbix-server-conf" class="headerlink" title="配置zabbix_server.conf"></a>配置zabbix_server.conf</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">'s/^DBName=.*$/DBName=zabbix/g'</span> /usr/<span class="built_in">local</span>/zabbix/etc/zabbix_server.conf</span><br><span class="line">sed -i <span class="string">'s/^DBUser=.*$/DBUser=zabbix/g'</span> /usr/<span class="built_in">local</span>/zabbix/etc/zabbix_server.conf</span><br><span class="line">sed -i <span class="string">'s/^DBPassword=.*$/DBPassword='</span>&lt;zabbix db password&gt;<span class="string">'/g'</span> /usr/<span class="built_in">local</span>/zabbix/etc/zabbix_server.conf</span><br><span class="line">sed -i <span class="string">'s/^ServerActive=.*$/ServerActive=127.0.0.1/g'</span> /usr/<span class="built_in">local</span>/zabbix/etc/zabbix_agentd.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">## 复制数据库监控模板</span></span><br><span class="line">cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /usr/<span class="built_in">local</span>/zabbix/etc/zabbix_agentd.conf.d/</span><br><span class="line"></span><br><span class="line"><span class="comment">## 复制启动脚本并修改为目前路径</span></span><br><span class="line">cp misc/init.d/fedora/core/zabbix_* /etc/init.d/</span><br><span class="line">sed -i <span class="string">'s#BASEDIR=/usr/local#BASEDIR=/usr/local/zabbix#g'</span> /etc/init.d/zabbix_server</span><br><span class="line">sed -i <span class="string">'s#BASEDIR=/usr/local#BASEDIR=/usr/local/zabbix#g'</span> /etc/init.d/zabbix_agentd</span><br></pre></td></tr></table></figure><h3 id="配置服务文件"><a href="#配置服务文件" class="headerlink" title="配置服务文件"></a>配置服务文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/services     <span class="comment"># 在文件最后添加</span></span><br><span class="line">zabbix-agent 10050/tcp Zabbix Agent</span><br><span class="line">zabbix-agent 10050/udp Zabbix Agent</span><br><span class="line">zabbix-trapper 10051/tcp Zabbix Trapper</span><br><span class="line">zabbix-trapper 10051/udp Zabbix Trapper</span><br></pre></td></tr></table></figure><h3 id="配置php-ini"><a href="#配置php-ini" class="headerlink" title="配置php.ini"></a>配置php.ini</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">'s/^.*post_max_size.*$/post_max_size = 16M/g'</span> /etc/php.ini</span><br><span class="line">sed -i <span class="string">'s/^.*max_execution_time.*$/max_execution_time = 300/g'</span> /etc/php.ini</span><br><span class="line">sed -i <span class="string">'s/^.*max_input_time.*$/max_input_time = 300/g'</span> /etc/php.ini</span><br><span class="line">sed -i <span class="string">'s/^.*always_populate_raw_post_data.*$/always_populate_raw_post_data = -1/g'</span> /etc/php.ini</span><br><span class="line">sed -i <span class="string">'s/^.*date.timezone.*$/date.timezone = Asia\/Shanghai/g'</span> /etc/php.ini</span><br><span class="line">sed -i <span class="string">'s/mbstring.func_overload.*$/mbstring.func_overload = 2/g'</span> /etc/php.ini</span><br></pre></td></tr></table></figure><h3 id="复制Zabbix前端文件"><a href="#复制Zabbix前端文件" class="headerlink" title="复制Zabbix前端文件"></a>复制Zabbix前端文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /usr/share/nginx/html/zabbix</span><br><span class="line">cp -a frontends/php/* /usr/share/nginx/html/zabbix/</span><br><span class="line">cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /usr/<span class="built_in">local</span>/zabbix/etc/zabbix_agentd.conf.d/</span><br><span class="line">chmod 777 -R  /var/lib/php/session/</span><br></pre></td></tr></table></figure><h3 id="关闭系统相关安全设置并开机自启动相关"><a href="#关闭系统相关安全设置并开机自启动相关" class="headerlink" title="关闭系统相关安全设置并开机自启动相关"></a>关闭系统相关安全设置并开机自启动相关</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop firewalld</span><br><span class="line">$ setenforce 0</span><br><span class="line">$ sed -i <span class="string">'s/SELINUX=enforcing/SELINUX=disabled/g'</span> /etc/sysconfig/selinux </span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"/etc/init.d/zabbix_server start"</span> &gt;&gt; /etc/rc.local</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">"/etc/init.d/zabbix_agentd start"</span> &gt;&gt; /etc/rc.local</span><br><span class="line">$ systemctl <span class="built_in">enable</span> mysql</span><br><span class="line">$ systemctl <span class="built_in">enable</span> nginx</span><br></pre></td></tr></table></figure><h3 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart nginx zabbix_server zabbix_agentd</span><br></pre></td></tr></table></figure><h3 id="Zabbix-Web页面"><a href="#Zabbix-Web页面" class="headerlink" title="Zabbix Web页面"></a>Zabbix Web页面</h3><p>请参考<a href="https://www.zabbix.com/documentation/3.4/manual/installation/install#installing_frontend" target="_blank" rel="noopener">官方手册</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是使用源码编译方式安装Zabbix3.4.x&lt;/p&gt;
&lt;h2 id=&quot;Zabbix简介&quot;&gt;&lt;a href=&quot;#Zabbix简介&quot; class=&quot;headerlink&quot; title=&quot;Zabbix简介&quot;&gt;&lt;/a&gt;Zabbix简介&lt;/h2&gt;&lt;p&gt;Zabbix 是由A
      
    
    </summary>
    
      <category term="Zabbix 编译安装" scheme="http://yoursite.com/categories/Zabbix-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="Zabbix" scheme="http://yoursite.com/tags/Zabbix/"/>
    
      <category term="Source" scheme="http://yoursite.com/tags/Source/"/>
    
      <category term="Installation" scheme="http://yoursite.com/tags/Installation/"/>
    
  </entry>
  
  <entry>
    <title>Zabbix YUM方式部署</title>
    <link href="http://yoursite.com/2018/02/25/zabbix-yum-installation/"/>
    <id>http://yoursite.com/2018/02/25/zabbix-yum-installation/</id>
    <published>2018-02-24T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.793Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是使用YUM方式安装Zabbix3.4.x</p><h2 id="Zabbix简介"><a href="#Zabbix简介" class="headerlink" title="Zabbix简介"></a>Zabbix简介</h2><p>Zabbix 是由Alexei Vladishev创建，目前由Zabbix SIA在持续开发和支持。</p><p>Zabbix 是一个企业级的分布式开源监控方案。</p><p>Zabbix是一款能够监控各种网络参数以及服务器健康性和完整性的软件。Zabbix使用灵活的通知机制，允许用户为几乎任何事件配置基于邮件的告警。这样可以快速反馈服务器的问题。基于已存储的数据，Zabbix提供了出色的报告和数据可视化功能。这些功能使得Zabbix成为容量规划的理想方案。</p><p>Zabbix支持主动轮询和被动捕获。Zabbix所有的报告、统计信息和配置参数都可以通过基于Web的前端页面进行访问。基于Web的前端页面可以确保您从任何方面评估您的网络状态和服务器的健康性。适当的配置后，Zabbix可以在IT基础架构监控方面扮演重要的角色。对于只有少量服务器的小型组织和拥有大量服务器的大型公司也同样如此。</p><p>Zabbix是免费的。Zabbix是根据GPL通用公共许可证第2版编写和发行的。这意味着它的源代码都是免费发行的，可供公众任意使用。</p><p>想了解更多Zabbix相关信息，可以参考<a href="https://www.zabbix.com/documentation/3.4/zh/start" target="_blank" rel="noopener">Zabbix官方文档</a></p><h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><ul><li>CentOS 7/RHEL 7</li></ul><p>整套安装流程是在CentOS7上的zabbix-server和zabbix-agent，使用前端网页服务器是apahce</p><h3 id="yum安装Zabbix-Server、mariadb"><a href="#yum安装Zabbix-Server、mariadb" class="headerlink" title="yum安装Zabbix Server、mariadb"></a>yum安装Zabbix Server、mariadb</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ rpm -i http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm</span><br><span class="line">$ yum install -y zabbix-server-mysql zabbix-web-mysql zabbix-agent mariadb*</span><br></pre></td></tr></table></figure><h3 id="启动、配置mariadb"><a href="#启动、配置mariadb" class="headerlink" title="启动、配置mariadb"></a>启动、配置mariadb</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 启动并设置开机自启动数据库</span></span><br><span class="line">$ systemctl start mariadb</span><br><span class="line">$ systemctl <span class="built_in">enable</span> mariadb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 配置mariadb</span></span><br><span class="line">$ mysql_secure_installation</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 首先是设置密码，会提示先输入密码</span></span><br><span class="line">$ Enter current password <span class="keyword">for</span> root (enter <span class="keyword">for</span> none):&lt;–初次运行直接回车</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 设置密码</span></span><br><span class="line">$ Set root password? [Y/n] &lt;– 是否设置root用户密码，输入y并回车或直接回车</span><br><span class="line">$ New password: &lt;– 设置root用户的密码</span><br><span class="line">$ Re-enter new password: &lt;– 再输入一次你设置的密码</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 其他配置</span></span><br><span class="line">$ Remove anonymous users? [Y/n] &lt;– 是否删除匿名用户，回车</span><br><span class="line"></span><br><span class="line">$ Disallow root login remotely? [Y/n] &lt;–是否禁止root远程登录,回车,</span><br><span class="line"></span><br><span class="line">$ Remove <span class="built_in">test</span> database and access to it? [Y/n] &lt;– 是否删除<span class="built_in">test</span>数据库，回车</span><br><span class="line"></span><br><span class="line">$ Reload privilege tables now? [Y/n] &lt;– 是否重新加载权限表，回车</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 初始化MariaDB完成，接下来测试登录</span></span><br><span class="line">$ mysql -uroot -ppassword</span><br><span class="line"><span class="comment">## 能进入数据库则完成安装</span></span><br></pre></td></tr></table></figure><h3 id="初始化zabbix-mariadb"><a href="#初始化zabbix-mariadb" class="headerlink" title="初始化zabbix mariadb"></a>初始化zabbix mariadb</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -uroot -p</span><br><span class="line"><span class="comment">#password</span></span><br><span class="line"></span><br><span class="line">mysql&gt; create database zabbix character <span class="built_in">set</span> utf8 collate utf8_bin;</span><br><span class="line">mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by <span class="string">'password'</span>;</span><br><span class="line">mysql&gt; quit;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 导入zabbix初始化sql</span></span><br><span class="line">$ zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix</span><br></pre></td></tr></table></figure><h3 id="配置zabbix-server-conf"><a href="#配置zabbix-server-conf" class="headerlink" title="配置zabbix_server.conf"></a>配置zabbix_server.conf</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/zabbix/zabbix_server.conf</span><br><span class="line">DBHost=localhost</span><br><span class="line">DBName=zabbix</span><br><span class="line">DBUser=zabbix</span><br><span class="line">DBPassword=password</span><br></pre></td></tr></table></figure><h3 id="启动zabbix相关服务和http服务"><a href="#启动zabbix相关服务和http服务" class="headerlink" title="启动zabbix相关服务和http服务"></a>启动zabbix相关服务和http服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl start zabbix-server zabbix-agent httpd</span><br><span class="line">$ systemctl <span class="built_in">enable</span> zabbix-server zabbix-agent httpd</span><br></pre></td></tr></table></figure><h3 id="配置Zabbix前端的PHP文件"><a href="#配置Zabbix前端的PHP文件" class="headerlink" title="配置Zabbix前端的PHP文件"></a>配置Zabbix前端的PHP文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/httpd/conf.d/zabbix.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对应位置默认已经设置好，剩下的就是需要修改date.timezone，把默认注释的去掉，然后后面的值(Europe/Riga)改成当前时区(Asia/Shanghai)</span></span><br><span class="line">php_value max_execution_time 300</span><br><span class="line">php_value memory_limit 128M</span><br><span class="line">php_value post_max_size 16M</span><br><span class="line">php_value upload_max_filesize 2M</span><br><span class="line">php_value max_input_time 300</span><br><span class="line">php_value always_populate_raw_post_data -1</span><br><span class="line">php_value date.timezone Aisa/Shanghai</span><br></pre></td></tr></table></figure><h3 id="配置Zabbix-Web"><a href="#配置Zabbix-Web" class="headerlink" title="配置Zabbix Web"></a>配置Zabbix Web</h3><p>登录到<code>http://server_ip_or_name/zabbix</code>，然后根据指示来安装<a href="https://www.zabbix.com/documentation/3.4/manual/installation/install#installing_frontend" target="_blank" rel="noopener">前端界面</a></p><h3 id="Zabbix使用手册"><a href="#Zabbix使用手册" class="headerlink" title="Zabbix使用手册"></a>Zabbix使用手册</h3><p>Zabbix日常使用和新版本特征可以参考<a href="https://www.zabbix.com/documentation/3.4/manual/quickstart/login" target="_blank" rel="noopener">官方使用手册</a></p><p>需要安装其他版本的zabbix或者不同的系统或者不同的数据库可以参考<a href="https://www.zabbix.com/download?zabbix=3.4&amp;os_distribution=centos&amp;os_version=7&amp;db=MySQL" target="_blank" rel="noopener">官方安装手册</a>进行选择对应的安装教程。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="部署分布式监控Zabbix-Proxy"><a href="#部署分布式监控Zabbix-Proxy" class="headerlink" title="部署分布式监控Zabbix Proxy"></a>部署分布式监控Zabbix Proxy</h3><p>Zabbix Proxy适用于大规模分布式监控场景，采用的一种分担Server端压力的分层结构，Proxy只负责一定区域内的数据采集工作，然后定期将数据一次性发送给Server，极大的减轻了Server的负载压力，使得可以支持更大规模的监控需求。</p><p><img src="/images/zabbix-proxy.png" alt="zabbix-proxy"></p><h3 id="用yum安装部署zabbix-proxy"><a href="#用yum安装部署zabbix-proxy" class="headerlink" title="用yum安装部署zabbix-proxy"></a>用yum安装部署zabbix-proxy</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 安装zabbix-release rpm包，若已经进行则可以无视以下这一条命令</span></span><br><span class="line">$ rpm -i http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装zabbix-proxy和zabbix-java-gateway</span></span><br><span class="line">$ yum install -y  zabbix-proxy zabbix-java-gateway</span><br><span class="line"></span><br><span class="line"><span class="comment">## 默认已经存在mysql，没有则自行安装，安装配置命令上述教程提及到</span></span><br><span class="line">$ mysql -u root -p</span><br><span class="line">&gt; create database zabbix_proxy character <span class="built_in">set</span> utf8;       <span class="comment">#数据名可以跟server端名称不同</span></span><br><span class="line">&gt; GRANT ALL PRIVILEGES ON zabbix_proxy.*  TO <span class="string">'zabbix'</span>@<span class="string">'localhost'</span>  IDENTIFIED BY <span class="string">'zabbix-proxy'</span>;</span><br><span class="line">&gt; GRANT ALL PRIVILEGES ON zabbix_proxy.* TO <span class="string">'zabbix'</span>@<span class="string">'%'</span>  IDENTIFIED BY <span class="string">'zabbix-proxy'</span>;</span><br><span class="line">&gt; flush PRIVILEGES;</span><br><span class="line">&gt; <span class="built_in">set</span> GLOBAL max_connections=10000;</span><br><span class="line">&gt; flush privileges;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 初始化zabbix-proxy数据库</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/share/doc/zabbix-proxy-mysql-3.0.1/</span><br><span class="line">$ zcat schema.sql.gz | mysql -uroot -p zabbix_proxy</span><br><span class="line"></span><br><span class="line"><span class="comment">## 修改zabbix-proxy.conf配置文件</span></span><br><span class="line">$ vi /etc/zabbix/zabbix-proxy.conf</span><br><span class="line"></span><br><span class="line">Server=10.40.150.150    <span class="comment">#同步指向的server端的IP，非本地IP。可以是server端的主机域名，但要确保proxy端解析server的域名，并且网络可达</span></span><br><span class="line">Hostname=zabbix-proxy-test  <span class="comment">#proxy本地的名称，此名称需要与将来在server端的WEB页面上的代理程序名称一致，名称自定义</span></span><br><span class="line">DBHost=localhost            <span class="comment">#与上面配置对应</span></span><br><span class="line">DBName=zabbix_proxy   <span class="comment">#与上面配置对应</span></span><br><span class="line">DBUser=zabbix                <span class="comment">#与上面配置对应</span></span><br><span class="line">DBPassword=zabbix-proxy   <span class="comment">#与上面配置对应</span></span><br><span class="line">DBPort=3306                       <span class="comment">#与上面配置对应</span></span><br><span class="line"> </span><br><span class="line">StartDiscoverers=4              <span class="comment">#与server端配置的功能说明一致。</span></span><br><span class="line"> </span><br><span class="line">JavaGateway=127.0.0.1       <span class="comment">#与server端配置的功能说明一致。</span></span><br><span class="line">JavaGatewayPort=10052     <span class="comment">#与server端配置的功能说明一致。</span></span><br><span class="line">StartJavaPollers=4               <span class="comment">#与server端配置的功能说明一致。</span></span><br><span class="line"> </span><br><span class="line">StartSNMPTrapper=1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 启动服务并设置开机启动</span></span><br><span class="line">$ systemctl start zabbix-java-gateway zabbix-proxy</span><br><span class="line">$ systemctl <span class="built_in">enable</span> zabbix-java-gateway zabbix-proxy</span><br></pre></td></tr></table></figure><p>致此，系统级proxy安装设置完成。回到server 端WEB页面(管理–&gt;agent代理程序–&gt;创建代理)添加代理机(主动式)，被动式的话需要填写proxy的公网IP。</p><p>如果之后，我们可以在主机页面上做监控添加，选择指向agent上报至proxy端。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是使用YUM方式安装Zabbix3.4.x&lt;/p&gt;
&lt;h2 id=&quot;Zabbix简介&quot;&gt;&lt;a href=&quot;#Zabbix简介&quot; class=&quot;headerlink&quot; title=&quot;Zabbix简介&quot;&gt;&lt;/a&gt;Zabbix简介&lt;/h2&gt;&lt;p&gt;Zabbix 是由Al
      
    
    </summary>
    
      <category term="Zabbix YUM安装" scheme="http://yoursite.com/categories/Zabbix-YUM%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="Zabbix" scheme="http://yoursite.com/tags/Zabbix/"/>
    
      <category term="Installation" scheme="http://yoursite.com/tags/Installation/"/>
    
      <category term="Yum" scheme="http://yoursite.com/tags/Yum/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB单实例部署</title>
    <link href="http://yoursite.com/2018/02/24/mongodb-single/"/>
    <id>http://yoursite.com/2018/02/24/mongodb-single/</id>
    <published>2018-02-23T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.838Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是MongoDB单实例部署全过程</p><h2 id="MongoDB简介"><a href="#MongoDB简介" class="headerlink" title="MongoDB简介"></a>MongoDB简介</h2><p>MongoDB是用C++语言编写的非关系型数据库。特点是高性能、易部署、易使用，存储数据十分方便，主要特性有： </p><ul><li><p>面向集合存储，易于存储对象类型的数据 </p></li><li><p>模式自由 </p></li><li><p>支持动态查询 </p></li><li><p>支持完全索引，包含内部对象 </p></li><li><p>支持复制和故障恢复 </p></li><li><p>使用高效的二进制数据存储，包括大型对象 </p></li><li><p>文件存储格式为BSON(一种JSON的扩展)</p></li></ul><p><a href="https://www.mongodb.com/download-center#atlas" target="_blank" rel="noopener">官网下载地址</a></p><p><a href="https://docs.mongodb.com/manual/introduction/" target="_blank" rel="noopener">官方文档</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul><li>系统：CentOS 7/RHEL 7</li></ul><h3 id="yum安装方式"><a href="#yum安装方式" class="headerlink" title="yum安装方式"></a>yum安装方式</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 以3.4.x为例</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 创建yum源文件</span></span><br><span class="line">$ vim /etc/yum.repos.d/mongodb-org-3.4.repo</span><br><span class="line"></span><br><span class="line"><span class="comment">## 把下面的内容复制到上面的文件中</span></span><br><span class="line">[mongodb-org-3.4]</span><br><span class="line">name=MongoDB Repository</span><br><span class="line">baseurl=https://repo.mongodb.org/yum/redhat/<span class="variable">$releasever</span>/mongodb-org/3.4/x86_64/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc123456</span><br><span class="line"></span><br><span class="line"><span class="comment">## 启动yum命令开始安装</span></span><br><span class="line">$ yum install -y mongodb-org</span><br></pre></td></tr></table></figure><p>各个安装包说明：</p><p><img src="/images/mongodb-org.png" alt="mongodb-org"></p><h2 id="编译安装方式"><a href="#编译安装方式" class="headerlink" title="编译安装方式"></a>编译安装方式</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 以3.4.13版本为例</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用wget命令下载安装包</span></span><br><span class="line">$ wget http://downloads.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.13.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment">## 解压压缩包，并配置相关文件</span></span><br><span class="line">$ tar zxf mongodb-linux-x86_64-rhel70-3.4.13.tgz</span><br><span class="line">$ mv mongodb-linux-x86_64-rhel70-3.4.13 mongodb</span><br><span class="line">$ mv mongodb /usr/<span class="built_in">local</span>/</span><br><span class="line"><span class="comment">## 那么/usr/local/mongodb/bin/下的命令就是mongodb相关的命令</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 若系统不存在mongodb用户则进行创建</span></span><br><span class="line">$ groupadd mongod</span><br><span class="line">$ useradd -r -g mongod -s /sbin/nologin -M mongod</span><br><span class="line"></span><br><span class="line"><span class="comment">## 现在创建mongodb数据库所需要的文件路径</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/single/data</span><br><span class="line">$ mkdir -p /data/db/mongodb/single/etc</span><br><span class="line">$ mkdir -p /data/db/mongodb/single/<span class="built_in">log</span></span><br><span class="line">$ chown -R mongod:mongod /data/db/mongodb</span><br></pre></td></tr></table></figure><h2 id="配置文件参数说明"><a href="#配置文件参数说明" class="headerlink" title="配置文件参数说明"></a>配置文件参数说明</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">storage:  </span><br><span class="line">   dbPath: &lt;string&gt;                       <span class="comment">#存储数据目录  </span></span><br><span class="line">   indexBuildRetry: &lt;boolean&gt;         <span class="comment">#当构建索引时mongod意外关闭，那么再次启动是否重新构建索引；索引构建失败，mongod重启后将会删除尚未完成的索引，但是否重建由此参数决定。默认值为true。  </span></span><br><span class="line">   repairPath: &lt;string&gt;                   <span class="comment">#配合--repair启动命令参数，在repair期间使用此目录存储临时数据，repair结束后此目录下数据将被删除，此配置仅对mongod进程有效。不建议在配置文件中配置，而是使用mongod启动命令指定。  </span></span><br><span class="line">   journal:  </span><br><span class="line">      enabled: &lt;boolean&gt;              <span class="comment">#是否开启journal日志持久存储，journal日志用来数据恢复，是mongod最基础的特性，通常用于故障恢复。  </span></span><br><span class="line">      commitIntervalMs: &lt;num&gt;         <span class="comment">#New in version 3.2.  日志提交间隔  </span></span><br><span class="line">   directoryPerDB: &lt;boolean&gt;          <span class="comment">#将不同DB的数据分子目录存储，基于dbPath，默认为 false  </span></span><br><span class="line">   syncPeriodSecs: &lt;int&gt;              <span class="comment">#使用fsync操作将数据flush到磁盘的时间间隔，默认值为60（单位：秒），建议不修改  </span></span><br><span class="line">   engine: &lt;string&gt;                       <span class="comment">#存储引擎，3.2后默认wiredTiger 可选 mmapv1  </span></span><br><span class="line">   mmapv1:  </span><br><span class="line">      preallocDataFiles: &lt;boolean&gt;        <span class="comment">#Deprecated since version 2.6. 已废弃  </span></span><br><span class="line">      nsSize: &lt;int&gt;  </span><br><span class="line">      quota:  </span><br><span class="line">         enforced: &lt;boolean&gt;  </span><br><span class="line">         maxFilesPerDB: &lt;int&gt;  </span><br><span class="line">      smallFiles: &lt;boolean&gt;  </span><br><span class="line">      journal:  </span><br><span class="line">         debugFlags: &lt;int&gt;  </span><br><span class="line">         commitIntervalMs: &lt;num&gt;  </span><br><span class="line">   wiredTiger:  </span><br><span class="line">      engineConfig:  </span><br><span class="line">         cacheSizeGB: &lt;number&gt;                <span class="comment">#GB，此值决定了wiredTiger与mmapv1的内存模型不同，它可以限制mongod对内存的使用量  </span></span><br><span class="line">         statisticsLogDelaySecs: &lt;number&gt;  </span><br><span class="line">         journalCompressor: &lt;string&gt;      <span class="comment">#journal日志的压缩算法，可选值为“none”、“snappy”、“zlib”。  </span></span><br><span class="line">         directoryForIndexes: &lt;boolean&gt;       <span class="comment">#是否将索引和collections数据分别存储在dbPath单独的目录中。即index数据保存“index”子目录，collections数据保存在“collection”子目录。默认值为false，仅对mongod有效。  </span></span><br><span class="line">      collectionConfig:  </span><br><span class="line">         blockCompressor: &lt;string&gt;            <span class="comment">#collection数据压缩算法，可选值“none”、“snappy”、“zlib”  </span></span><br><span class="line">      indexConfig:    </span><br><span class="line">         prefixCompression: &lt;boolean&gt;     <span class="comment">#是否对索引数据使用“前缀压缩”（prefix compression，一种算法）。前缀压缩，对那些经过排序的值存储，有很大帮助，可以有效的减少索引数据的内存使用量。默认值为true。  </span></span><br><span class="line"></span><br><span class="line">operationProfiling:  </span><br><span class="line">   slowOpThresholdMs: &lt;int&gt;    <span class="comment">#数据库profiler判定一个操作是“慢查询”的时间阀值，单位毫秒；  </span></span><br><span class="line">   mode: &lt;string&gt;          <span class="comment">#off：关闭profiling  slowOp：on，只包含慢操作日志； all  On. Includes all operations.  </span></span><br><span class="line">                <span class="comment">#Database profiling can impact database performance. Enable this option only after careful consideration.  </span></span><br><span class="line">                <span class="comment">#对性能有影响，建议只在调试期间开启  </span></span><br><span class="line">systemLog:          <span class="comment">#系统日志配置  </span></span><br><span class="line">   verbosity: &lt;int&gt; <span class="comment">#日志级别，0：默认值，包含“info”信息，1~5，即大于0的值均会包含debug信息  </span></span><br><span class="line">   quiet: &lt;boolean&gt;  <span class="comment">#"安静"，此时mongod/mongos将会尝试减少日志的输出量。不建议在production环境下开启，否则将会导致跟踪错误比较困难。  </span></span><br><span class="line">   traceAllExceptions: &lt;boolean&gt; <span class="comment"># 打印异常详细信息  </span></span><br><span class="line">   syslogFacility: &lt;string&gt; <span class="comment">#The facility level used when logging messages to syslog.  default:user  </span></span><br><span class="line">   path: &lt;string&gt;         <span class="comment">#日志文件路径  </span></span><br><span class="line">   logAppend: &lt;boolean&gt;       <span class="comment">#启动或重启后是否追加写入  </span></span><br><span class="line">   logRotate: &lt;string&gt;        <span class="comment">#防止一个日志文件特别大，可选项：rename(重命名日志文件，默认值);reopen(使用linux日志rotate特性，关闭并重新打开此日志文件，可以避免日志丢失，但是logAppend必须为true)  </span></span><br><span class="line">   destination: &lt;string&gt;  <span class="comment">#日志输出目的地，可为 file 或 syslog; if file, you must also specify systemLog.path.  </span></span><br><span class="line">   timeStampFormat: &lt;string&gt;<span class="comment">#时间格式 默认为 iso8601-local     </span></span><br><span class="line">   component:  </span><br><span class="line">      accessControl:  </span><br><span class="line">         verbosity: &lt;int&gt;  </span><br><span class="line">      <span class="built_in">command</span>:  </span><br><span class="line">         verbosity: &lt;int&gt;  </span><br><span class="line"></span><br><span class="line">net:                    <span class="comment">#网络相关配置  </span></span><br><span class="line">   port: &lt;int&gt;            <span class="comment">#监听端口  </span></span><br><span class="line">   bindIp: &lt;string&gt;       <span class="comment">#监听ip，不指定则监听所有网卡，  </span></span><br><span class="line">   maxIncomingConnections: &lt;int&gt; <span class="comment">#进程允许的最大连接数，默认:65536  </span></span><br><span class="line">   wireObjectCheck: &lt;boolean&gt; <span class="comment">#当客户端写入数据时，mongos/mongod是否检测数据的有效性(BSON)，如果数据格式不良，此insert、update操作将会被拒绝；默认值为true  </span></span><br><span class="line">   ipv6: &lt;boolean&gt;    <span class="comment">#是否支持mongos/mongod多个实例之间使用IPV6网络，默认值为false。此值需要在整个cluster中保持一致。  </span></span><br><span class="line">   unixDomainSocket:  </span><br><span class="line">      enabled: &lt;boolean&gt;  </span><br><span class="line">      pathPrefix: &lt;string&gt;  </span><br><span class="line">      filePermissions: &lt;int&gt;  </span><br><span class="line">   http:  </span><br><span class="line">      enabled: &lt;boolean&gt;  <span class="comment">#Enable or disable the HTTP interface.   </span></span><br><span class="line">      JSONPEnabled: &lt;boolean&gt;  </span><br><span class="line">      RESTInterfaceEnabled: &lt;boolean&gt;  </span><br><span class="line">   ssl:  </span><br><span class="line">      sslOnNormalPorts: &lt;boolean&gt;  <span class="comment"># deprecated since 2.6  </span></span><br><span class="line">      mode: &lt;string&gt;  </span><br><span class="line">      PEMKeyFile: &lt;string&gt;  </span><br><span class="line">      PEMKeyPassword: &lt;string&gt;  </span><br><span class="line">      clusterFile: &lt;string&gt;  </span><br><span class="line">      clusterPassword: &lt;string&gt;  </span><br><span class="line">      CAFile: &lt;string&gt;  </span><br><span class="line">      CRLFile: &lt;string&gt;  </span><br><span class="line">      allowConnectionsWithoutCertificates: &lt;boolean&gt;  </span><br><span class="line">      allowInvalidCertificates: &lt;boolean&gt;  </span><br><span class="line">      allowInvalidHostnames: &lt;boolean&gt;  </span><br><span class="line">      disabledProtocols: &lt;string&gt;  </span><br><span class="line">      FIPSMode: &lt;boolean&gt;</span><br></pre></td></tr></table></figure><p><strong>mongodb配置文件例子</strong>(/data/db/mongodb/single/etc/config.yml)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: file</span><br><span class="line">   path: <span class="string">"/data/db/mongodb/single/log/mongodb.log"</span></span><br><span class="line">   quiet: <span class="literal">true</span></span><br><span class="line">   logAppend: <span class="literal">true</span></span><br><span class="line">storage:</span><br><span class="line">   dbPath: <span class="string">"/data/db/mongodb/single/data"</span></span><br><span class="line">   journal:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">   engine: <span class="string">"wiredTiger"</span></span><br><span class="line">   wiredTiger:</span><br><span class="line">      engineConfig:</span><br><span class="line">          cacheSizeGB: 1</span><br><span class="line">          directoryForIndexes: <span class="literal">true</span></span><br><span class="line">      collectionConfig:</span><br><span class="line">          blockCompressor: zlib</span><br><span class="line">      indexConfig:</span><br><span class="line">          prefixCompression: <span class="literal">true</span></span><br><span class="line">operationProfiling:</span><br><span class="line">   slowOpThresholdMs: 100</span><br><span class="line">   mode: <span class="string">"slowOp"</span></span><br><span class="line">processManagement:</span><br><span class="line">   fork: <span class="literal">true</span></span><br><span class="line">   pidFilePath: <span class="string">"/data/db/mongodb/single/mongodb.pid"</span></span><br><span class="line">net:</span><br><span class="line">   bindIp: 192.168.0.123</span><br><span class="line">   port: 37017</span><br><span class="line"><span class="comment">#security:</span></span><br><span class="line">   <span class="comment">##keyFile: /data/mongodb/config/data/keyfile</span></span><br><span class="line">   <span class="comment">##authorization: enabled</span></span><br></pre></td></tr></table></figure><h2 id="启动命令"><a href="#启动命令" class="headerlink" title="启动命令"></a>启动命令</h2><p>因为安全问题，不建议直接使用<code>root</code>来启动数据库</p><ul><li>yum安装方式</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo -u mongod mongod -f /data/db/mongodb/single/config.yml</span><br></pre></td></tr></table></figure><ul><li>编译安装方式</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/<span class="built_in">local</span>/mongodb/bin/mongod -f /data/db/mongodb/single/config.yml</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是MongoDB单实例部署全过程&lt;/p&gt;
&lt;h2 id=&quot;MongoDB简介&quot;&gt;&lt;a href=&quot;#MongoDB简介&quot; class=&quot;headerlink&quot; title=&quot;MongoDB简介&quot;&gt;&lt;/a&gt;MongoDB简介&lt;/h2&gt;&lt;p&gt;MongoDB是用C++
      
    
    </summary>
    
      <category term="MongoDB单实例部署" scheme="http://yoursite.com/categories/MongoDB%E5%8D%95%E5%AE%9E%E4%BE%8B%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="NoSql" scheme="http://yoursite.com/tags/NoSql/"/>
    
      <category term="MongoDB" scheme="http://yoursite.com/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB复制集部署</title>
    <link href="http://yoursite.com/2018/02/24/mongodb-replset/"/>
    <id>http://yoursite.com/2018/02/24/mongodb-replset/</id>
    <published>2018-02-23T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.815Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是MongoDB复制集部署全过程,有关MongoDB简介、安装以及配置文件参数说明,请看回上一个帖子<a href="https://polaris0112.github.io/2018/02/24/mongodb-single/" target="_blank" rel="noopener">MongoDB单实例部署</a></p><p>以下就直接介绍复制集以及部署过程</p><h2 id="MongoDB复制集简介"><a href="#MongoDB复制集简介" class="headerlink" title="MongoDB复制集简介"></a>MongoDB复制集简介</h2><p>   Mongodb复制集由一组Mongod实例（进程）组成，包含一个Primary节点和多个Secondary节点，Mongodb Driver（客户端）的所有数据都写入Primary，Secondary从Primary同步写入的数据，以保持复制集内所有成员存储相同的数据集，提供数据的高可用。更多关于副本集的介绍请见<a href="https://docs.mongodb.com/manual/replication/" target="_blank" rel="noopener">官网</a>。</p><p>   下图（图片源于Mongodb官方文档）是一个典型的Mongdb复制集，包含一个Primary节点和2个Secondary节点。</p><p><img src="/images/mongodb-replication.png" alt="mongodb-replication"></p><h2 id="复制集-副本集-处理数据过程"><a href="#复制集-副本集-处理数据过程" class="headerlink" title="复制集(副本集)处理数据过程"></a>复制集(副本集)处理数据过程</h2><p>副本集中数据同步过程：Primary节点写入数据，Secondary通过读取Primary的oplog得到复制信息，开始复制数据并且将复制信息写入到自己的oplog。如果某个操作失败，则备份节点停止从当前数据源复制数据。如果某个备份节点由于某些原因挂掉了，当重新启动后，就会自动从oplog的最后一个操作开始同步，同步完成后，将信息写入自己的oplog，由于复制操作是先复制数据，复制完成后再写入oplog，有可能相同的操作会同步两份，不过MongoDB在设计之初就考虑到这个问题，将oplog的同一个操作执行多次，与执行一次的效果是一样的。简单的说就是：</p><p>当Primary节点完成数据操作后，Secondary会做出一系列的动作保证数据的同步：<br>1：检查自己local库的oplog.rs集合找出最近的时间戳。<br>2：检查Primary节点local库oplog.rs集合，找出大于此时间戳的记录。<br>3：将找到的记录插入到自己的oplog.rs集合中，并执行这些操作。</p><p>副本集的同步和主从同步一样，都是异步同步的过程，不同的是副本集有个自动故障转移的功能。其原理是：slave端从primary端获取日志，然后在自己身上完全顺序的执行日志所记录的各种操作（该日志是不记录查询操作的），这个日志就是local数据 库中的oplog.rs表，默认在64位机器上这个表是比较大的，占磁盘大小的5%，oplog.rs的大小可以在启动参数中设 定：–oplogSize 1000,单位是M。</p><p>同期原理是，写操作发生在主库，从库同步主库的OpLog日志。</p><p><img src="/images/mongodb-replication-run.png" alt="mongodb-replication-run"></p><p>集群中没有特定的主库，主库是选举产生，如果主库down了，会再选举出一台主库。</p><p><img src="/images/mongodb-replication-fail.png" alt="mongodb-replication-fail"></p><p>注意：在副本集的环境中，要是所有的Secondary都宕机了，只剩下Primary。最后Primary会变成Secondary，不能提供服务。</p><h2 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h2><p>Mongodb的安装和配置文件的说明不再重复，详细请看帖子<a href="https://polaris0112.github.io/2018/02/24/mongodb-single/" target="_blank" rel="noopener">《MongoDB单实例部署》</a></p><p>官方推荐最小的复制集是3节点集群，一主两从或者一主一从一仲裁(其中仲裁节点，即当参与选举的节点无法选出主节点时仲裁节点充当仲裁的作用，仲裁节点不存储数据。)</p><p>由于两从的配置除了ip设置不一样之外其他都一样的，所以这里例子示范的是一主一从一仲裁的搭建过程。</p><p>准备3台服务器：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.0.100    <span class="comment">#主节点</span></span><br><span class="line">192.168.0.101    <span class="comment">#从节点</span></span><br><span class="line">192.168.0.102    <span class="comment">#仲裁节点</span></span><br></pre></td></tr></table></figure></p><p>均安装上MongoDB并配置好对应的目录(假设每个节点存放的路径都是在/data/db/mongodb/repl目录下的data、log和etc文件夹)</p><p>在主节点(192.168.0.100)编辑配置文件(/data/db/mongodb/repl/etc/config.yml)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: <span class="string">"file"</span></span><br><span class="line">   path: <span class="string">"/data/db/mongodb/repl/log/mongodb.log"</span></span><br><span class="line">   quiet: <span class="literal">true</span></span><br><span class="line">   logAppend: <span class="literal">true</span></span><br><span class="line">storage:</span><br><span class="line">   dbPath: <span class="string">"/data/db/mongodb/repl/data"</span></span><br><span class="line">   journal:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">   engine: <span class="string">"wiredTiger"</span></span><br><span class="line">   wiredTiger:</span><br><span class="line">      engineConfig:</span><br><span class="line">          cacheSizeGB: 1</span><br><span class="line">          directoryForIndexes: <span class="literal">true</span></span><br><span class="line">      collectionConfig:</span><br><span class="line">          blockCompressor: zlib</span><br><span class="line">      indexConfig:</span><br><span class="line">          prefixCompression: <span class="literal">true</span></span><br><span class="line">operationProfiling:</span><br><span class="line">   slowOpThresholdMs: 100</span><br><span class="line">   mode: <span class="string">"slowOp"</span></span><br><span class="line">processManagement:</span><br><span class="line">   fork: <span class="literal">true</span></span><br><span class="line">   pidFilePath: <span class="string">"/data/db/mongodb/repl/mongodb.pid"</span></span><br><span class="line">net:</span><br><span class="line">   bindIp: <span class="string">"192.168.0.100"</span></span><br><span class="line">   port: 27100</span><br><span class="line">replication:</span><br><span class="line">  replSetName: <span class="string">"replSet"</span></span><br><span class="line"><span class="comment">##security:</span></span><br><span class="line"><span class="comment">##   authorization: enabled</span></span><br><span class="line"><span class="comment">##   keyFile: "/data/db/mongodb/repl/mongodb-keyfile"</span></span><br></pre></td></tr></table></figure></p><p>从节点(192.168.0.101)的配置文件(/data/db/mongodb/repl/etc/config.yml)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: <span class="string">"file"</span></span><br><span class="line">   path: <span class="string">"/data/db/mongodb/repl/log/mongodb.log"</span></span><br><span class="line">   quiet: <span class="literal">true</span></span><br><span class="line">   logAppend: <span class="literal">true</span></span><br><span class="line">storage:</span><br><span class="line">   dbPath: <span class="string">"/data/db/mongodb/repl/data"</span></span><br><span class="line">   journal:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">   engine: <span class="string">"wiredTiger"</span></span><br><span class="line">   wiredTiger:</span><br><span class="line">      engineConfig:</span><br><span class="line">          cacheSizeGB: 1</span><br><span class="line">          directoryForIndexes: <span class="literal">true</span></span><br><span class="line">      collectionConfig:</span><br><span class="line">          blockCompressor: zlib</span><br><span class="line">      indexConfig:</span><br><span class="line">          prefixCompression: <span class="literal">true</span></span><br><span class="line">operationProfiling:</span><br><span class="line">   slowOpThresholdMs: 100</span><br><span class="line">   mode: <span class="string">"slowOp"</span></span><br><span class="line">processManagement:</span><br><span class="line">   fork: <span class="literal">true</span></span><br><span class="line">   pidFilePath: <span class="string">"/data/db/mongodb/repl/mongodb.pid"</span></span><br><span class="line">net:</span><br><span class="line">   bindIp: <span class="string">"192.168.0.101"</span></span><br><span class="line">   port: 27100</span><br><span class="line">replication:</span><br><span class="line">  replSetName: <span class="string">"replSet"</span></span><br><span class="line"><span class="comment">##security:</span></span><br><span class="line"><span class="comment">##   authorization: enabled</span></span><br><span class="line"><span class="comment">##   keyFile: "/data/db/mongodb/repl/mongodb-keyfile"</span></span><br></pre></td></tr></table></figure></p><p>仲裁节点(192.168.0.102)的配置文件(/data/db/mongodb/repl/etc/config.yml)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: <span class="string">"file"</span></span><br><span class="line">   path: <span class="string">"/data/db/mongodb/repl/log/mongodb.log"</span></span><br><span class="line">   quiet: <span class="literal">true</span></span><br><span class="line">   logAppend: <span class="literal">true</span></span><br><span class="line">storage:</span><br><span class="line">   dbPath: <span class="string">"/data/db/mongodb/repl/data"</span></span><br><span class="line">   journal:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">   engine: <span class="string">"wiredTiger"</span></span><br><span class="line">   wiredTiger:</span><br><span class="line">      engineConfig:</span><br><span class="line">          cacheSizeGB: 1</span><br><span class="line">          directoryForIndexes: <span class="literal">true</span></span><br><span class="line">      collectionConfig:</span><br><span class="line">          blockCompressor: zlib</span><br><span class="line">      indexConfig:</span><br><span class="line">          prefixCompression: <span class="literal">true</span></span><br><span class="line">operationProfiling:</span><br><span class="line">   slowOpThresholdMs: 100</span><br><span class="line">   mode: <span class="string">"slowOp"</span></span><br><span class="line">processManagement:</span><br><span class="line">   fork: <span class="literal">true</span></span><br><span class="line">   pidFilePath: <span class="string">"/data/db/mongodb/repl/mongodb.pid"</span></span><br><span class="line">net:</span><br><span class="line">   bindIp: <span class="string">"192.168.0.102"</span></span><br><span class="line">   port: 27100</span><br><span class="line">replication:</span><br><span class="line">  replSetName: <span class="string">"replSet"</span></span><br><span class="line"><span class="comment">##security:</span></span><br><span class="line"><span class="comment">##   authorization: enabled</span></span><br><span class="line"><span class="comment">##   keyFile: "/data/db/mongodb/repl/mongodb-keyfile"</span></span><br></pre></td></tr></table></figure></p><p><strong>注意：</strong></p><p>1、每个配置文件看上去好像是一样，不过最重要的是要确定好端口有没有在本机被占用和绑定的IP是否确定为本机IP</p><p>2、每个配置文件最后3行是开启用户认证的，如果是生产环境必须先在无用户认证下先创建好管理员账号，然后把用户认证的参数打开(取消注释)</p><p>3、增加安全认证机制KeyFile，配置文件最后的<code>keyfile</code>是MongoDB集群认证的方式之一，确保集群中的成员都是信任的，生成keyfile命令如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ openssl rand -base64 745 &gt; /data/db/mongodb/repl/mongodb-keyfile</span><br><span class="line">$ chmod 600 /data/db/mongodb/repl/mongodb-keyfile</span><br><span class="line">$ chown mongod:mongod /data/db/mongodb/repl/mongodb-keyfile</span><br></pre></td></tr></table></figure></p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>在所有节点中执行命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mongod -f /data/db/mongodb/repl/etc/config.yml</span><br></pre></td></tr></table></figure><p>如果发现启动错误或者失败，可以先从配置文件检查，再看文件目录，查看文件目录是否建好，用户和组的设置有没有设成mongod，再不行请查看mongodb日志文件排错。</p><p>若使用MongoDB3.0.9，有可能是mongodb-keyfile最后两个<code>=</code>符号需要删去才能启动(之前遇到过的坑，应该是版本的bug)</p><p>成功启动后，登陆到主节点中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ mongo 192.168.0.100:27100/admin</span><br><span class="line"></span><br><span class="line">&gt; config = &#123; _id:<span class="string">"replSet"</span>,</span><br><span class="line">             members:[</span><br><span class="line">                      &#123;_id:0,host:<span class="string">"192.168.0.100:27100"</span>,priority:100&#125;,</span><br><span class="line">                      &#123;_id:1,host:<span class="string">"192.168.0.101:27100"</span>,priority:99&#125;,</span><br><span class="line">                      &#123;_id:2,host:<span class="string">"192.168.0.102:27100"</span>,arbiterOnly:<span class="literal">true</span>&#125;</span><br><span class="line">  ]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; rs.initiate(config)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 稍等一会之后，按几下回车，应该就会见到命令行发生改变</span></span><br><span class="line"></span><br><span class="line">&gt;</span><br><span class="line">&gt;</span><br><span class="line">replSet:PRIMARY&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看rs集群状态</span></span><br><span class="line">replSet:PRIMARY&gt; rs.status()</span><br></pre></td></tr></table></figure><p>其中，刚才的配置里面<code>priority</code>的值越大，就会选取最大的那个做主节点。<code>arbiterOnly</code>则是定义这个节点是用于仲裁作用的。</p><p>副本集配置完成。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是MongoDB复制集部署全过程,有关MongoDB简介、安装以及配置文件参数说明,请看回上一个帖子&lt;a href=&quot;https://polaris0112.github.io/2018/02/24/mongodb-single/&quot; target=&quot;_blank
      
    
    </summary>
    
      <category term="MongoDB复制集部署" scheme="http://yoursite.com/categories/MongoDB%E5%A4%8D%E5%88%B6%E9%9B%86%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="NoSql" scheme="http://yoursite.com/tags/NoSql/"/>
    
      <category term="MongoDB" scheme="http://yoursite.com/tags/MongoDB/"/>
    
      <category term="ReplSet" scheme="http://yoursite.com/tags/ReplSet/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB Sharding集群部署</title>
    <link href="http://yoursite.com/2018/02/24/mongodb-shard/"/>
    <id>http://yoursite.com/2018/02/24/mongodb-shard/</id>
    <published>2018-02-23T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.775Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是MongoDB分片+副本集集群部署</p><h2 id="MongoDB-Sharding简介"><a href="#MongoDB-Sharding简介" class="headerlink" title="MongoDB Sharding简介"></a>MongoDB Sharding简介</h2><p>  分片（sharding）是MongoDB用来将大型集合分割到不同服务器（或者说一个集群）上所采用的方法。尽管分片起源于关系型数据库分区，但MongoDB分片完全又是另一回事。和MySQL分区方案相比，MongoDB的最大区别在于它几乎能自动完成所有事情，只要告诉MongoDB要分配数据，它就能自动维护数据在不同服务器之间的均衡。 </p><h3 id="分片的目的"><a href="#分片的目的" class="headerlink" title="分片的目的"></a>分片的目的</h3><p>  高数据量和吞吐量的数据库应用会对单机的性能造成较大压力,大的查询量会将单机的CPU耗尽,大的数据量对单机的存储压力较大,最终会耗尽系统的内存而将压力转移到磁盘IO上。</p><p>  为了解决这些问题,有两个基本的方法: 垂直扩展和水平扩展。</p><p>  垂直扩展：增加更多的CPU和存储资源来扩展容量。</p><p>  水平扩展：将数据集分布在多个服务器上。水平扩展即分片。</p><h3 id="分片设计思想"><a href="#分片设计思想" class="headerlink" title="分片设计思想"></a>分片设计思想</h3><p>  分片为应对高吞吐量与大数据量提供了方法。使用分片减少了每个分片需要处理的请求数，因此，通过水平扩展，集群可以提高自己的存储容量和吞吐量。举例来说，当插入一条数据时，应用只需要访问存储这条数据的分片.</p><p>  使用分片减少了每个分片存储的数据。</p><p>  例如，如果数据库1tb的数据集，并有4个分片，然后每个分片可能仅持有256 GB的数据。如果有40个分片，那么每个切分可能只有25GB的数据。</p><p><img src="/images/mongodb-sharding-concept.png" alt="mongodb-sharding-concept"></p><h3 id="分片设计架构"><a href="#分片设计架构" class="headerlink" title="分片设计架构"></a>分片设计架构</h3><p><img src="/images/mongodb-sharding-struct.png" alt="mongodb-sharding-struct"></p><p><img src="/images/mongodb-sharding-pic.png" alt="mongodb-sharding-pic"></p><h2 id="分片部署"><a href="#分片部署" class="headerlink" title="分片部署"></a>分片部署</h2><ul><li>系统：CentOS 7/RHEL 7</li></ul><h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><p>准备三台服务器做副本集，具体操作可以参考<a href="https://polaris0112.github.io/2018/02/24/mongodb-replset/" target="_blank" rel="noopener">《MongoDB复制集部署》</a></p><p>三个节点都用相同端口配置<br>Sharding port: 27100  27101 27102 27103<br>Config Server port: 27000<br>Mongos port: 30000</p><p><strong>请注意，配置文件会区别，不能完全照搬</strong></p><p>假设我们都已经安装好MongoDB，参考<a href="https://polaris0112.github.io/2018/02/24/mongodb-single/" target="_blank" rel="noopener">《MongoDB单实例部署》</a></p><p>这个例子我们是分4片，4个Sharding</p><p>先在192.168.0.100创建目录路径<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Sharding 0</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s0/data</span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s0/<span class="built_in">log</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s0/etc</span><br><span class="line"></span><br><span class="line"><span class="comment">## Sharding 1</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s1/data</span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s1/<span class="built_in">log</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s1/etc</span><br><span class="line"></span><br><span class="line"><span class="comment">## Sharding 2</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s2/data</span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s2/<span class="built_in">log</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s2/etc</span><br><span class="line"></span><br><span class="line"><span class="comment">## Sharding 3</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s3/data</span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s3/<span class="built_in">log</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/shard/s3/etc</span><br></pre></td></tr></table></figure></p><h2 id="编辑Sharding-0的配置文件-data-db-mongodb-shard-s0-etc-config-yml"><a href="#编辑Sharding-0的配置文件-data-db-mongodb-shard-s0-etc-config-yml" class="headerlink" title="编辑Sharding 0的配置文件(/data/db/mongodb/shard/s0/etc/config.yml)"></a>编辑Sharding 0的配置文件(/data/db/mongodb/shard/s0/etc/config.yml)</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: <span class="string">"file"</span></span><br><span class="line">   path: <span class="string">"/data/db/mongodb/shard/s0/log/s0.log"</span></span><br><span class="line">   quiet: <span class="literal">true</span></span><br><span class="line">   logAppend: <span class="literal">true</span></span><br><span class="line">storage:</span><br><span class="line">   dbPath: <span class="string">"/data/db/mongodb/shard/s0/data"</span></span><br><span class="line">   journal:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">   engine: <span class="string">"wiredTiger"</span></span><br><span class="line">   wiredTiger:</span><br><span class="line">      engineConfig:</span><br><span class="line">          cacheSizeGB: 1</span><br><span class="line">processManagement:</span><br><span class="line">   fork: <span class="literal">true</span></span><br><span class="line">   pidFilePath: <span class="string">"/data/db/mongodb/shard/s0/shard.pid"</span></span><br><span class="line">net:</span><br><span class="line">   bindIp: <span class="string">"192.168.0.100"</span></span><br><span class="line">   port: 27100</span><br><span class="line">sharding:</span><br><span class="line">   clusterRole: <span class="string">"shardsvr"</span></span><br><span class="line">replication:</span><br><span class="line">  replSetName: <span class="string">"s0"</span></span><br><span class="line"><span class="comment">##security:</span></span><br><span class="line"><span class="comment">##  authorization: enabled</span></span><br><span class="line"><span class="comment">##  keyFile: "/data/db/mongodb/mongodb-keyfile"</span></span><br></pre></td></tr></table></figure><p>参照以上的配置文件，修改<code>path</code>、<code>dbPath</code>、<code>pidFilePath</code>、<code>bindIp</code>、<code>port</code>、<code>replSetName</code>为对应的shard配置(sharding在同一节点上)</p><p>同理，副本集也要对应放置相同的sharding配置文件，然后启动该实例。</p><p>启动命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo -u mongod mongod -f /data/db/mongodb/shard/s0/etc/config.yml</span><br></pre></td></tr></table></figure></p><p>其他实例可以仿照这个启动命令进行启动</p><p>启动后，先配置每个分片的副本集，对应一个sharding一个副本集，副本集名为s0,s1,s2,s3</p><p>副本集详细配置请参考<a href="https://polaris0112.github.io/2018/02/24/mongodb-replset/" target="_blank" rel="noopener">《MongoDB复制集部署》</a></p><p>然后我们来创建分片中的config server。</p><p>先创建文件目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /data/db/mongodb/config/data</span><br><span class="line">$ mkdir -p /data/db/mongodb/config/<span class="built_in">log</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/config/etc</span><br></pre></td></tr></table></figure><p>创建配置文件(/data/db/mongodb/config/etc/config.yml)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: <span class="string">"file"</span></span><br><span class="line">   path: <span class="string">"/data/db/mongodb/config/log/config.log"</span></span><br><span class="line">   quiet: <span class="literal">true</span></span><br><span class="line">   logAppend: <span class="literal">true</span></span><br><span class="line">storage:</span><br><span class="line">   dbPath: <span class="string">"/data/db/mongodb/config/data"</span></span><br><span class="line">   journal:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">   engine: <span class="string">"wiredTiger"</span></span><br><span class="line">   wiredTiger:</span><br><span class="line">      engineConfig:</span><br><span class="line">          cacheSizeGB: 1</span><br><span class="line">processManagement:</span><br><span class="line">   fork: <span class="literal">true</span></span><br><span class="line">   pidFilePath: <span class="string">"/data/db/mongodb/config/config.pid"</span></span><br><span class="line">net:</span><br><span class="line">   bindIp: <span class="string">"192.168.0.100"</span></span><br><span class="line">   port: 27000</span><br><span class="line">sharding:</span><br><span class="line">   clusterRole: <span class="string">"configsvr"</span></span><br><span class="line">replication:</span><br><span class="line">  replSetName: <span class="string">"cs"</span></span><br><span class="line"><span class="comment">##security:</span></span><br><span class="line"><span class="comment">##  authorization: enabled</span></span><br><span class="line"><span class="comment">##  keyFile: "/data/db/mongodb/mongodb-keyfile"</span></span><br></pre></td></tr></table></figure><p>同样地，在三个节点都创建对应的配置文件(IP地址需要修改为本机的IP)，并创建副本集。</p><p>启动实例并配置副本集<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mongod -f /data/db/mongodb/config/etc/config.yml</span><br></pre></td></tr></table></figure></p><p>创建mongos文件路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /data/db/mongodb/mongos/data</span><br><span class="line">$ mkdir -p /data/db/mongodb/mongos/<span class="built_in">log</span></span><br><span class="line">$ mkdir -p /data/db/mongodb/mongos/etc</span><br></pre></td></tr></table></figure><p>创建mongos配置文件(/data/db/mongodb/mongos/etc/config.yml)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: <span class="string">"file"</span></span><br><span class="line">   path: <span class="string">"/data/db/mongodb/mongos/log/mongos.log"</span></span><br><span class="line">   quiet: <span class="literal">true</span></span><br><span class="line">   logAppend: <span class="literal">true</span></span><br><span class="line">   logRotate: reopen</span><br><span class="line">processManagement:</span><br><span class="line">   fork: <span class="literal">true</span></span><br><span class="line">   pidFilePath: <span class="string">"/data/db/mongodb/mongos/mongos.pid"</span></span><br><span class="line">net:</span><br><span class="line">   bindIp: <span class="string">"192.168.0.100"</span></span><br><span class="line">   port: 30000</span><br><span class="line">sharding:</span><br><span class="line">   configDB: 192.168.0.100:27100,192.168.0.101:27100,192.168.0.102:27100</span><br><span class="line">   chunkSize: 64</span><br><span class="line"><span class="comment">##security:</span></span><br><span class="line"><span class="comment">##  authorization: enabled</span></span><br><span class="line"><span class="comment">##   keyFile: "/data/db/mongodb/mongodb-keyfile"</span></span><br></pre></td></tr></table></figure><p>启动命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mongod -f /data/db/mongodb/mongos/etc/config.yml</span><br></pre></td></tr></table></figure><p>mongos作为整个分片集群的入口，不需要配置副本集，不过可以配置多个节点的mongos，留意的是<code>configDB</code>需要指定所有节点的config server，若配置了多个节点的mongos，可以使用mongodb uri达到高可用的效果。</p><p>mongos成功启动后，可以开始进行sharding的配置。</p><p>进入其中一个mongos</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ mongo 192.168.0.100:30000/admin</span><br><span class="line"></span><br><span class="line"><span class="comment">## 添加分片</span></span><br><span class="line">mongos&gt; sh.addShard(<span class="string">"shard1/192.168.0.100:27100,192.168.0.101:27100,192.168.0.102:27100"</span>)</span><br><span class="line">mongos&gt; sh.addShard(<span class="string">"shard2/192.168.0.100:27101,192.168.0.101:27101,192.168.0.102:27101"</span>)</span><br><span class="line">mongos&gt; sh.addShard(<span class="string">"shard3/192.168.0.100:27102,192.168.0.101:27102,192.168.0.102:27102"</span>)</span><br><span class="line">mongos&gt; sh.addShard(<span class="string">"shard4/192.168.0.100:27103,192.168.0.101:27103,192.168.0.102:27103"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看集群状态</span></span><br><span class="line">mongos&gt; sh.status()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 指定特定数据库分片生效</span></span><br><span class="line">mongos&gt; db.runCommand( &#123; enablesharding :<span class="string">"test"</span>&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">## 指定数据库里需要分片的集合和片键</span></span><br><span class="line">db.runCommand( &#123; shardcollection : <span class="string">"testdb.table1"</span>,key : &#123;id: 1&#125; &#125; )</span><br></pre></td></tr></table></figure><p>到此，分片+副本集部署完毕。</p><h3 id="记得修改文件路径权限，最好使用mongod用户来启动"><a href="#记得修改文件路径权限，最好使用mongod用户来启动" class="headerlink" title="记得修改文件路径权限，最好使用mongod用户来启动"></a>记得修改文件路径权限，最好使用mongod用户来启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ chown -R mongod:mongod /data/db/mongodb</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是MongoDB分片+副本集集群部署&lt;/p&gt;
&lt;h2 id=&quot;MongoDB-Sharding简介&quot;&gt;&lt;a href=&quot;#MongoDB-Sharding简介&quot; class=&quot;headerlink&quot; title=&quot;MongoDB Sharding简介&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
      <category term="MongoDB分片集群部署" scheme="http://yoursite.com/categories/MongoDB%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="NoSql" scheme="http://yoursite.com/tags/NoSql/"/>
    
      <category term="MongoDB" scheme="http://yoursite.com/tags/MongoDB/"/>
    
      <category term="Sharding" scheme="http://yoursite.com/tags/Sharding/"/>
    
      <category term="replSet" scheme="http://yoursite.com/tags/replSet/"/>
    
  </entry>
  
  <entry>
    <title>HAProxy日常使用说明</title>
    <link href="http://yoursite.com/2018/02/23/haproxy/"/>
    <id>http://yoursite.com/2018/02/23/haproxy/</id>
    <published>2018-02-22T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.862Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是HAProxy安装和配置说明</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。</p><p>HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。</p><p>HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。</p><p>HAProxy实现了一种事件驱动, 单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户空间(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle)做更多的工作。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul><li>系统：CentOS 7/RHEL 7</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 以1.6.9为例</span></span><br><span class="line"><span class="comment">#下载</span></span><br><span class="line">wget http://fossies.org/linux/misc/haproxy-1.6.9.tar.gz</span><br><span class="line"><span class="comment">#解压</span></span><br><span class="line">tar -zxvf haproxy-1.6.9.tar.gz</span><br><span class="line"><span class="built_in">cd</span> haproxy-1.6.9</span><br><span class="line"><span class="comment">#安装</span></span><br><span class="line">make TARGET=linux2628 ARCH=x86_64 PREFIX=/usr/<span class="built_in">local</span>/haproxy</span><br><span class="line">make install PREFIX=/usr/<span class="built_in">local</span>/haproxy</span><br><span class="line"></span><br><span class="line"><span class="comment">#参数说明</span></span><br><span class="line">TARGET=linux26 <span class="comment">#内核版本，使用uname -r查看内核，如：2.6.18-371.el5，此时该参数就为linux26；kernel 大于2.6.28的用：TARGET=linux2628</span></span><br><span class="line">ARCH=x86_64 <span class="comment">#系统位数</span></span><br><span class="line">PREFIX=/usr/<span class="built_in">local</span>/haprpxy <span class="comment">#/usr/local/haprpxy为haprpxy安装路径</span></span><br></pre></td></tr></table></figure><p>也可以直接使用<code>yum</code>命令进行下载，如：<code>yum install -y haproxy</code></p><p>这里也记录下各个系统各haproxy版本的rpm包<a href="https://pkgs.org/download/haproxy" target="_blank" rel="noopener">下载地址</a></p><h2 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h2><ul><li><strong>启动配置文件<code>/usr/local/haproxy/haproxy.cfg</code></strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###########全局配置#########</span></span><br><span class="line">global</span><br><span class="line">　　<span class="built_in">log</span> 127.0.0.1 local0 <span class="comment">#[日志输出配置，所有日志都记录在本机，通过local0输出]</span></span><br><span class="line">　　<span class="built_in">log</span> 127.0.0.1 local1 notice <span class="comment">#定义haproxy 日志级别[error warringinfo debug]</span></span><br><span class="line">　　daemon <span class="comment">#以后台形式运行harpoxy</span></span><br><span class="line">　　nbproc 1 <span class="comment">#设置进程数量</span></span><br><span class="line">　　maxconn 4096 <span class="comment">#默认最大连接数,需考虑ulimit-n限制</span></span><br><span class="line">　　<span class="comment">#user haproxy #运行haproxy的用户</span></span><br><span class="line">　　<span class="comment">#group haproxy #运行haproxy的用户所在的组</span></span><br><span class="line">　　<span class="comment">#pidfile /var/run/haproxy.pid #haproxy 进程PID文件</span></span><br><span class="line">　　<span class="comment">#ulimit-n 819200 #ulimit 的数量限制</span></span><br><span class="line">　　<span class="comment">#chroot /usr/share/haproxy #chroot运行路径</span></span><br><span class="line">　　<span class="comment">#debug #haproxy 调试级别，建议只在开启单进程的时候调试</span></span><br><span class="line">　　<span class="comment">#quiet</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########默认配置############</span></span><br><span class="line">defaults</span><br><span class="line">　　<span class="built_in">log</span> global</span><br><span class="line">　　mode http <span class="comment">#默认的模式mode &#123; tcp|http|health &#125;，tcp是4层，http是7层，health只会返回OK</span></span><br><span class="line">　　option httplog <span class="comment">#日志类别,采用httplog</span></span><br><span class="line">　　option dontlognull <span class="comment">#不记录健康检查日志信息</span></span><br><span class="line">　　retries 2 <span class="comment">#两次连接失败就认为是服务器不可用，也可以通过后面设置</span></span><br><span class="line">　　<span class="comment">#option forwardfor #如果后端服务器需要获得客户端真实ip需要配置的参数，可以从Http Header中获得客户端ip</span></span><br><span class="line">　　option httpclose <span class="comment">#每次请求完毕后主动关闭http通道,haproxy不支持keep-alive,只能模拟这种模式的实现</span></span><br><span class="line">　　<span class="comment">#option redispatch #当serverId对应的服务器挂掉后，强制定向到其他健康的服务器，以后将不支持</span></span><br><span class="line">　　option abortonclose <span class="comment">#当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接</span></span><br><span class="line">　　maxconn 4096 <span class="comment">#默认的最大连接数</span></span><br><span class="line">　　timeout connect 5000ms <span class="comment">#连接超时</span></span><br><span class="line">　　timeout client 30000ms <span class="comment">#客户端超时</span></span><br><span class="line">　　timeout server 30000ms <span class="comment">#服务器超时</span></span><br><span class="line">　　<span class="comment">#timeout check 2000 #心跳检测超时</span></span><br><span class="line">　　<span class="comment">#timeout http-keep-alive10s #默认持久连接超时时间</span></span><br><span class="line">　　<span class="comment">#timeout http-request 10s #默认http请求超时时间</span></span><br><span class="line">　　<span class="comment">#timeout queue 1m #默认队列超时时间</span></span><br><span class="line">　　balance roundrobin <span class="comment">#设置默认负载均衡方式，轮询方式</span></span><br><span class="line">　　<span class="comment">#balance source #设置默认负载均衡方式，类似于nginx的ip_hash</span></span><br><span class="line">　　<span class="comment">#balnace leastconn #设置默认负载均衡方式，最小连接数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########统计页面配置########</span></span><br><span class="line">listen stats</span><br><span class="line">　　<span class="built_in">bind</span> 0.0.0.0:1080 <span class="comment">#设置Frontend和Backend的组合体，监控组的名称，按需要自定义名称</span></span><br><span class="line">　　mode http <span class="comment">#http的7层模式</span></span><br><span class="line">　　option httplog <span class="comment">#采用http日志格式</span></span><br><span class="line">　　<span class="comment">#log 127.0.0.1 local0 err #错误日志记录</span></span><br><span class="line">　　maxconn 10 <span class="comment">#默认的最大连接数</span></span><br><span class="line">　　stats refresh 30s <span class="comment">#统计页面自动刷新时间</span></span><br><span class="line">　　stats uri /stats <span class="comment">#统计页面url</span></span><br><span class="line">　　stats realm XingCloud\ Haproxy <span class="comment">#统计页面密码框上提示文本</span></span><br><span class="line">　　stats auth admin:admin <span class="comment">#设置监控页面的用户和密码:admin,可以设置多个用户名</span></span><br><span class="line">　　stats auth Frank:Frank <span class="comment">#设置监控页面的用户和密码：Frank</span></span><br><span class="line">　　stats hide-version <span class="comment">#隐藏统计页面上HAProxy的版本信息</span></span><br><span class="line">　　stats admin <span class="keyword">if</span> TRUE <span class="comment">#设置手工启动/禁用，后端服务器(haproxy-1.4.9以后版本)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########设置haproxy 错误页面#####</span></span><br><span class="line"><span class="comment">#errorfile 403 /home/haproxy/haproxy/errorfiles/403.http</span></span><br><span class="line"><span class="comment">#errorfile 500 /home/haproxy/haproxy/errorfiles/500.http</span></span><br><span class="line"><span class="comment">#errorfile 502 /home/haproxy/haproxy/errorfiles/502.http</span></span><br><span class="line"><span class="comment">#errorfile 503 /home/haproxy/haproxy/errorfiles/503.http</span></span><br><span class="line"><span class="comment">#errorfile 504 /home/haproxy/haproxy/errorfiles/504.http</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########frontend前端配置##############</span></span><br><span class="line">frontend main</span><br><span class="line">　　<span class="built_in">bind</span> *:80 <span class="comment">#这里建议使用bind *:80的方式，要不然做集群高可用的时候有问题，vip切换到其他机器就不能访问了。</span></span><br><span class="line">　　acl web hdr(host) -i www.abc.com  <span class="comment">#acl后面是规则名称，-i为忽略大小写，后面跟的是要访问的域名，如果访问www.abc.com这个域名，就触发web规则，。</span></span><br><span class="line">　　acl img hdr(host) -i img.abc.com  <span class="comment">#如果访问img.abc.com这个域名，就触发img规则。</span></span><br><span class="line">　　use_backend webserver <span class="keyword">if</span> web   <span class="comment">#如果上面定义的web规则被触发，即访问www.abc.com，就将请求分发到webserver这个作用域。</span></span><br><span class="line">　　use_backend imgserver <span class="keyword">if</span> img   <span class="comment">#如果上面定义的img规则被触发，即访问img.abc.com，就将请求分发到imgserver这个作用域。</span></span><br><span class="line">　　default_backend dynamic <span class="comment">#不满足则响应backend的默认页面</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########backend后端配置##############</span></span><br><span class="line">backend webserver <span class="comment">#webserver作用域</span></span><br><span class="line">　　mode http</span><br><span class="line">　　balance roundrobin <span class="comment">#balance roundrobin 负载轮询，balance source 保存session值，支持static-rr，leastconn，first，uri等参数</span></span><br><span class="line">　　option httpchk /index.html HTTP/1.0 <span class="comment">#健康检查, 检测文件，如果分发到后台index.html访问不到就不再分发给它</span></span><br><span class="line">　　server web1 10.16.0.9:8085 cookie 1 weight 5 check inter 2000 rise 2 fall 3</span><br><span class="line">　　server web2 10.16.0.10:8085 cookie 2 weight 3 check inter 2000 rise 2 fall 3</span><br><span class="line">　　<span class="comment">#cookie 1表示serverid为1，check inter 1500 是检测心跳频率 </span></span><br><span class="line">　　<span class="comment">#rise 2是2次正确认为服务器可用，fall 3是3次失败认为服务器不可用，weight代表权重</span></span><br><span class="line"></span><br><span class="line">backend imgserver</span><br><span class="line">　　mode http</span><br><span class="line">　　option httpchk /index.php</span><br><span class="line">　　balance roundrobin </span><br><span class="line">　　server img01 192.168.137.101:80 check inter 2000 fall 3</span><br><span class="line">　　server img02 192.168.137.102:80 check inter 2000 fall 3</span><br><span class="line"></span><br><span class="line">backend dynamic </span><br><span class="line">　　balance roundrobin </span><br><span class="line">　　server test1 192.168.1.23:80 check maxconn 2000 </span><br><span class="line">　　server test2 192.168.1.24:80 check maxconn 2000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">listen tcptest </span><br><span class="line">　　<span class="built_in">bind</span> 0.0.0.0:5222 </span><br><span class="line">　　mode tcp </span><br><span class="line">　　option tcplog <span class="comment">#采用tcp日志格式 </span></span><br><span class="line">　　balance <span class="built_in">source</span> </span><br><span class="line">　　<span class="comment">#log 127.0.0.1 local0 debug </span></span><br><span class="line">　　server s1 192.168.100.204:7222 weight 1 </span><br><span class="line">　　server s2 192.168.100.208:7222 weight 1</span><br></pre></td></tr></table></figure><ul><li><strong>负载均衡算法</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">一、roundrobin，表示简单的轮询，每个服务器根据权重轮流使用，在服务器的处理时间平均分配的情况下这是最流畅和公平的算法。该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。</span><br><span class="line"></span><br><span class="line">二、static-rr，表示根据权重，建议关注；每个服务器根据权重轮流使用，类似roundrobin，但它是静态的，意味着运行时修改权限是无效的。另外，它对服务器的数量没有限制。</span><br><span class="line"></span><br><span class="line">三、leastconn，表示最少连接者先处理，建议关注；leastconn建议用于长会话服务，例如LDAP、SQL、TSE等，而不适合短会话协议。如HTTP.该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。</span><br><span class="line"></span><br><span class="line">四、<span class="built_in">source</span>，表示根据请求源IP，建议关注；对请求源IP地址进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。</span><br><span class="line">           只要服务器正常，同一个客户端IP地址总是访问同一个服务器。如果哈希的结果随可用服务器数量而变化，那么客户端会定向到不同的服务器；</span><br><span class="line">           该算法一般用于不能插入cookie的Tcp模式。它还可以用于广域网上为拒绝使用会话cookie的客户端提供最有效的粘连；</span><br><span class="line">           该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“<span class="built_in">hash</span>-type”的变化做调整。</span><br><span class="line">五、uri，表示根据请求的URI；表示根据请求的URI左端（问号之前）进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。</span><br><span class="line">        只要服务器正常，同一个URI地址总是访问同一个服务器。</span><br><span class="line">        一般用于代理缓存和反病毒代理，以最大限度的提高缓存的命中率。该算法只能用于HTTP后端；</span><br><span class="line">        该算法一般用于后端是缓存服务器；</span><br><span class="line">        该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“<span class="built_in">hash</span>-type”的变化做调整。</span><br><span class="line">六、url_param，表示根据请求的URl参数<span class="string">'balance url_param'</span> requires an URL parameter name</span><br><span class="line">              在HTTP GET请求的查询串中查找&lt;param&gt;中指定的URL参数，基本上可以锁定使用特制的URL到特定的负载均衡器节点的要求；</span><br><span class="line">              该算法一般用于将同一个用户的信息发送到同一个后端服务器；</span><br><span class="line">              该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“<span class="built_in">hash</span>-type”的变化做调整。</span><br><span class="line">七、hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；</span><br><span class="line">              在每个HTTP请求中查找HTTP头&lt;name&gt;，HTTP头&lt;name&gt;将被看作在每个HTTP请求，并针对特定的节点；</span><br><span class="line">              如果缺少头或者头没有任何值，则用roundrobin代替；</span><br><span class="line">              该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“<span class="built_in">hash</span>-type”的变化做调整。</span><br><span class="line">八、rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。</span><br><span class="line">                     为每个进来的TCP请求查询并哈希RDP cookie&lt;name&gt;；</span><br><span class="line">                     该机制用于退化的持久模式，可以使同一个用户或者同一个会话ID总是发送给同一台服务器。</span><br><span class="line">                     如果没有cookie，则使用roundrobin算法代替；</span><br><span class="line">                     该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“<span class="built_in">hash</span>-type”的变化做调整。</span><br><span class="line"></span><br><span class="line"><span class="comment">#其实这些算法各有各的用法，我们平时应用得比较多的应该是roundrobin、source和lestconn。</span></span><br></pre></td></tr></table></figure><ul><li><strong>ACL规则定义</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">########ACL策略定义#########################</span></span><br><span class="line">1、<span class="comment">#如果请求的域名满足正则表达式返回true -i是忽略大小写</span></span><br><span class="line">acl denali_policy hdr_reg(host) -i ^(www.inbank.com|image.inbank.com)$</span><br><span class="line"></span><br><span class="line">2、<span class="comment">#如果请求域名满足www.inbank.com 返回 true -i是忽略大小写</span></span><br><span class="line">acl tm_policy hdr_dom(host) -i www.inbank.com</span><br><span class="line"></span><br><span class="line">3、<span class="comment">#在请求url中包含sip_apiname=，则此控制策略返回true,否则为false</span></span><br><span class="line">acl invalid_req url_sub -i sip_apiname=<span class="comment">#定义一个名为invalid_req的策略</span></span><br><span class="line"></span><br><span class="line">4、<span class="comment">#在请求url中存在timetask作为部分地址路径，则此控制策略返回true,否则返回false</span></span><br><span class="line">acl timetask_req url_dir -i timetask</span><br><span class="line"></span><br><span class="line">5、<span class="comment">#当请求的header中Content-length等于0时返回 true</span></span><br><span class="line">acl missing_cl hdr_cnt(Content-length) eq 0</span><br><span class="line"></span><br><span class="line"><span class="comment">#########acl策略匹配相应###################</span></span><br><span class="line">1、<span class="comment">#当请求中header中Content-length等于0 阻止请求返回403</span></span><br><span class="line">block <span class="keyword">if</span> missing_cl</span><br><span class="line"></span><br><span class="line">2、<span class="comment">#block表示阻止请求，返回403错误，当前表示如果不满足策略invalid_req，或者满足策略timetask_req，则阻止请求。</span></span><br><span class="line">block <span class="keyword">if</span> !invalid_req || timetask_req</span><br><span class="line"></span><br><span class="line">3、<span class="comment">#当满足denali_policy的策略时使用denali_server的backend</span></span><br><span class="line">use_backend denali_server <span class="keyword">if</span> denali_policy</span><br><span class="line"></span><br><span class="line">4、<span class="comment">#当满足tm_policy的策略时使用tm_server的backend</span></span><br><span class="line">use_backend tm_server <span class="keyword">if</span> tm_policy</span><br><span class="line"></span><br><span class="line">5、<span class="comment">#reqisetbe关键字定义，根据定义的关键字选择backend</span></span><br><span class="line">reqisetbe ^Host:\ img dynamic</span><br><span class="line">reqisetbe ^[^\ ]*\ /(img|css)/ dynamic</span><br><span class="line">reqisetbe ^[^\ ]*\ /admin/stats stats</span><br><span class="line"></span><br><span class="line">6、<span class="comment">#以上都不满足的时候使用默认mms_server的backend</span></span><br><span class="line">default_backend mms</span><br><span class="line"></span><br><span class="line">haproxy acl定义</span><br></pre></td></tr></table></figure><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><ul><li>编译安装</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/<span class="built_in">local</span>/haproxy/sbin/haproxy -f /usr/<span class="built_in">local</span>/haproxy/haproxy.cfg</span><br></pre></td></tr></table></figure><ul><li>yum安装</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ service haproxy start      <span class="comment">#CentOS6</span></span><br><span class="line">$ systemctl start haproxy    <span class="comment">#CentOS7</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是HAProxy安装和配置说明&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主
      
    
    </summary>
    
      <category term="HAProxy使用" scheme="http://yoursite.com/categories/HAProxy%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="haproxy" scheme="http://yoursite.com/tags/haproxy/"/>
    
  </entry>
  
  <entry>
    <title>Certbot安装/部分问题解决方案</title>
    <link href="http://yoursite.com/2018/02/22/certbot/"/>
    <id>http://yoursite.com/2018/02/22/certbot/</id>
    <published>2018-02-21T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.869Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是Nginx + Certbot的安装过程以及在阿里云CentOS7上部署Certbot遇到的问题以及解决方法</p><h2 id="Using-CentOS-7-RHEL-7"><a href="#Using-CentOS-7-RHEL-7" class="headerlink" title="Using CentOS 7/RHEL 7"></a>Using CentOS 7/RHEL 7</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>Certbot安装包已经包含在EPEL(Extra Packages for Enterprise Linux)源中，所以如果安装Certbot需要先安装<a href="https://fedoraproject.org/wiki/EPEL#How_can_I_use_these_extra_packages.3F" target="_blank" rel="noopener">EPEL源</a>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 在CentOS/RHEL 7中使用</span></span><br><span class="line"></span><br><span class="line">$ yum -y install yum-utils</span><br><span class="line">$ yum-config-manager --<span class="built_in">enable</span> rhui-REGION-rhel-server-extras rhui-REGION-rhel-server-optional</span><br><span class="line">$ yum install certbot-nginx</span><br></pre></td></tr></table></figure><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>由于Certbot已经有nginx插件，所以安装证书只需要运行以下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo certbot --nginx</span><br></pre></td></tr></table></figure><p>运行后按照提示输入指定的参数值后就会自动配置nginx并启用，若需要自定义nginx配置文件则可以先使用以下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo certbot --nginx certonly</span><br></pre></td></tr></table></figure><p>更多请参考<a href="https://certbot.eff.org/docs" target="_blank" rel="noopener">文档</a></p><h3 id="更新证书"><a href="#更新证书" class="headerlink" title="更新证书"></a>更新证书</h3><p>根据官方文档上的说明，Certbot的证书有效期为90天，有效期少于30天才能更新一次，大于30天不用更新(不能更新)</p><p>测试更新命令如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo certbot renew --dry-run</span><br></pre></td></tr></table></figure><p>若上述命令测试通过(无报错)，则可以把以下命令写入到<a href="http://www.unixgeeks.org/security/newbie/unix/cron-1.html" target="_blank" rel="noopener">cron job</a>或者<a href="https://wiki.archlinux.org/index.php/Systemd/Timers" target="_blank" rel="noopener">systemd timer</a>中，就可以实现长期自动更新(官方推荐是一天执行两次确保证书能及时更新)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ certbot renew</span><br></pre></td></tr></table></figure><p>官方crontab例子参考(命令会在正午和午夜进行)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 0,12 * * * python -c <span class="string">'import random; import time; time.sleep(random.random() * 3600)'</span> &amp;&amp; certbot renew</span><br></pre></td></tr></table></figure><h2 id="其他安装方法"><a href="#其他安装方法" class="headerlink" title="其他安装方法"></a>其他安装方法</h2><h3 id="使用certbot-auto脚本安装Certbot"><a href="#使用certbot-auto脚本安装Certbot" class="headerlink" title="使用certbot-auto脚本安装Certbot"></a>使用certbot-auto脚本安装Certbot</h3><p>certbot-auto脚本会安装Certbot，并且能够自己解决RPM包和Python包依赖问题，同样非常方便。同时certbot-auto是对certbot的封装，即certbot-auto提供certbot的所有功能。在使用此方法安装Certbot后，运行certbot-auto命令获取证书。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 1) 获取certbot-auto脚本</span></span><br><span class="line">$ wget https://dl.eff.org/certbot-auto</span><br><span class="line"></span><br><span class="line"><span class="comment">## 2) 使certbot-auto脚本可执行</span></span><br><span class="line">$ sudo chmod a+x ./certbot-auto</span><br><span class="line"></span><br><span class="line"><span class="comment">## 3) 运行certbot-auto，安装Certbot</span></span><br><span class="line">$ ./certbot-auto</span><br><span class="line"></span><br><span class="line"><span class="comment">## 4) 获取Lets Encrypt证书，certbot-auto是对脚本certbot的封装，并且已经更新到了最新版本，所以使用此脚本获取证书</span></span><br><span class="line">$ ./certbot-auto</span><br></pre></td></tr></table></figure><h3 id="使用pip安装Certbot"><a href="#使用pip安装Certbot" class="headerlink" title="使用pip安装Certbot"></a>使用pip安装Certbot</h3><p>此种方法比较简单，最好先创建一个Python虚拟环境，然后再安装Certbot</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">1) 安装虚拟环境软件包(针对于Python2.7)</span><br><span class="line">$ sudo yum install python-virtualenv</span><br><span class="line"></span><br><span class="line">2) 创建虚拟环境</span><br><span class="line">$ sudo virtualenv /usr/<span class="built_in">local</span>/python-certbot</span><br><span class="line"></span><br><span class="line">3) 激活虚拟环境</span><br><span class="line">$ <span class="built_in">source</span> /usr/<span class="built_in">local</span>/python-certbot/bin/activate</span><br><span class="line"></span><br><span class="line">4) 首先更新pip</span><br><span class="line">$ pip install --upgrade pip</span><br><span class="line"></span><br><span class="line">5) 安装Certbot</span><br><span class="line">$ pip install certbot</span><br><span class="line"></span><br><span class="line">6) 安装Certbot Apache插件</span><br><span class="line">$ pip install certbot-apache</span><br><span class="line"></span><br><span class="line">或者安装Certbot Nginx插件：</span><br><span class="line">$ pip install certbot-nginx</span><br><span class="line"></span><br><span class="line">7) 在安装Certbot Apache插件时，如提示如下错误：</span><br><span class="line">OSError: ctypes.util.find_library() did not manage to locate a library called <span class="string">'augeas'</span></span><br><span class="line"></span><br><span class="line">那是因为缺少augeas库文件，安装augeas库文件：</span><br><span class="line">$ sudo yum install augeas-libs</span><br><span class="line"></span><br><span class="line">然后就能成功安装Certbot Apache插件。</span><br><span class="line"></span><br><span class="line">8) 获取Lets Encrypt证书，同时配置Apache服务器</span><br><span class="line">$ sudo certbot --apache</span><br><span class="line"></span><br><span class="line">或者，同时配置Nginx服务器</span><br><span class="line">$ sudo certbot --nginx</span><br></pre></td></tr></table></figure><h2 id="在阿里云CentOS7上部署Certbot遇到的坑以及解决方法"><a href="#在阿里云CentOS7上部署Certbot遇到的坑以及解决方法" class="headerlink" title="在阿里云CentOS7上部署Certbot遇到的坑以及解决方法"></a>在阿里云CentOS7上部署Certbot遇到的坑以及解决方法</h2><p><strong>报错1：</strong>ImportError: No module named ‘requests.packages.urllib3’ (感觉是阿里云的centos7镜像本身python包的问题，因为直接import requests都会报错)</p><p>解决方法：更改/usr/lib/python2.7/site-packages/requests/exceptions.py模块导入部分</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把/usr/lib/python2.7/site-packages/requests/exceptions.py 传入包的部分</span></span><br><span class="line">from .packages.urllib3.exceptions import HTTPError as BaseHTTPError</span><br><span class="line"><span class="comment">#改为</span></span><br><span class="line">from urllib3.exceptions import HTTPError as BaseHTTPError</span><br></pre></td></tr></table></figure><p><strong>报错2：</strong>ImportError: cannot import name UnrewindableBodyError</p><p>解决方法： 重新安装对应版本的urllib3</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#报错</span></span><br><span class="line">pkg_resources.DistributionNotFound: The <span class="string">'urllib3&lt;1.22,&gt;=1.21.1'</span> distribution was not found and is required by requests</span><br><span class="line"></span><br><span class="line"><span class="comment">#解决方法：</span></span><br><span class="line">$ pip install urllib3==1.21.1</span><br></pre></td></tr></table></figure><p><strong>报错3：</strong>pkg_resources.ContextualVersionConflict: (idna 2.6 (/usr/lib/python2.7/site-packages), Requirement.parse(‘idna<2.6,>=2.5’), set([‘requests’]))</2.6,></p><p>解决方法：先检查pip freeze|grep pyOpenSSL版本(需要2.5~2.6之间)，理论上都要根据报错的版本进行安装，不符合则安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install idna==2.5</span><br></pre></td></tr></table></figure><p><strong>报错4：</strong>ImportError: ‘pyOpenSSL’ module missing required functionality. Try upgrading to v0.14 or newer.</p><p>解决方法：这个是yum下的openssl版本过低</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget ftp://mirror.switch.ch/pool/4/mirror/centos/7.4.1708/cloud/x86_64/openstack-ocata/common/pyOpenSSL-0.15.1-1.el7.noarch.rpm</span><br><span class="line">$ rpm -Uvh pyOpenSSL-0.15.1-1.el7.noarch.rpm</span><br><span class="line"><span class="comment">#rpm -qa|grep pyOpenSSL</span></span><br><span class="line"><span class="comment">#pyOpenSSL-0.15.1-1.el7.noarch</span></span><br></pre></td></tr></table></figure><p><strong>报错5：</strong>AttributeError: ‘module’ object has no attribute ‘SSL_ST_INIT’</p><p>解决方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install pyOpenSSL==16.2.0</span><br></pre></td></tr></table></figure><h2 id="迁移https证书过程备注："><a href="#迁移https证书过程备注：" class="headerlink" title="迁移https证书过程备注："></a>迁移https证书过程备注：</h2><ul><li><p>复制/etc/letsencrypt/archive对应两个域名的文件夹到新机器上</p></li><li><p>复制/etc/letsencrypt/live对应两个域名的文件夹到新机器上</p></li><li><p>在新机器上的/etc/letsencrypt/renewal/目录下拷贝测试conf作为旧域名的新配置文件，[renewalparams]以下的参数不变，修改其余路径相关对应域名即可</p></li><li><p>添加nginx/conf.d/对应下的配置文件，注意配置ssl_certificate和ssl_certificate_key</p></li></ul><h2 id="nginx配置"><a href="#nginx配置" class="headerlink" title="nginx配置"></a>nginx配置</h2><p>以下是Certbot自动生成的nginx配置文件，把http访问的域名都会转到https</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  <span class="built_in">test</span>-certbot.xxx.com;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="variable">$scheme</span> != <span class="string">"https"</span>) &#123;</span><br><span class="line">        <span class="built_in">return</span> 301 https://<span class="variable">$host</span><span class="variable">$request_uri</span>;</span><br><span class="line">    &#125; <span class="comment"># managed by Certbot</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是Nginx + Certbot的安装过程以及在阿里云CentOS7上部署Certbot遇到的问题以及解决方法&lt;/p&gt;
&lt;h2 id=&quot;Using-CentOS-7-RHEL-7&quot;&gt;&lt;a href=&quot;#Using-CentOS-7-RHEL-7&quot; class=&quot;
      
    
    </summary>
    
      <category term="Certbot安装/部分问题解决方案" scheme="http://yoursite.com/categories/Certbot%E5%AE%89%E8%A3%85-%E9%83%A8%E5%88%86%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    
    
      <category term="Certbot" scheme="http://yoursite.com/tags/Certbot/"/>
    
      <category term="https" scheme="http://yoursite.com/tags/https/"/>
    
  </entry>
  
  <entry>
    <title>Nginx正反向代理/负载均衡</title>
    <link href="http://yoursite.com/2018/02/21/nginx/"/>
    <id>http://yoursite.com/2018/02/21/nginx/</id>
    <published>2018-02-20T16:00:00.000Z</published>
    <updated>2018-03-06T02:54:24.806Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是Nginx配置正向代理、反向代理和负载均衡相关参数。</p><h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><ul><li>正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用。</li></ul><p><img src="/images/nginx-forward-proxy.png" alt="nginx-forward-proxy"></p><ul><li>反向代理正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置。客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好似他自己一样，一次客户端并不会感知到反向代理后面的服务，也因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了。</li></ul><p><img src="/images/nginx-reverse-proxy.png" alt="nginx-reverse-proxy"></p><ul><li>负载均衡：当反向代理服务器不止一个的时候，我们甚至可以把它们做成集群，当更多的用户访问资源服务器B的时候，让不同的代理服务器Z（x）去应答不同的用户，然后发送不同用户需要的资源。</li></ul><p><img src="/images/nginx-balance.png" alt="nginx-balance.png"></p><h3 id="正向代理和反向代理区别"><a href="#正向代理和反向代理区别" class="headerlink" title="正向代理和反向代理区别"></a>正向代理和反向代理区别</h3><p>正向代理需要你主动设置代理服务器ip或者域名进行访问，由设置的服务器ip或者域名去获取访问内容并返回；而反向代理不需要你做任何设置，直接访问服务器真实ip或者域名，但是服务器内部会自动根据访问内容进行跳转及内容返回，你不知道它最终访问的是哪些机器。</p><p>正向代理是代理客户端，为客户端收发请求，使真实客户端对服务器不可见；而反向代理是代理服务器端，为服务器收发请求，使真实服务器对客户端不可见。</p><p>从上面的描述也能看得出来正向代理和反向代理最关键的两点区别：</p><ul><li><p>是否指定目标服务器</p></li><li><p>客户端是否要做设置</p></li></ul><p>下面用一张图来表示两者的差异：</p><p><img src="/images/nginx-proxy.png" alt="nginx-proxy"></p><p>正向代理中，proxy和client同属一个LAN，对server透明； 反向代理中，proxy和server同属一个LAN，对client透明。 实际上proxy在两种代理中做的事都是代为收发请求和响应，不过从结构上来看正好左右互换了下，所以把前者那种代理方式叫做正向代理，后者叫做反向代理。</p><p><strong>从用途上来区分：</strong></p><p>正向代理：正向代理用途是为了在防火墙内的局域网提供访问internet的途径。另外还可以使用缓冲特性减少网络使用率</p><p>反向代理：反向代理的用途是将防火墙后面的服务器提供给internet用户访问。同时还可以完成诸如负载均衡等功能</p><p><strong>从安全性来讲：</strong></p><p>正向代理：正向代理允许客户端通过它访问任意网站并且隐蔽客户端自身，因此你必须采取安全措施来确保仅为经过授权的客户端提供服务</p><p>反向代理：对外是透明的，访问者并不知道自己访问的是代理。对访问者而言，他以为访问的就是原始服务器</p><h2 id="Nginx-配置"><a href="#Nginx-配置" class="headerlink" title="Nginx 配置"></a>Nginx 配置</h2><h2 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h2><p>nginx.conf 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    <span class="comment"># 配置DNS解析IP地址，比如 Google Public DNS，以及超时时间（5秒）</span></span><br><span class="line">    resolver 8.8.8.8;    <span class="comment"># 必需</span></span><br><span class="line">    resolver_timeout 5s;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 监听端口</span></span><br><span class="line">    listen 8080;</span><br><span class="line"></span><br><span class="line">    access_log  /home/reistlin/logs/proxy.access.log;</span><br><span class="line">    error_log   /home/reistlin/logs/proxy.error.log;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        <span class="comment"># 配置正向代理参数</span></span><br><span class="line">        proxy_pass <span class="variable">$scheme</span>://<span class="variable">$host</span><span class="variable">$request_uri</span>;</span><br><span class="line">        <span class="comment"># 解决如果URL中带"."后Nginx 503错误</span></span><br><span class="line">        proxy_set_header Host <span class="variable">$http_host</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置缓存大小</span></span><br><span class="line">        proxy_buffers 256 4k;</span><br><span class="line">        <span class="comment"># 关闭磁盘缓存读写减少I/O</span></span><br><span class="line">        proxy_max_temp_file_size 0;</span><br><span class="line">         <span class="comment"># 代理连接超时时间</span></span><br><span class="line">        proxy_connect_timeout 30;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置代理服务器HTTP状态缓存时间</span></span><br><span class="line">        proxy_cache_valid 200 302 10m;</span><br><span class="line">        proxy_cache_valid 301 1h;</span><br><span class="line">        proxy_cache_valid any 1m;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>备注：</p><ul><li><p>配置 nginx 正向代理服务，一般是配置到一个 server 块中。注意，在该 server 块中，不要出现 server_name 指令，即不要设置虚拟主机的名称和 IP；</p></li><li><p>resolver 是必需的，如果没有该指令， nginx 无法处理接收到的域名；</p></li><li><p>nginx 代理服务不支持正向代理 HTTPS 站点；</p></li></ul><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>nginx.conf 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">upstream webServer01 &#123;</span><br><span class="line">    server 127.0.0.1:3001;</span><br><span class="line">    keepalive 64;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">upstream webServer02 &#123;</span><br><span class="line">    server 127.0.0.1:3002;</span><br><span class="line">    keepalive 64;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name www.test01.com;</span><br><span class="line">    <span class="comment">#access_log /var/log/nginx/test01.log;</span></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header Host  <span class="variable">$http_host</span>;</span><br><span class="line">        proxy_set_header X-Nginx-Proxy <span class="literal">true</span>;</span><br><span class="line">        proxy_set_header Connection <span class="string">""</span>;</span><br><span class="line">        proxy_pass       http://webServer01;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name www.test02.com;</span><br><span class="line">    <span class="comment">#access_log /var/log/nginx/test02.log;</span></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_set_header Host  <span class="variable">$http_host</span>;</span><br><span class="line">        proxy_set_header X-Nginx-Proxy <span class="literal">true</span>;</span><br><span class="line">        proxy_set_header Connection <span class="string">""</span>;</span><br><span class="line">        proxy_pass       http://webServer02;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>Nginx负载均衡是通过upstream模块来实现的，内置实现了三种负载策略，配置还是比较简单的。<a href="http://nginx.org/en/docs/http/load_balancing.html" target="_blank" rel="noopener">官网负载均衡配置说明</a></p><ul><li>轮循（默认）<br>Nginx根据请求次数，将每个请求均匀分配到每台服务器</li></ul><ul><li>最少连接<br>将请求分配给连接数最少的服务器。Nginx会统计哪些服务器的连接数最少。</li></ul><ul><li>IP Hash<br>绑定处理请求的服务器。第一次请求时，根据该客户端的IP算出一个HASH值，将请求分配到集群中的某一台服务器上。后面该客户端的所有请求，都将通过HASH算法，找到之前处理这台客户端请求的服务器，然后将请求交给它来处理。</li></ul><h3 id="轮循"><a href="#轮循" class="headerlink" title="轮循"></a>轮循</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ... 省略其它配置</span></span><br><span class="line"></span><br><span class="line">    upstream tomcats &#123;</span><br><span class="line">        server 192.168.0.100:8080;</span><br><span class="line">        server 192.168.0.101:8080;</span><br><span class="line">        server example.com:8080;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            proxy_pass http://tomcats;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ... 省略其它配置</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>proxy_pass <a href="http://tomcats：表示将所有请求转发到tomcats服务器组中配置的某一台服务器上。" target="_blank" rel="noopener">http://tomcats：表示将所有请求转发到tomcats服务器组中配置的某一台服务器上。</a></p></li><li><p>upstream模块：配置反向代理服务器组，Nginx会根据配置，将请求分发给组里的某一台服务器。tomcats是服务器组的名称。</p></li><li><p>upstream模块下的server指令：配置处理请求的服务器IP或域名，端口可选，不配置默认使用80端口。通过上面的配置，Nginx默认将请求依次分配给100，101，102来处理，可以通过修改下面这些参数来改变默认的分配策略：</p><ul><li><p>weight </p><p>默认为1，将请求平均分配给每台server</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">upstream tomcats &#123;</span><br><span class="line">    server 192.168.0.100:8080 weight=2;  <span class="comment"># 2/6次</span></span><br><span class="line">    server 192.168.0.101:8080 weight=3;  <span class="comment"># 3/6次</span></span><br><span class="line">    server 192.168.0.102:8080 weight=1;  <span class="comment"># 1/6次</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上例配置，表示6次请求中，100分配2次，101分配3次，102分配1次</p></li><li><p>max_fails </p><p>默认为1。某台Server允许请求失败的次数，超过最大次数后，在fail_timeout时间内，新的请求将不会分配给这台机器。如果设置为0，Nginx会将这台Server置为永久无效状态，然后将请求发给定义了proxy_next_upstream, fastcgi_next_upstream, uwsgi_next_upstream, scgi_next_upstream, and memcached_next_upstream指令来处理这次错误的请求。</p></li><li><p>fail_timeout </p><p>默认为10秒。某台Server达到max_fails次失败请求后，在fail_timeout期间内，nginx会认为这台Server暂时不可用，不会将请求分配给它</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">upstream tomcats &#123;</span><br><span class="line">    server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15;</span><br><span class="line">    server 192.168.0.101:8080 weight=3;</span><br><span class="line">    server 192.168.0.102:8080 weight=1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>   192.168.0.100这台机器，如果有3次请求失败，nginx在15秒内，不会将新的请求分配给它。</p><ul><li><p>backup </p><p>备份机，所有服务器挂了之后才会生效</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">upstream tomcats &#123;</span><br><span class="line">    server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15;</span><br><span class="line">    server 192.168.0.101:8080 weight=3;</span><br><span class="line"></span><br><span class="line">    server 192.168.0.102:8080 backup;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在100和101都挂了之前，102为不可用状态，不会将请求分配给它。只有当100和101都挂了，102才会被启用。</p></li><li><p>down </p><p>标识某一台server不可用。可能能通过某些参数动态的激活它吧，要不真没啥用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">upstream tomcats &#123;</span><br><span class="line">    server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15;</span><br><span class="line"></span><br><span class="line">    server 192.168.0.101:8080 down;</span><br><span class="line"></span><br><span class="line">    server 192.168.0.102:8080 backup;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>   表示101这台Server为无效状态，不会将请求分配给它。</p><ul><li><p>max_conns </p><p>限制分配给某台Server处理的最大连接数量，超过这个数量，将不会分配新的连接给它。默认为0，表示不限制。注意：1.5.9之后的版本才有这个配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">upstream tomcats &#123;</span><br><span class="line">    server 192.168.0.100:8080 max_conns=1000;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>   表示最多给100这台Server分配1000个请求，如果这台Server正在处理1000个请求，nginx将不会分配新的请求给到它。假如有一个请求处理完了，还剩下999个请求在处理，这时nginx也会将新的请求分配给它。</p><ul><li><p>resolve </p><p>将server指令配置的域名，指定域名解析服务器。需要在http模块下配置resolver指令，指定域名解析服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    resolver 10.0.0.1;</span><br><span class="line"></span><br><span class="line">    upstream u &#123;</span><br><span class="line">        zone ...;</span><br><span class="line">        ...</span><br><span class="line">        server example.com resolve;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>表示example.com域名，由10.0.0.1服务器来负责解析。 </p><p>upstream模块server指令的其它参数和详细配置说明，请参考<a href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server" target="_blank" rel="noopener">官方文档</a>。</p></li></ul><h2 id="第三方负载策略"><a href="#第三方负载策略" class="headerlink" title="第三方负载策略"></a>第三方负载策略</h2><ul><li><p>fair</p><p>根据服务器的响应时间来分配请求，响应时间短的优先分配，即负载压力小的优先会分配。</p><p>由于fair模块是第三方提供的，所以在编译nginx源码的时候，需要将fair添加到nginx模块中。</p><ul><li><p>下载fair模块源码 </p><p><a href="https://github.com/xyang0917/nginx-upstream-fair" target="_blank" rel="noopener">下载地址</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /opt</span><br><span class="line">$ wget https://github.com/xyang0917/nginx-upstream-fair/archive/master.zip</span><br><span class="line">$ unzip master.zip</span><br></pre></td></tr></table></figure><p>解压后的目录名为：nginx-upstream-fair-master</p></li><li><p>重新编译nginx，将fair模块添加到编译参数 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /opt/nginx-nginx-1.10.0</span><br><span class="line">$ ./configure --prefix=/opt/nginx --add-module=/opt/nginx-upstream-fair-master</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure><p><strong>注意：</strong>不要执行make install，这样会覆盖之前nginx的配置 </p></li><li><p>将新编译的nginx可执行程序拷贝到/opt/nginx/sbin/目录下，覆盖之前安装的nginx编译后的nginx执行程序，放在nginx源码的objs目录下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ps -aux | grep nginx</span><br><span class="line">$ <span class="built_in">kill</span> -9 nginx进程ID  <span class="comment"># 停止nginx服务</span></span><br><span class="line">$ cp /opt/nginx-1.10.0/objs/nginx /opt/nginx/sbin/  <span class="comment"># 覆盖旧的nginx</span></span><br><span class="line">$ nginx <span class="comment"># 启动服务</span></span><br></pre></td></tr></table></figure><p>配置使用fair负载策略模块：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">upstream tomcats &#123;</span><br><span class="line">    fair;</span><br><span class="line">    server 192.168.0.100:8080;</span><br><span class="line">    server 192.168.0.101:8080;</span><br><span class="line">    server 192.168.0.102:8080;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于采用fair负载策略，配置weigth参数改变负载权重将无效。</p></li></ul></li></ul><ul><li><p>url_hash</p><p>按请求url的hash结果来分配请求，使每个url定向到同一个后端服务器，服务器做缓存时比较有效。</p></li></ul><p>  1.7.2版本以后，url_hash模块已经集成到了nginx源码当中，不需要单独安装。之前的版本仍需要单独安装，<a href="https://github.com/evanmiller/nginx_upstream_hash" target="_blank" rel="noopener">下载地址</a></p><p>  安装方法和fair模块一样，先下载url_hash源码，然后重新编译nginx源码，将url_hash模块添加到编译配置参数当中，最后将编译后生成的nginx二进制文件替换之前安装的nginx二进制文件即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">upstream tomcats &#123;</span><br><span class="line">    server 192.168.0.100:8080;</span><br><span class="line">    server 192.168.0.101:8080;</span><br><span class="line">    server 192.168.0.102:8080;</span><br><span class="line">    <span class="built_in">hash</span> <span class="variable">$request_uri</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是Nginx配置正向代理、反向代理和负载均衡相关参数。&lt;/p&gt;
&lt;h2 id=&quot;相关概念&quot;&gt;&lt;a href=&quot;#相关概念&quot; class=&quot;headerlink&quot; title=&quot;相关概念&quot;&gt;&lt;/a&gt;相关概念&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;正向代理是一个位于客户端和目标
      
    
    </summary>
    
      <category term="Nginx正反向代理/负载均衡" scheme="http://yoursite.com/categories/Nginx%E6%AD%A3%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
    
      <category term="nginx" scheme="http://yoursite.com/tags/nginx/"/>
    
      <category term="proxy" scheme="http://yoursite.com/tags/proxy/"/>
    
      <category term="load-balance" scheme="http://yoursite.com/tags/load-balance/"/>
    
  </entry>
  
  <entry>
    <title>LVM创建/扩容/常用操作</title>
    <link href="http://yoursite.com/2018/02/20/lvm/"/>
    <id>http://yoursite.com/2018/02/20/lvm/</id>
    <published>2018-02-19T16:00:00.000Z</published>
    <updated>2018-03-07T07:37:42.978Z</updated>
    
    <content type="html"><![CDATA[<p>本帖子记录的是LVM初始化和扩容等操作</p><h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><ul><li><p>LVM是逻辑盘卷管理（Logical Volume Manager）的简称，它是Linux环境下对磁盘分区进行管理的一种机制，LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分区管理的灵活性。LVM是在磁盘分区和文件系统之间添加的一个逻辑层，来为文件系统屏蔽下层磁盘分区布局，提供一个抽象的盘卷，在盘卷上建立文件系统。物理卷（physical volume）物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备（如RAID），是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数。</p></li><li><p>物理卷：Physical Volume，简称PV，一个物理卷只不过是一个有LVM管理数据添加在里面的物理存储介质。要使用LVM系统，首先对要用于LVM的磁盘进行初始化，初始化的目的就是将磁盘或分区标识为LVM 的物理卷。使用pvcreate 命令可以将一个磁盘标记为 LVM 物理卷。</p></li><li><p>物理分区：Physical Extents，简称PE，LVM将每个物理卷分别叫做物理分区的可寻址存储单元，存储单元的大小通常为几MB。磁盘的开头部分为LVM元数据，之后从索引为零开始，每个物理分区的索引依次递增一，按顺序进行分配。</p></li><li><p>卷组：Volume Group，简称VG，物理卷可以组织为卷组。卷组可以由一个或多个物理卷组成，同时系统中可以有多个卷组。创建了卷组之后，该卷组（而不是磁盘）便是表示数据存储的实体。因此，尽管以前是将磁盘从一个系统移动到另一个系统，使用了 LVM 之后，会将卷组从一个系统移动到另一个系统。出于这种原因，通常在一个系统上创建多个卷组会比较方便。</p></li><li><p>逻辑分区：Logical Extents，简称LE，逻辑卷的基本分配单元称为逻辑分区。逻辑分区映射到物理分区，因此，如果物理分区的尺寸小为4MB，那么逻辑分区的尺寸也将为4MB。逻辑卷的大小取决于所分配的逻辑分区数量。</p></li></ul><p><img src="/images/lvm-concept.png" alt="lvm-concept"></p><h2 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h2><ul><li>CentOS 7/RHEL 7</li></ul><p>建议在安装系统的时候就选择好LVM分区，不然已经有数据的话再选择LVM需要格式化。</p><h2 id="对新增加的硬盘进行分区、格式化"><a href="#对新增加的硬盘进行分区、格式化" class="headerlink" title="对新增加的硬盘进行分区、格式化"></a>对新增加的硬盘进行分区、格式化</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 在CentOS/RHEL 7中使用</span></span><br><span class="line"></span><br><span class="line">$ fdisk /dev/sda　　　 </span><br><span class="line"><span class="comment">## 继续输入命令： </span></span><br><span class="line"><span class="comment">## p　　　　　　　查看已分区数量</span></span><br><span class="line"><span class="comment">## n　　　　　　　新增加一个分区 </span></span><br><span class="line"><span class="comment">## p　　　　　　　分区类型我们选择为主分区 </span></span><br><span class="line"><span class="comment">##　　　　　　分区号按照默认选择（已经存在的会顺着按下一个分区号生成）</span></span><br><span class="line"><span class="comment">## 回车　　　　　　默认（起始扇区） </span></span><br><span class="line"><span class="comment">## 回车　　　　　　默认（结束扇区） </span></span><br><span class="line"><span class="comment">## t　　　　　　　修改分区类型 </span></span><br><span class="line"><span class="comment">##　　　　　　选分区3 </span></span><br><span class="line"><span class="comment">## 8e　　　　　　修改为LVM（8e就是LVM） </span></span><br><span class="line"><span class="comment">## w　　　　　　写分区表 </span></span><br><span class="line"><span class="comment">## q　　　　　　完成，退出fdisk命令 </span></span><br><span class="line"><span class="comment">##　　系统提示重启。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 开机后，格式化，等待一会儿： </span></span><br><span class="line">$ mkfs.ext3 /dev/sda3</span><br></pre></td></tr></table></figure><h2 id="添加新LVM到已有的LVM组，实现扩容"><a href="#添加新LVM到已有的LVM组，实现扩容" class="headerlink" title="添加新LVM到已有的LVM组，实现扩容"></a>添加新LVM到已有的LVM组，实现扩容</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ pvcreate /dev/sda3　　　                              <span class="comment">#创建pv</span></span><br><span class="line"></span><br><span class="line">$ pvdisplay                                             <span class="comment">#查看创建好的pv信息</span></span><br><span class="line"></span><br><span class="line">$ vgdisplay                                             <span class="comment">#查看vg信息，记录需要扩容的vg名称</span></span><br><span class="line"></span><br><span class="line">$ vgcreate vg_test /dev/sdb3                            <span class="comment">#没有则创建</span></span><br><span class="line"></span><br><span class="line">$ vgextend vg_test /dev/sda3                            <span class="comment">#将初始化过的分区加入到虚拟卷组vg_test</span></span><br><span class="line"></span><br><span class="line">$ lvextend -l +20G /dev/mapper/vg_test-root             <span class="comment">#扩展已有卷的容量</span></span><br><span class="line"></span><br><span class="line">$ lvextend -l +100%FREE /dev/mapper/vg_test-root        <span class="comment">#把所有空余的空间全部加入到卷组</span></span><br><span class="line"></span><br><span class="line">$ lvcreate -L 15G -n lv_test vg_test                    <span class="comment">#若初始化，则创建LV</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## CentOS7使用以下命令,进行文件系统的真正扩容</span></span><br><span class="line">$ xfs_growfs /dev/mapper/vg_test-root</span><br><span class="line"></span><br><span class="line"><span class="comment">## CentOS6使用以下命令,进行文件系统的真正扩容</span></span><br><span class="line">$ resize2fs /dev/mapper/vg_test-root</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看新的磁盘空间</span></span><br><span class="line">$ df -h</span><br></pre></td></tr></table></figure><h2 id="LVM常用命令"><a href="#LVM常用命令" class="headerlink" title="LVM常用命令"></a>LVM常用命令</h2><ul><li>lvremove : 移除逻辑卷</li></ul><p>lvremove /dev/vgname/lvname     </p><p>如果该lv已经mount了，lvremove不能使用，必须unmount后才可以使用。</p><ul><li>lvcreate ：创建逻辑卷</li></ul><p>lvcreate –name vol_01  -L  10G vgname</p><p>-L ：指定逻辑卷大小，单位可以是”kKmMgGtT”</p><ul><li>lvextend -L +10G  /dev/vgname/lvname</li></ul><p>给lvname添加10G的容量</p><p>另外一种写法：</p><p>lvcreate –size 40GB –name vol vgname</p><ul><li>vgcreate：创建卷组vg</li></ul><p>vgcreate vg-test /dev/sdb1 /dev/sdb2</p><ul><li>vgremove：强制删除vg，及时vg下有lv，也会被删除</li></ul><p>vgremove vgname -f </p><ul><li>vgreduce ：移除物理卷</li></ul><p>my_volume_group /dev/hda1</p><p>vgreduce –removemissing  vgname </p><ul><li>vgextend ：扩容物理卷</li></ul><p>vgextend vgname   /dev/sdb1(物理卷位置)</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>为了系统启动是自动加载文件系统，需要在 /etc/fstab 添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/dev/vg_test/lv_test   /opt/<span class="built_in">test</span> ext3 defaults 1 2</span><br></pre></td></tr></table></figure><p>有时可能因为逻辑卷为打开而无法启动系统</p><p>以下是系统启动LVM的过程图：</p><p><img src="/images/lvm-run.png" alt="lvm-run"></p><h2 id="自动化脚本例子"><a href="#自动化脚本例子" class="headerlink" title="自动化脚本例子"></a>自动化脚本例子</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Usage: Automatic expand lv with LVM managed disk</span></span><br><span class="line"><span class="meta">#</span><span class="bash">  Setp 1: Add Hard Disk or Storage to Computing unit</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   Setp 2: Execute this script with root privilege</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   Setp 3: Mind info of this script execution result</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> Open the refrigerator door, get the shell script execution environment ready</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Put the elephant into the refrigerator, how the shell scripts works</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Close the refrigerator door, check out the result of execution</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Simetimes, we have to pull new elephant or elephant dung out here, <span class="built_in">unset</span> variables of shell script</span></span><br><span class="line"> </span><br><span class="line">function check_execution_result()&#123;</span><br><span class="line">        if [[ ! -z $RETVAL ]]; then</span><br><span class="line">                unset RETVAL</span><br><span class="line">        fi</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        if [[ $RETVAL -ne 0 ]]; then</span><br><span class="line">                echo execution failed! </span><br><span class="line">                exit $RETVAL</span><br><span class="line">        else</span><br><span class="line">                echo execution successfully! </span><br><span class="line">        fi</span><br><span class="line">        unset RETVAL</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> lsblk --scsi</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> lsblk --all</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> fd0               2:0    1    4K  0 disk </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sda               8:0    0   40G  0 disk </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ├─sda1            8:1    0  500M  0 part /boot</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> └─sda2            8:2    0 39.5G  0 part </span></span><br><span class="line"><span class="meta">#</span><span class="bash">   ├─centos-swap 253:0    0  3.9G  0 lvm  [SWAP]</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   └─centos-root 253:1    0 35.6G  0 lvm  /</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sdb               8:16   0   16G  0 disk </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sr0              11:0    1  6.6G  0 rom  </span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> Show present scsi disk online</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Q: Why use <span class="string">"xargs"</span> here?</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> A: Convert the text from multi-line single-column into single-line multi-column, <span class="keyword">for</span> sed operation</span></span><br><span class="line">ONLINE_SCSI_DISK_PRESENT=$(lsblk --all | grep disk | grep -v fd | awk '&#123;print $1&#125;' | xargs)</span><br><span class="line"><span class="meta">#</span><span class="bash"> TODO</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> For execution this script beyond twice</span></span><br><span class="line">ONLINE_SCSI_DISK_PRESENT=sda</span><br><span class="line"><span class="meta">#</span><span class="bash"> Find new scsi disk online</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> TODO figure it out why there is host0? </span></span><br><span class="line">echo "- - -" &gt;/sys/class/scsi_host/host0/scan</span><br><span class="line">echo "- - -" &gt;/sys/class/scsi_host/host1/scan</span><br><span class="line">echo "- - -" &gt;/sys/class/scsi_host/host2/scan</span><br><span class="line"><span class="meta">#</span><span class="bash"> Show new added scsi disk online</span></span><br><span class="line">ONLINE_SCSI_DISK_NEWADD=$(lsblk --all | grep disk | grep -v fd | awk '&#123;print $1&#125;' | xargs echo | sed "s/$ONLINE_SCSI_DISK_PRESENT//g")</span><br><span class="line"><span class="meta">#</span><span class="bash"> Construct disk file with full path</span></span><br><span class="line">echo New Added SCSI Disk: $ONLINE_SCSI_DISK_NEWADD</span><br><span class="line"><span class="meta">#</span><span class="bash"> Get VG Name</span></span><br><span class="line">VG_Name=$(vgdisplay | grep 'VG Name' | awk '&#123;print $NF&#125;')</span><br><span class="line">VG_PATH_TO_EXTEND=$(lvdisplay | grep 'LV Path' | awk '&#123;print $NF&#125;' | grep root)</span><br><span class="line">for BLOCK in $ONLINE_SCSI_DISK_NEWADD; do</span><br><span class="line">    ONLINE_SCSI_DISK_NEWADD_FILENAME="/dev/"$BLOCK</span><br><span class="line">    # end-of-file contents and eof mark must start row1</span><br><span class="line">    fdisk $ONLINE_SCSI_DISK_NEWADD_FILENAME &gt;/dev/null 2&gt;&amp;1&lt;&lt;eof</span><br><span class="line">n</span><br><span class="line">p</span><br><span class="line">1</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">t</span><br><span class="line">8e</span><br><span class="line">w</span><br><span class="line">eof</span><br><span class="line">    check_execution_result</span><br><span class="line">    LVM_OPERATION_DISK_FILENAME=$ONLINE_SCSI_DISK_NEWADD_FILENAME"1"</span><br><span class="line">    pvcreate $LVM_OPERATION_DISK_FILENAME &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">    check_execution_result</span><br><span class="line">    vgextend $VG_Name $LVM_OPERATION_DISK_FILENAME &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">    check_execution_result</span><br><span class="line">    lvresize -l +100%FREE $VG_PATH_TO_EXTEND &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">    check_execution_result</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> resize2fs - ext2/ext3/ext4 file system resizer</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> xfs_growfs, xfs_info - expand an XFS filesystem</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">[root@hlc7172009 ~]<span class="comment"># resize2fs /dev/mapper/centos-root</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">resize2fs 1.42.9 (28-Dec-2013)</span></span><br><span class="line"><span class="meta">#</span><span class="bash">resize2fs: Bad magic number <span class="keyword">in</span> super-block <span class="keyword">while</span> trying to open /dev/mapper/centos-root</span></span><br><span class="line"><span class="meta">#</span><span class="bash">Couldn<span class="string">'t find valid filesystem superblock.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">[root@hlc7172009 ~]<span class="comment">#</span></span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">[root@hlc7172009 ~]<span class="comment"># xfs_growfs $VG_PATH_TO_EXTEND</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">meta-data=/dev/mapper/centos-root isize=256    agcount=4, agsize=2334208 blks</span></span><br><span class="line"><span class="meta">#</span><span class="bash">         =                       sectsz=512   attr=2, projid32bit=1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">         =                       crc=0</span></span><br><span class="line"><span class="meta">#</span><span class="bash">data     =                       bsize=4096   blocks=9336832, imaxpct=25</span></span><br><span class="line"><span class="meta">#</span><span class="bash">         =                       sunit=0      swidth=0 blks</span></span><br><span class="line"><span class="meta">#</span><span class="bash">naming   =version 2              bsize=4096   ascii-ci=0 ftype=0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">log</span>      =internal               bsize=4096   blocks=4559, version=2</span></span><br><span class="line"><span class="meta">#</span><span class="bash">         =                       sectsz=512   sunit=0 blks, lazy-count=1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">realtime =none                   extsz=4096   blocks=0, rtextents=0</span></span><br><span class="line"><span class="meta">#</span><span class="bash">data blocks changed from 9336832 to 13530112</span></span><br><span class="line"><span class="meta">#</span><span class="bash">[root@hlc7172009 ~]<span class="comment">#</span></span></span><br><span class="line"> </span><br><span class="line">    # Check xfs_info if is installed </span><br><span class="line">    which xfs_info &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">    if [[ $? -ne 0 ]]; then</span><br><span class="line">        yum install xfsprogs -y &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">    fi</span><br><span class="line">    # end Check xfs_info if is installed</span><br><span class="line"> </span><br><span class="line">    # Check VG_PATH_TO_EXTEND if is xfs filesystem</span><br><span class="line">    xfs_info $VG_PATH_TO_EXTEND &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">    if [[ $? -ne 0 ]]; then</span><br><span class="line">        # is not xfs</span><br><span class="line">        VG_PATH_TO_EXTEND_IS_NOT_XFS=0</span><br><span class="line">    else </span><br><span class="line">        # is xfs</span><br><span class="line">        VG_PATH_TO_EXTEND_IS_NOT_XFS=1</span><br><span class="line">    fi</span><br><span class="line">    # end Check VG_PATH_TO_EXTEND if is xfs filesystem</span><br><span class="line"> </span><br><span class="line">    # TODO CentOS7 default filesystem is xfs, so we can check it out by OS if is CentOS7</span><br><span class="line"> </span><br><span class="line">    if [[ $VG_PATH_TO_EXTEND_IS_NOT_XFS ]]; then</span><br><span class="line">        # is xfs</span><br><span class="line">        xfs_growfs $VG_PATH_TO_EXTEND &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">    else</span><br><span class="line">        # is not xfs</span><br><span class="line">        resize2fs $VG_PATH_TO_EXTEND &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">    fi</span><br><span class="line">    check_execution_result</span><br><span class="line">    df -h</span><br><span class="line">    lsblk --all</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p>添加磁盘前：</p><p><img src="/images/lvm-before.jpg" alt="lvm-before"></p><p>添加磁盘后运行脚本后：</p><p><img src="/images/lvm-after.jpg" alt="lvm-after"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本帖子记录的是LVM初始化和扩容等操作&lt;/p&gt;
&lt;h2 id=&quot;相关概念&quot;&gt;&lt;a href=&quot;#相关概念&quot; class=&quot;headerlink&quot; title=&quot;相关概念&quot;&gt;&lt;/a&gt;相关概念&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;LVM是逻辑盘卷管理（Logical Volume 
      
    
    </summary>
    
      <category term="LVM使用" scheme="http://yoursite.com/categories/LVM%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="centos" scheme="http://yoursite.com/tags/centos/"/>
    
      <category term="lvm" scheme="http://yoursite.com/tags/lvm/"/>
    
  </entry>
  
</feed>
